<!DOCTYPE html>
<html >

<head>

  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <title>AnalizaR datos políticos</title>
  <meta name="description" content="Proyecto de libro">
  <meta name="generator" content="bookdown 0.7 and GitBook 2.6.7">

  <meta property="og:title" content="AnalizaR datos políticos" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="Proyecto de libro" />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="AnalizaR datos políticos" />
  
  <meta name="twitter:description" content="Proyecto de libro" />
  

<meta name="author" content="Francisco Urdinez y Andrés Cruz Labrín (editores)">



  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  
  <link rel="shortcut icon" href="favicon.ico" type="image/x-icon">
<link rel="prev" href="stats.html">
<link rel="next" href="logit.html">
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />







<script src="libs/kePrint-0.0.1/kePrint.js"></script>
<script src="libs/htmlwidgets-1.2/htmlwidgets.js"></script>
<link href="libs/wordcloud2-0.0.1/wordcloud.css" rel="stylesheet" />
<script src="libs/wordcloud2-0.0.1/wordcloud2-all.js"></script>
<script src="libs/wordcloud2-0.0.1/hover.js"></script>
<script src="libs/wordcloud2-binding-0.2.1/wordcloud2.js"></script>


<style type="text/css">
a.sourceLine { display: inline-block; line-height: 1.25; }
a.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; }
a.sourceLine:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
a.sourceLine { text-indent: -1em; padding-left: 1em; }
}
pre.numberSource a.sourceLine
  { position: relative; left: -4em; }
pre.numberSource a.sourceLine::before
  { content: attr(data-line-number);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; pointer-events: all; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {  }
@media screen {
a.sourceLine::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><b><a href="./index.html">analizaR datos políticos</a></b></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Tabla de contenidos</a></li>
<li class="chapter" data-level="1" data-path="prefacio.html"><a href="prefacio.html"><i class="fa fa-check"></i><b>1</b> Prefacio</a><ul>
<li class="chapter" data-level="1.1" data-path="prefacio.html"><a href="prefacio.html#agradecimientos"><i class="fa fa-check"></i><b>1.1</b> Agradecimientos</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="introduccion.html"><a href="introduccion.html"><i class="fa fa-check"></i><b>2</b> Introducción</a><ul>
<li class="chapter" data-level="2.1" data-path="introduccion.html"><a href="introduccion.html#organizacion-del-libro"><i class="fa fa-check"></i><b>2.1</b> Organización del libro</a></li>
<li class="chapter" data-level="2.2" data-path="introduccion.html"><a href="introduccion.html#prerrequisitos"><i class="fa fa-check"></i><b>2.2</b> Prerrequisitos</a></li>
</ul></li>
<li class="part"><span><b>I Introducción a R</b></span></li>
<li class="chapter" data-level="3" data-path="rbas.html"><a href="rbas.html"><i class="fa fa-check"></i><b>3</b> R básico</a><ul>
<li class="chapter" data-level="3.1" data-path="rbas.html"><a href="rbas.html#instalacion"><i class="fa fa-check"></i><b>3.1</b> Instalación</a><ul>
<li class="chapter" data-level="3.1.1" data-path="rbas.html"><a href="rbas.html#r"><i class="fa fa-check"></i><b>3.1.1</b> R</a></li>
<li class="chapter" data-level="3.1.2" data-path="rbas.html"><a href="rbas.html#rstudio"><i class="fa fa-check"></i><b>3.1.2</b> RStudio</a></li>
</ul></li>
<li class="chapter" data-level="3.2" data-path="rbas.html"><a href="rbas.html#partes-de-rstudio"><i class="fa fa-check"></i><b>3.2</b> Partes de RStudio</a><ul>
<li class="chapter" data-level="3.2.1" data-path="rbas.html"><a href="rbas.html#consola"><i class="fa fa-check"></i><b>3.2.1</b> Consola</a></li>
<li class="chapter" data-level="3.2.2" data-path="rbas.html"><a href="rbas.html#script"><i class="fa fa-check"></i><b>3.2.2</b> Script</a></li>
<li class="chapter" data-level="3.2.3" data-path="rbas.html"><a href="rbas.html#objetos"><i class="fa fa-check"></i><b>3.2.3</b> Objetos</a></li>
<li class="chapter" data-level="3.2.4" data-path="rbas.html"><a href="rbas.html#archivos-graficos-paquetes-ayuda"><i class="fa fa-check"></i><b>3.2.4</b> Archivos / gráficos / paquetes / ayuda</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="rbas.html"><a href="rbas.html#ejercicios"><i class="fa fa-check"></i><b>3.3</b> Ejercicios</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="manejo-de-datos.html"><a href="manejo-de-datos.html"><i class="fa fa-check"></i><b>4</b> Manejo de datos</a><ul>
<li class="chapter" data-level="4.1" data-path="manejo-de-datos.html"><a href="manejo-de-datos.html#nuestra-base-de-datos"><i class="fa fa-check"></i><b>4.1</b> Nuestra base de datos</a></li>
<li class="chapter" data-level="4.2" data-path="manejo-de-datos.html"><a href="manejo-de-datos.html#describir-la-base"><i class="fa fa-check"></i><b>4.2</b> Describir la base</a></li>
<li class="chapter" data-level="4.3" data-path="manejo-de-datos.html"><a href="manejo-de-datos.html#ordenar-la-base-con-arrange"><i class="fa fa-check"></i><b>4.3</b> Ordenar la base con <code>arrange()</code></a></li>
<li class="chapter" data-level="4.4" data-path="manejo-de-datos.html"><a href="manejo-de-datos.html#seleccionar-columnas-de-la-base-con-select"><i class="fa fa-check"></i><b>4.4</b> Seleccionar columnas de la base con <code>select()</code></a></li>
<li class="chapter" data-level="4.5" data-path="manejo-de-datos.html"><a href="manejo-de-datos.html#renombrar-columnas-de-la-base-con-rename"><i class="fa fa-check"></i><b>4.5</b> Renombrar columnas de la base con <code>rename()</code></a></li>
<li class="chapter" data-level="4.6" data-path="manejo-de-datos.html"><a href="manejo-de-datos.html#filtrar-observaciones-de-la-base-con-filter"><i class="fa fa-check"></i><b>4.6</b> Filtrar observaciones de la base con <code>filter()</code></a></li>
<li class="chapter" data-level="4.7" data-path="manejo-de-datos.html"><a href="manejo-de-datos.html#crear-nuevas-variables-en-la-base-con-mutate"><i class="fa fa-check"></i><b>4.7</b> Crear nuevas variables en la base con <code>mutate()</code></a></li>
<li class="chapter" data-level="4.8" data-path="manejo-de-datos.html"><a href="manejo-de-datos.html#concatenar-comandos-las-pipes"><i class="fa fa-check"></i><b>4.8</b> Concatenar comandos: las pipes (<code>%&gt;%</code>)</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="dataviz.html"><a href="dataviz.html"><i class="fa fa-check"></i><b>5</b> Visualización de datos</a><ul>
<li class="chapter" data-level="5.1" data-path="dataviz.html"><a href="dataviz.html#por-que-quiero-visualizar-mis-datos"><i class="fa fa-check"></i><b>5.1</b> ¿Por qué quiero visualizar mis datos?</a></li>
<li class="chapter" data-level="5.2" data-path="dataviz.html"><a href="dataviz.html#primeros-pasos"><i class="fa fa-check"></i><b>5.2</b> Primeros pasos</a><ul>
<li class="chapter" data-level="5.2.1" data-path="dataviz.html"><a href="dataviz.html#las-capas-del-multiverso-ggplotidiano"><i class="fa fa-check"></i><b>5.2.1</b> Las capas del multiverso ggplotidiano</a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="dataviz.html"><a href="dataviz.html#elecciones-locales-y-visualizacion-de-datos"><i class="fa fa-check"></i><b>5.3</b> Elecciones locales y visualización de datos</a><ul>
<li class="chapter" data-level="5.3.1" data-path="dataviz.html"><a href="dataviz.html#grafico-de-barras"><i class="fa fa-check"></i><b>5.3.1</b> Gráfico de barras</a></li>
<li class="chapter" data-level="5.3.2" data-path="dataviz.html"><a href="dataviz.html#boxplot"><i class="fa fa-check"></i><b>5.3.2</b> Boxplot</a></li>
<li class="chapter" data-level="5.3.3" data-path="dataviz.html"><a href="dataviz.html#relacion-entre-variables"><i class="fa fa-check"></i><b>5.3.3</b> Relación entre variables</a></li>
</ul></li>
<li class="chapter" data-level="5.4" data-path="dataviz.html"><a href="dataviz.html#para-seguir-aprendiendo"><i class="fa fa-check"></i><b>5.4</b> Para seguir aprendiendo</a><ul>
<li class="chapter" data-level="5.4.1" data-path="dataviz.html"><a href="dataviz.html#otros-paquetes"><i class="fa fa-check"></i><b>5.4.1</b> Otros paquetes:</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="6" data-path="carga-flujo.html"><a href="carga-flujo.html"><i class="fa fa-check"></i><b>6</b> Carga de bases y flujo de trabajo</a></li>
<li class="part"><span><b>II Modelos</b></span></li>
<li class="chapter" data-level="7" data-path="stats.html"><a href="stats.html"><i class="fa fa-check"></i><b>7</b> Estadística inferencial básica</a></li>
<li class="chapter" data-level="8" data-path="lineal.html"><a href="lineal.html"><i class="fa fa-check"></i><b>8</b> Modelos lineales</a><ul>
<li class="chapter" data-level="8.1" data-path="lineal.html"><a href="lineal.html#introduccion-1"><i class="fa fa-check"></i><b>8.1</b> Introducción</a></li>
<li class="chapter" data-level="8.2" data-path="lineal.html"><a href="lineal.html#aplicacion-en-r"><i class="fa fa-check"></i><b>8.2</b> Aplicación en R</a><ul>
<li class="chapter" data-level="8.2.1" data-path="lineal.html"><a href="lineal.html#estadisticos-descriptivos"><i class="fa fa-check"></i><b>8.2.1</b> Estadísticos Descriptivos</a></li>
<li class="chapter" data-level="8.2.2" data-path="lineal.html"><a href="lineal.html#estadisticos-descriptivos-y-distribucion-de-las-variables-del-modelo"><i class="fa fa-check"></i><b>8.2.2</b> Estadísticos descriptivos y distribución de las variables del modelo</a></li>
<li class="chapter" data-level="8.2.3" data-path="lineal.html"><a href="lineal.html#matriz-de-correlacion-de-variables-independientes"><i class="fa fa-check"></i><b>8.2.3</b> Matriz de correlación de variables independientes</a></li>
<li class="chapter" data-level="8.2.4" data-path="lineal.html"><a href="lineal.html#distribucion-de-las-variables-de-interes"><i class="fa fa-check"></i><b>8.2.4</b> Distribución de las variables de interés</a></li>
<li class="chapter" data-level="8.2.5" data-path="lineal.html"><a href="lineal.html#relacion-entre-la-variable-dependiente-e-independiente"><i class="fa fa-check"></i><b>8.2.5</b> Relación entre la variable dependiente e independiente</a></li>
</ul></li>
<li class="chapter" data-level="8.3" data-path="lineal.html"><a href="lineal.html#modelo-bivariado-regresion-lineal-simple"><i class="fa fa-check"></i><b>8.3</b> Modelo bivariado: regresión lineal simple</a><ul>
<li class="chapter" data-level="8.3.1" data-path="lineal.html"><a href="lineal.html#estimando-un-modelo-lineal-en-r"><i class="fa fa-check"></i><b>8.3.1</b> Estimando un modelo lineal en R</a></li>
<li class="chapter" data-level="8.3.2" data-path="lineal.html"><a href="lineal.html#representacion-grafica."><i class="fa fa-check"></i><b>8.3.2</b> Representación gráfica.</a></li>
</ul></li>
<li class="chapter" data-level="8.4" data-path="lineal.html"><a href="lineal.html#modelo-multivariado-regresion-multiple"><i class="fa fa-check"></i><b>8.4</b> Modelo multivariado: regresión múltiple</a><ul>
<li class="chapter" data-level="8.4.1" data-path="lineal.html"><a href="lineal.html#ajuste-del-modelo"><i class="fa fa-check"></i><b>8.4.1</b> Ajuste del modelo</a></li>
<li class="chapter" data-level="8.4.2" data-path="lineal.html"><a href="lineal.html#inferencia-en-modelos-lineales-multiples"><i class="fa fa-check"></i><b>8.4.2</b> Inferencia en modelos lineales múltiples</a></li>
<li class="chapter" data-level="8.4.3" data-path="lineal.html"><a href="lineal.html#supuestos-de-ols"><i class="fa fa-check"></i><b>8.4.3</b> Supuestos de OLS</a></li>
<li class="chapter" data-level="8.4.4" data-path="lineal.html"><a href="lineal.html#errores-estandares-robustos"><i class="fa fa-check"></i><b>8.4.4</b> Errores estándares robustos</a></li>
<li class="chapter" data-level="8.4.5" data-path="lineal.html"><a href="lineal.html#un-caso-especial-de-heterocedasticidad-la-varianza-del-error-asociada-a-clusters"><i class="fa fa-check"></i><b>8.4.5</b> Un caso especial de Heterocedasticidad: la varianza del error asociada a clusters</a></li>
<li class="chapter" data-level="8.4.6" data-path="lineal.html"><a href="lineal.html#un-supuesto-adicional-para-poder-realizar-inferencia"><i class="fa fa-check"></i><b>8.4.6</b> Un supuesto adicional para poder realizar <strong>inferencia</strong></a></li>
</ul></li>
<li class="chapter" data-level="8.5" data-path="lineal.html"><a href="lineal.html#seleccion-de-casos"><i class="fa fa-check"></i><b>8.5</b> Selección de casos</a><ul>
<li class="chapter" data-level="8.5.1" data-path="lineal.html"><a href="lineal.html#que-casos-seleccionar"><i class="fa fa-check"></i><b>8.5.1</b> ¿Qué casos seleccionar?</a></li>
<li class="chapter" data-level="8.5.2" data-path="lineal.html"><a href="lineal.html#casos-tipicos"><i class="fa fa-check"></i><b>8.5.2</b> Casos Típicos</a></li>
<li class="chapter" data-level="8.5.3" data-path="lineal.html"><a href="lineal.html#casos-desviados"><i class="fa fa-check"></i><b>8.5.3</b> Casos desviados</a></li>
<li class="chapter" data-level="8.5.4" data-path="lineal.html"><a href="lineal.html#casos-influyentes"><i class="fa fa-check"></i><b>8.5.4</b> Casos Influyentes</a></li>
<li class="chapter" data-level="8.5.5" data-path="lineal.html"><a href="lineal.html#casos-extremos"><i class="fa fa-check"></i><b>8.5.5</b> Casos extremos</a></li>
<li class="chapter" data-level="8.5.6" data-path="lineal.html"><a href="lineal.html#casos-mas-similares"><i class="fa fa-check"></i><b>8.5.6</b> Casos más similares</a></li>
<li class="chapter" data-level="8.5.7" data-path="lineal.html"><a href="lineal.html#casos-mas-diferentes"><i class="fa fa-check"></i><b>8.5.7</b> Casos más diferentes</a></li>
</ul></li>
<li class="chapter" data-level="8.6" data-path="lineal.html"><a href="lineal.html#la-relevancia-de-combinar-metodos"><i class="fa fa-check"></i><b>8.6</b> La relevancia de combinar métodos</a></li>
<li class="chapter" data-level="8.7" data-path="lineal.html"><a href="lineal.html#referencias"><i class="fa fa-check"></i><b>8.7</b> Referencias</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="logit.html"><a href="logit.html"><i class="fa fa-check"></i><b>9</b> Modelos binarios</a><ul>
<li class="chapter" data-level="9.1" data-path="logit.html"><a href="logit.html#nociones-basicas"><i class="fa fa-check"></i><b>9.1</b> Nociones básicas</a></li>
<li class="chapter" data-level="9.2" data-path="logit.html"><a href="logit.html#aplicacion-en-r-1"><i class="fa fa-check"></i><b>9.2</b> Aplicación en R</a><ul>
<li class="chapter" data-level="9.2.1" data-path="logit.html"><a href="logit.html#estimar-los-modelos"><i class="fa fa-check"></i><b>9.2.1</b> Estimar los modelos</a></li>
<li class="chapter" data-level="9.2.2" data-path="logit.html"><a href="logit.html#crear-tablas"><i class="fa fa-check"></i><b>9.2.2</b> Crear tablas</a></li>
<li class="chapter" data-level="9.2.3" data-path="logit.html"><a href="logit.html#visualizacion-de-resultados"><i class="fa fa-check"></i><b>9.2.3</b> Visualización de resultados</a></li>
<li class="chapter" data-level="9.2.4" data-path="logit.html"><a href="logit.html#ajuste-de-los-modelos"><i class="fa fa-check"></i><b>9.2.4</b> Ajuste de los modelos</a></li>
</ul></li>
<li class="chapter" data-level="9.3" data-path="logit.html"><a href="logit.html#proximos-pasos"><i class="fa fa-check"></i><b>9.3</b> Próximos pasos</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="surv.html"><a href="surv.html"><i class="fa fa-check"></i><b>10</b> Modelos de supervivencia</a><ul>
<li class="chapter" data-level="10.1" data-path="surv.html"><a href="surv.html#nociones-basicas-1"><i class="fa fa-check"></i><b>10.1</b> Nociones básicas</a></li>
<li class="chapter" data-level="10.2" data-path="surv.html"><a href="surv.html#el-modelo-cox-de-riesgos-proporcionales"><i class="fa fa-check"></i><b>10.2</b> El modelo Cox de riesgos proporcionales</a></li>
<li class="chapter" data-level="10.3" data-path="surv.html"><a href="surv.html#aplicacion-en-r-2"><i class="fa fa-check"></i><b>10.3</b> Aplicación en R</a><ul>
<li class="chapter" data-level="10.3.1" data-path="surv.html"><a href="surv.html#replicar-la-tabla-1.2-de-altman-e-interpretar-sus-coeficientes-como-hazard-ratios."><i class="fa fa-check"></i><b>10.3.1</b> Replicar la tabla 1.2 de Altman e interpretar sus coeficientes como Hazard Ratios.</a></li>
</ul></li>
</ul></li>
<li class="part"><span><b>III Aplicaciones</b></span></li>
<li class="chapter" data-level="11" data-path="manejo-av.html"><a href="manejo-av.html"><i class="fa fa-check"></i><b>11</b> Manejo avanzado de datos políticos</a><ul>
<li class="chapter" data-level="11.1" data-path="manejo-av.html"><a href="manejo-av.html#introduccion-2"><i class="fa fa-check"></i><b>11.1</b> Introducción</a></li>
<li class="chapter" data-level="11.2" data-path="manejo-av.html"><a href="manejo-av.html#como-aprovechar-countrycode"><i class="fa fa-check"></i><b>11.2</b> ¿Cómo aprovechar ´countrycode´?</a></li>
<li class="chapter" data-level="11.3" data-path="manejo-av.html"><a href="manejo-av.html#como-imputar-datos"><i class="fa fa-check"></i><b>11.3</b> ¿Cómo imputar datos?</a></li>
</ul></li>
<li class="chapter" data-level="12" data-path="pca.html"><a href="pca.html"><i class="fa fa-check"></i><b>12</b> Creación de índices con Análisis de Componentes Principales (PCA)</a><ul>
<li class="chapter" data-level="12.1" data-path="pca.html"><a href="pca.html#conceptos-importantes"><i class="fa fa-check"></i><b>12.1</b> Conceptos importantes</a></li>
<li class="chapter" data-level="12.2" data-path="pca.html"><a href="pca.html#aplicacion-en-r-3"><i class="fa fa-check"></i><b>12.2</b> Aplicación en R</a></li>
</ul></li>
<li class="chapter" data-level="13" data-path="web-mining.html"><a href="web-mining.html"><i class="fa fa-check"></i><b>13</b> Mínería de datos</a></li>
<li class="chapter" data-level="14" data-path="redes.html"><a href="redes.html"><i class="fa fa-check"></i><b>14</b> Análisis de redes</a><ul>
<li class="chapter" data-level="14.1" data-path="redes.html"><a href="redes.html#introduccion-3"><i class="fa fa-check"></i><b>14.1</b> Introducción</a></li>
<li class="chapter" data-level="14.2" data-path="redes.html"><a href="redes.html#conceptos-basicos-de-redes"><i class="fa fa-check"></i><b>14.2</b> Conceptos básicos de redes</a><ul>
<li class="chapter" data-level="14.2.1" data-path="redes.html"><a href="redes.html#nodos-y-enlaces"><i class="fa fa-check"></i><b>14.2.1</b> Nodos y enlaces</a></li>
<li class="chapter" data-level="14.2.2" data-path="redes.html"><a href="redes.html#matriz-de-adyacencia"><i class="fa fa-check"></i><b>14.2.2</b> Matriz de adyacencia</a></li>
<li class="chapter" data-level="14.2.3" data-path="redes.html"><a href="redes.html#pesos-y-direccion"><i class="fa fa-check"></i><b>14.2.3</b> Pesos y dirección</a></li>
</ul></li>
<li class="chapter" data-level="14.3" data-path="redes.html"><a href="redes.html#generar-una-base-de-datos-de-redes"><i class="fa fa-check"></i><b>14.3</b> Generar una base de datos de redes</a></li>
<li class="chapter" data-level="14.4" data-path="redes.html"><a href="redes.html#disposicion-de-los-puntos-en-el-espacio"><i class="fa fa-check"></i><b>14.4</b> Disposición de los puntos en el espacio</a></li>
<li class="chapter" data-level="14.5" data-path="redes.html"><a href="redes.html#calcular-medidas-de-centralidad-basicas"><i class="fa fa-check"></i><b>14.5</b> Calcular medidas de centralidad básicas</a></li>
<li class="chapter" data-level="14.6" data-path="redes.html"><a href="redes.html#detectar-comunidades-en-las-redes"><i class="fa fa-check"></i><b>14.6</b> Detectar comunidades en las redes</a></li>
</ul></li>
<li class="chapter" data-level="15" data-path="qta.html"><a href="qta.html"><i class="fa fa-check"></i><b>15</b> Análisis cuantitativo de textos</a><ul>
<li class="chapter" data-level="15.1" data-path="qta.html"><a href="qta.html#introduccion-4"><i class="fa fa-check"></i><b>15.1</b> Introducción</a></li>
<li class="chapter" data-level="15.2" data-path="qta.html"><a href="qta.html#bases-de-datos"><i class="fa fa-check"></i><b>15.2</b> Bases de datos</a></li>
<li class="chapter" data-level="15.3" data-path="qta.html"><a href="qta.html#calculo-de-frecuencias"><i class="fa fa-check"></i><b>15.3</b> Cálculo de frecuencias</a><ul>
<li class="chapter" data-level="15.3.1" data-path="qta.html"><a href="qta.html#hashtags-mas-usados-de-las-cuentas-de-los-diputados"><i class="fa fa-check"></i><b>15.3.1</b> 10 hashtags mas usados de las cuentas de los diputados</a></li>
<li class="chapter" data-level="15.3.2" data-path="qta.html"><a href="qta.html#frecuencias-por-genero-cantidad-de-hashtags-usados-por-los-diputados-en-total"><i class="fa fa-check"></i><b>15.3.2</b> Frecuencias por género: cantidad de hashtags usados por los diputados en total</a></li>
</ul></li>
<li class="chapter" data-level="15.4" data-path="qta.html"><a href="qta.html#wordcloud-de-hashtags"><i class="fa fa-check"></i><b>15.4</b> Wordcloud de hashtags</a></li>
<li class="chapter" data-level="15.5" data-path="qta.html"><a href="qta.html#hashtags-mas-usados-por-genero"><i class="fa fa-check"></i><b>15.5</b> Hashtags más usados por género</a><ul>
<li class="chapter" data-level="15.5.1" data-path="qta.html"><a href="qta.html#entre-las-diputadas"><i class="fa fa-check"></i><b>15.5.1</b> Entre las diputadas</a></li>
<li class="chapter" data-level="15.5.2" data-path="qta.html"><a href="qta.html#entre-las-diputadas-1"><i class="fa fa-check"></i><b>15.5.2</b> Entre las diputadas</a></li>
</ul></li>
<li class="chapter" data-level="15.6" data-path="qta.html"><a href="qta.html#hashtags-de-genero-por-caracteristicas-del-diputado"><i class="fa fa-check"></i><b>15.6</b> Hashtags de género por características del diputado</a><ul>
<li class="chapter" data-level="15.6.1" data-path="qta.html"><a href="qta.html#por-el-genero-del-diputado"><i class="fa fa-check"></i><b>15.6.1</b> Por el género del diputado</a></li>
<li class="chapter" data-level="15.6.2" data-path="qta.html"><a href="qta.html#por-la-coalicion-de-los-diputados"><i class="fa fa-check"></i><b>15.6.2</b> Por la coalición de los diputados</a></li>
</ul></li>
<li class="chapter" data-level="15.7" data-path="qta.html"><a href="qta.html#variacion-temporal-del-uso-de-estos-hashtags"><i class="fa fa-check"></i><b>15.7</b> Variación temporal del uso de estos hashtags</a><ul>
<li class="chapter" data-level="15.7.1" data-path="qta.html"><a href="qta.html#frecuencia-semanal-de-olafeminista"><i class="fa fa-check"></i><b>15.7.1</b> Frecuencia semanal de #olafeminista</a></li>
<li class="chapter" data-level="15.7.2" data-path="qta.html"><a href="qta.html#frecuencia-semanal-de-tres-hashtags-de-genero"><i class="fa fa-check"></i><b>15.7.2</b> Frecuencia semanal de tres hashtags de género</a></li>
<li class="chapter" data-level="15.7.3" data-path="qta.html"><a href="qta.html#grafiquemos-los-hashtags-de-genero-por-semana"><i class="fa fa-check"></i><b>15.7.3</b> Grafiquemos los hashtags de género por semana</a></li>
<li class="chapter" data-level="15.7.4" data-path="qta.html"><a href="qta.html#ponderamos-en-relacion-al-total-de-hashtags-por-semana"><i class="fa fa-check"></i><b>15.7.4</b> Ponderamos en relación al total de hashtags por semana</a></li>
<li class="chapter" data-level="15.7.5" data-path="qta.html"><a href="qta.html#grafiquemos-los-hashtags-interesantes-ponderados-por-el-total-semanal"><i class="fa fa-check"></i><b>15.7.5</b> Grafiquemos los hashtags interesantes ponderados por el total semanal</a></li>
<li class="chapter" data-level="15.7.6" data-path="qta.html"><a href="qta.html#diputadas"><i class="fa fa-check"></i><b>15.7.6</b> Diputadas</a></li>
</ul></li>
<li class="chapter" data-level="15.8" data-path="qta.html"><a href="qta.html#hashtags-de-genero-por-semana-a-nivel-de-diputados-ponderados-por-semana"><i class="fa fa-check"></i><b>15.8</b> Hashtags de género por semana a nivel de diputados (ponderados por semana)</a></li>
<li class="chapter" data-level="15.9" data-path="qta.html"><a href="qta.html#comentarios-finales"><i class="fa fa-check"></i><b>15.9</b> Comentarios finales</a></li>
</ul></li>
<li class="chapter" data-level="16" data-path="mapas.html"><a href="mapas.html"><i class="fa fa-check"></i><b>16</b> Generación de mapas</a><ul>
<li class="chapter" data-level="16.1" data-path="mapas.html"><a href="mapas.html#datos-espaciales"><i class="fa fa-check"></i><b>16.1</b> Datos Espaciales</a><ul>
<li class="chapter" data-level="16.1.1" data-path="mapas.html"><a href="mapas.html#que-son"><i class="fa fa-check"></i><b>16.1.1</b> ¿Qué son?</a></li>
<li class="chapter" data-level="16.1.2" data-path="mapas.html"><a href="mapas.html#estructura-de-los-datos-espaciales"><i class="fa fa-check"></i><b>16.1.2</b> Estructura de los Datos Espaciales</a></li>
</ul></li>
<li class="chapter" data-level="16.2" data-path="mapas.html"><a href="mapas.html#datos-espaciales-en-r"><i class="fa fa-check"></i><b>16.2</b> Datos Espaciales en R</a></li>
<li class="chapter" data-level="16.3" data-path="mapas.html"><a href="mapas.html#special-features-en-r"><i class="fa fa-check"></i><b>16.3</b> Special Features en R</a><ul>
<li class="chapter" data-level="16.3.1" data-path="mapas.html"><a href="mapas.html#estructura"><i class="fa fa-check"></i><b>16.3.1</b> Estructura</a></li>
</ul></li>
<li class="chapter" data-level="16.4" data-path="mapas.html"><a href="mapas.html#manejo-de-datos-espaciales"><i class="fa fa-check"></i><b>16.4</b> Manejo de Datos Espaciales</a><ul>
<li class="chapter" data-level="16.4.1" data-path="mapas.html"><a href="mapas.html#modificaciones"><i class="fa fa-check"></i><b>16.4.1</b> Modificaciones</a></li>
<li class="chapter" data-level="16.4.2" data-path="mapas.html"><a href="mapas.html#crear-nuevos-shapefiles-con-st_write"><i class="fa fa-check"></i><b>16.4.2</b> .4 Crear nuevos shapefiles con <code>st_write</code></a></li>
<li class="chapter" data-level="16.4.3" data-path="mapas.html"><a href="mapas.html#incorporar-datos-de-otras-bases-con-merge"><i class="fa fa-check"></i><b>16.4.3</b> Incorporar datos de otras bases con <code>merge</code></a></li>
</ul></li>
<li class="chapter" data-level="16.5" data-path="mapas.html"><a href="mapas.html#mapear-en-r"><i class="fa fa-check"></i><b>16.5</b> Mapear en R</a></li>
<li class="chapter" data-level="16.6" data-path="mapas.html"><a href="mapas.html#mapeando-variables"><i class="fa fa-check"></i><b>16.6</b> Mapeando variables</a><ul>
<li class="chapter" data-level="16.6.1" data-path="mapas.html"><a href="mapas.html#mapas-animados-con-gganimate"><i class="fa fa-check"></i><b>16.6.1</b> Mapas animados con gganimate</a></li>
</ul></li>
<li class="chapter" data-level="16.7" data-path="mapas.html"><a href="mapas.html#inferencia-a-partir-de-datos-espaciales"><i class="fa fa-check"></i><b>16.7</b> Inferencia a partir de Datos Espaciales</a><ul>
<li class="chapter" data-level="16.7.1" data-path="mapas.html"><a href="mapas.html#indicadores-locales-de-asociacion-espacial-lisa"><i class="fa fa-check"></i><b>16.7.1</b> Indicadores locales de asociación espacial (LISA)</a></li>
<li class="chapter" data-level="16.7.2" data-path="mapas.html"><a href="mapas.html#matriz-de-pesos-espaciales"><i class="fa fa-check"></i><b>16.7.2</b> Matriz de Pesos Espaciales</a></li>
<li class="chapter" data-level="16.7.3" data-path="mapas.html"><a href="mapas.html#morans-i"><i class="fa fa-check"></i><b>16.7.3</b> Moran’s I</a></li>
</ul></li>
</ul></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">AnalizaR datos políticos</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="lineal" class="section level1">
<h1><span class="header-section-number">Capítulo 8</span> Modelos lineales</h1>
<p><em>Por Inés Fynn y Lihuen Nocetto</em></p>
<div id="introduccion-1" class="section level2">
<h2><span class="header-section-number">8.1</span> Introducción</h2>
<p>PENDIENTE.</p>
</div>
<div id="aplicacion-en-r" class="section level2">
<h2><span class="header-section-number">8.2</span> Aplicación en R</h2>
<p>La base de datos con la que trabajaremos en este capítulo se nutre de dos bases de datos construidas por Evelyne Huber y John D. Stephens (<a href="http://huberandstephens.web.unc.edu/common-works/data/" class="uri">http://huberandstephens.web.unc.edu/common-works/data/</a>). Estas dos bases de datos son:</p>
<ul>
<li><p>Latin America Welfare Dataset, 1960-2014 (Evelyne Huber and John D. Stephens, Latin American Welfare Dataset, 1960-2014, University of North Carolina at Chapel Hill, 2014.): contiene variables sobre Estados de Bienestar en todos los países de América Latina y el Caribe entre los años 1960 y 2014.</p></li>
<li><p>Latin America and Caribbean Political Data Set, 1945-2012 (Evelyne Huber and John D. Stephens, Latin America and the Caribbean Political Dataset, 1945-2012, University of North Carolina at Chapel Hill, 2012.): contiene variables políticas para todos los países de América Latina y el Caribe entre los años 1945 y 2012.</p></li>
</ul>
<p>La base de datos resultante contiene 1074 observaciones de 25 países entre los años 1970 y 2012 (se dejaron por fuera los datos de la década del 60 por tener demasiados valores perdidos).</p>
<p>Primero cargamos el paquete <code>tidyverse</code> que incluye un conjunto amplio de funciones para el manejo de bases de datos</p>
<div class="sourceCode" id="cb80"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb80-1" data-line-number="1"><span class="kw">library</span>(tidyverse)</a></code></pre></div>
<p>Vamos a importar esta base de datos:</p>
<p>Como base para el análisis en este capítuo tomaremos el paper de Huber et al (2006) donde se estiman los determinantes de la desigualdad en los países de América Latina y el Caribe. Trabajar sobre la base de este artículo nos permite estimar un modelo con varias variables de control que ya se ha probado son importantes para explicar la variación de la desigualdad en la región.</p>
<p>Por tanto, la variable dependiente que nos interesa explicar es la desigualdad de ingresos en países de América Latina y el Caribe, operacionalizada a partir del Índice de Gini (<code>gini_slc</code>).</p>
<p>Las variables independientes que incorporaremos al modelo son las siguientes:</p>
<ul>
<li>Dualismosectorial (refiere a la la coexistencia de un sector tradicional de baja productividad y un sector moderno de alta productividad) - s_dualism</li>
<li>PBI - rgdpch</li>
<li>Inversión Extranjera Directa (ingresos netos - % del PIB) - fdiingdp</li>
<li>Diversidad étnica (variable dummy codificada 1 cuando al menos el 20 %, pero no más del 80 % de la población es étnicamente diversa) - ethnicdicot</li>
<li>Democracia (tipo de régimen) - demrss</li>
<li>Gasto en educación (como porcentaje del PBI) - cseduc</li>
<li>Gasto en salud (comoporcentaje del PBI) - cshlth</li>
<li>Gasto en seguridad social - csssw</li>
<li>Balance legislativo - legbal</li>
<li>AutoritarismoRepresivo - repressauthor</li>
</ul>
<p>Durante este capítulo intentaremos estimar cuál es el efecto del gasto en educación sobre la desigualdad en los países de América Latina y el Caribe. De este modo, nuestra variable independiente de interés será Gasto en Educación (<code>cseduc</code>).</p>
<div id="estadisticos-descriptivos" class="section level3">
<h3><span class="header-section-number">8.2.1</span> Estadísticos Descriptivos</h3>
<p>Antes de estimar un modelo con Mínimos Cuadrados Ordinarios (MCO, o OLS por su sigla en inglés), o con cualquier estimador, es recomendable reconocer la distribución de las variables de interés: la variable dependiente <span class="math inline">\(y\)</span> (variable explicada, el regresando) y la variable independiente de interés <span class="math inline">\(x\)</span> (variable explicativa, regresor).</p>
<p>Por lo general, en nuestros modelos tendremos, además de la variable independiente de interés, otras variables independientes (o explicativas) que les llamaremos “controles” pues su función será hacer el escenario <em>ceteris paribus</em> lo más creíble posible. Es decir, “mantener el resto de los factores constantes” para acercarnos lo más posible a un mundo experimental, en el que podemos controlar todas las variables que afectan <span class="math inline">\(y\)</span> y observar cómo la variación en una sola variable independiente <span class="math inline">\(x\)</span> afecta la variación de la variable dependiente (<span class="math inline">\(y\)</span>).</p>
<p>Entonces, antes de estimar el modelo, vamos a observar los estadísticos descriptivos de las variables que estarán incorporadas a dicho modelo (tanto de la dependiente como de las independientes). El objetivo es prestar atención a los siguientes puntos:</p>
<ol style="list-style-type: decimal">
<li><p>Variación en <span class="math inline">\(x\)</span>: que las variables independientes (pero sobre todo la de interés) tengan variación en nuestra muestra. Pues si no hay variación de <span class="math inline">\(x\)</span>, no podremos estimar cómo esta variación afecta la variación de <span class="math inline">\(y\)</span>.</p></li>
<li><p>Variación en <span class="math inline">\(y\)</span>: si la variable dependiente no varía, no vamos a poder explicar su variación en función de las <span class="math inline">\(x\)</span>.</p></li>
<li><p>Unidad de medición de las variables: es en esta instancia donde evaluamos cómo están medidas nuestras variables (además de revisar los diccionarios que por lo general acompañan las bases de datos con las que trabajamos), para poder entender qué tipo de variables estas debieran ser (nominales, ordinales, continuas), y además para luego poder interpretar correctamente los resultados obtenidos.</p></li>
<li><p>Tipos de variables: en la estimación por Mínimos Cuadrados Ordinarios las variables dependientes deben ser, generalmente, <em>continuas</em> (aunque es posible trabajar con variables dependientes dicotómicas). Por tanto, debemos asegurarnos que la variable dependiente sea continua y numérica. Además, es importante conocer el tipo de variables independientes y chequear que su tipo sea coherente con cómo está codificada (i.e si tenemos una variable independiente de “rangos de edad” la variable debe ser categórica o de factor, y no númerica), para que luego nuestras interpretaciones de los resultados sean correctas.</p></li>
<li><p>Identificar valores perdidos: Si nuestras variables tienen demasiados valores perdidos debemos revisar a qué se debe esto y, eventualmente, imputar datos (como se explica en el capítuo #XX ).</p></li>
</ol>
</div>
<div id="estadisticos-descriptivos-y-distribucion-de-las-variables-del-modelo" class="section level3">
<h3><span class="header-section-number">8.2.2</span> Estadísticos descriptivos y distribución de las variables del modelo</h3>
<p>Una primera visualización de nuestras variables de interés la podemos hacer utilizando el comando <code>skmir</code> que nos otorga no solo algunos estadísticos descriptivos sino también la distribución de las variables.</p>
<div class="sourceCode" id="cb81"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb81-1" data-line-number="1"><span class="kw">library</span>(skimr)</a></code></pre></div>
<div class="sourceCode" id="cb82"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb82-1" data-line-number="1"><span class="kw">skim</span>(basehys <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">select</span>(gini_slc, cseduc, fdiingdp, rgdpch, cseduc, cshlth, csssw, ethnicdicot, pop014wdi))<span class="op">%&gt;%</span><span class="st"> </span>skimr<span class="op">::</span><span class="kw">kable</span>()</a>
<a class="sourceLine" id="cb82-2" data-line-number="2"><span class="co">## Skim summary statistics  </span></a>
<a class="sourceLine" id="cb82-3" data-line-number="3"><span class="co">##  n obs: 1074    </span></a>
<a class="sourceLine" id="cb82-4" data-line-number="4"><span class="co">##  n variables: 8    </span></a>
<a class="sourceLine" id="cb82-5" data-line-number="5"><span class="co">## </span></a>
<a class="sourceLine" id="cb82-6" data-line-number="6"><span class="co">## Variable type: numeric</span></a>
<a class="sourceLine" id="cb82-7" data-line-number="7"><span class="co">## </span></a>
<a class="sourceLine" id="cb82-8" data-line-number="8"><span class="co">##   variable      missing    complete     n       mean        sd         p0         p25        p50        p75       p100        hist   </span></a>
<a class="sourceLine" id="cb82-9" data-line-number="9"><span class="co">## -------------  ---------  ----------  ------  ---------  ---------  ---------  ---------  ---------  ---------  ---------  ----------</span></a>
<a class="sourceLine" id="cb82-10" data-line-number="10"><span class="co">##    cseduc         325        749       1074      3.8       1.65        0.4        2.6        3.8        4.8        9.1      ▂▅▇▇▅▂▁▁ </span></a>
<a class="sourceLine" id="cb82-11" data-line-number="11"><span class="co">##    cshlth         325        749       1074      2.5       1.89        0.1        1.1        2.1        3.4        15       ▇▆▃▁▁▁▁▁ </span></a>
<a class="sourceLine" id="cb82-12" data-line-number="12"><span class="co">##     csssw         467        607       1074      4.1       3.57         0         1.5         3         5.7       16.8      ▇▆▃▂▁▁▁▁ </span></a>
<a class="sourceLine" id="cb82-13" data-line-number="13"><span class="co">##  ethnicdicot      370        704       1074     0.45        0.5         0          0          0          1          1       ▇▁▁▁▁▁▁▇ </span></a>
<a class="sourceLine" id="cb82-14" data-line-number="14"><span class="co">##   fdiingdp        198        876       1074     2.19       4.18      -55.24      0.48       1.43       3.29       39.81     ▁▁▁▁▇▂▁▁ </span></a>
<a class="sourceLine" id="cb82-15" data-line-number="15"><span class="co">##   gini_slc        649        425       1074     49.54      6.73       28.9        44        50.6        55        68.3      ▁▁▅▆▆▇▁▁ </span></a>
<a class="sourceLine" id="cb82-16" data-line-number="16"><span class="co">##   pop014wdi       129        945       1074     36.36      7.01       18.99      30.79      36.57      42.26      48.73     ▁▃▆▆▇▆▇▆ </span></a>
<a class="sourceLine" id="cb82-17" data-line-number="17"><span class="co">##    rgdpch         194        880       1074    7345.94    4981.75    1421.71    4046.04    6264.85    8667.02    29343.9    ▇▇▃▁▁▁▁▁</span></a></code></pre></div>
<p>En el output se ordenan los resultados por tipo de variable, nos indica la cantidad de missing para cada una de ellas, su respectiva media, desvío estandar, los valores correspondientes a los percentiles y un pequeño histograma que nos muestra cómoestán distribuidas.</p>
<p>Además, si quisieramos, podriamos realizar una tabla seleccionando solo algunos de los estadísticos que te interesan. Aquí por ejemplo, solo nos interesa ver la media y desviación estándar:</p>
<div class="sourceCode" id="cb83"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb83-1" data-line-number="1"><span class="kw">skim</span>(basehys <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">select</span>(cseduc, fdiingdp, rgdpch, cseduc, cshlth, csssw, ethnicdicot, pop014wdi))<span class="op">%&gt;%</span><span class="st"> </span>dplyr<span class="op">::</span><span class="kw">filter</span>(stat<span class="op">==</span><span class="kw">c</span>(<span class="st">&quot;mean&quot;</span>,<span class="st">&quot;sd&quot;</span>))<span class="op">%&gt;%</span><span class="st"> </span>skimr<span class="op">::</span><span class="kw">kable</span>()</a>
<a class="sourceLine" id="cb83-2" data-line-number="2"><span class="co">## Warning in stat == c(&quot;mean&quot;, &quot;sd&quot;): longer object length is not a multiple</span></a>
<a class="sourceLine" id="cb83-3" data-line-number="3"><span class="co">## of shorter object length</span></a></code></pre></div>
<table>
<thead>
<tr class="header">
<th align="left">variable</th>
<th>type s</th>
<th>tat l</th>
<th>evel v</th>
<th>alue f</th>
<th align="left">ormatted</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">fdiingdp</td>
<td>numeric</td>
<td>mean</td>
<td>.all</td>
<td>2.19</td>
<td align="left">2.19</td>
</tr>
<tr class="even">
<td align="left">fdiingdp</td>
<td>numeric</td>
<td>sd</td>
<td>.all</td>
<td>4.18</td>
<td align="left">4.18</td>
</tr>
<tr class="odd">
<td align="left">cshlth</td>
<td>numeric</td>
<td>mean</td>
<td>.all</td>
<td>2.50</td>
<td align="left">2.5</td>
</tr>
<tr class="even">
<td align="left">cshlth</td>
<td>numeric</td>
<td>sd</td>
<td>.all</td>
<td>1.89</td>
<td align="left">1.89</td>
</tr>
<tr class="odd">
<td align="left">ethnicdicot</td>
<td>numeric</td>
<td>mean</td>
<td>.all</td>
<td>0.45</td>
<td align="left">0.45</td>
</tr>
<tr class="even">
<td align="left">ethnicdicot</td>
<td>numeric</td>
<td>sd</td>
<td>.all</td>
<td>0.50</td>
<td align="left">0.5</td>
</tr>
</tbody>
</table>
<p>En este caso solo nos interesa observar su distribución en histogramas:</p>
<div class="sourceCode" id="cb84"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb84-1" data-line-number="1"><span class="kw">skim</span>(basehys <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">select</span>(cseduc, fdiingdp, rgdpch, cseduc, cshlth, csssw))<span class="op">%&gt;%</span><span class="st"> </span>dplyr<span class="op">::</span><span class="kw">filter</span>(stat<span class="op">==</span><span class="st">&quot;hist&quot;</span>)<span class="op">%&gt;%</span><span class="st"> </span>skimr<span class="op">::</span><span class="kw">kable</span>()</a></code></pre></div>
<table>
<thead>
<tr class="header">
<th align="left">variable</th>
<th align="center">type</th>
<th align="left">stat</th>
<th align="left">level</th>
<th align="left">value</th>
<th align="left">formatted</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">cseduc</td>
<td align="center">numeric</td>
<td align="left">hist</td>
<td align="left">.all</td>
<td align="left">NA</td>
<td align="left">▂▅▇▇▅▂▁▁</td>
</tr>
<tr class="even">
<td align="left">fdiingdp</td>
<td align="center">numeric</td>
<td align="left">hist</td>
<td align="left">.all</td>
<td align="left">NA</td>
<td align="left">▁▁▁▁▇▂▁▁</td>
</tr>
<tr class="odd">
<td align="left">rgdpch</td>
<td align="center">numeric</td>
<td align="left">hist</td>
<td align="left">.all</td>
<td align="left">NA</td>
<td align="left">▇▇▃▁▁▁▁▁</td>
</tr>
<tr class="even">
<td align="left">cshlth</td>
<td align="center">numeric</td>
<td align="left">hist</td>
<td align="left">.all</td>
<td align="left">NA</td>
<td align="left">▇▆▃▁▁▁▁▁</td>
</tr>
<tr class="odd">
<td align="left">csssw</td>
<td align="center">numeric</td>
<td align="left">hist</td>
<td align="left">.all</td>
<td align="left">NA</td>
<td align="left">▇▆▃▂▁▁▁▁</td>
</tr>
</tbody>
</table>
</div>
<div id="matriz-de-correlacion-de-variables-independientes" class="section level3">
<h3><span class="header-section-number">8.2.3</span> Matriz de correlación de variables independientes</h3>
<p>Luego de reconocer todas las variables que incorporaremos al modelo, es recomendable observar cómo están relacionadas entre ellas. Para esto, realizamos una matriz de correlación de las variables independientes con el comando <code>rcorr</code> del paquete <code>Hmisc</code> donde podemos evaluar la correlaicón de Pearson entre todas las variables. Además, este comando también nos da el <em>p value</em> para cada correlación, donde podemos evaluar si la correlación observada es significativa.</p>
<p>De todos modos, es importante recordar que la <strong>correlación no implica causación</strong>. Aquí simplemente queremos comprender si las variables del modelo están de algún modo relacionadas. Este paso es importante no solo para un reconocimiento de nuestros datos y variables, sino también porque queremos evitar que nuestro modelo tenga multicolinealidad perfecta (que hayan variables independientes que estén perfectamente corrrelacionadas) pues es uno de los supuestos centrales de OLS que revisaremos al final de este capítuo.</p>
<div class="sourceCode" id="cb85"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb85-1" data-line-number="1">variables &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="st">&quot;gini_slc&quot;</span>,<span class="st">&quot;cseduc&quot;</span>,<span class="st">&quot;s_dualism&quot;</span>,<span class="st">&quot;fdiingdp&quot;</span>,<span class="st">&quot;rgdpch&quot;</span>,<span class="st">&quot;ethnicdicot&quot;</span>,<span class="st">&quot;demrss&quot;</span>,<span class="st">&quot;cshlth&quot;</span>,<span class="st">&quot;csssw&quot;</span>,<span class="st">&quot;legbal&quot;</span>,<span class="st">&quot;repressauthor&quot;</span>,<span class="st">&quot;pop014wdi&quot;</span>)</a>
<a class="sourceLine" id="cb85-2" data-line-number="2">vind &lt;-<span class="st"> </span>basehys[variables]</a></code></pre></div>
<div class="sourceCode" id="cb86"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb86-1" data-line-number="1"><span class="co">#install.packages(&#39;Hmisc&#39;)</span></a>
<a class="sourceLine" id="cb86-2" data-line-number="2"><span class="kw">library</span> (Hmisc)</a></code></pre></div>
<div class="sourceCode" id="cb87"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb87-1" data-line-number="1"><span class="kw">rcorr</span>(<span class="kw">as.matrix</span>(vind))</a>
<a class="sourceLine" id="cb87-2" data-line-number="2"><span class="co">##               gini_slc cseduc s_dualism fdiingdp rgdpch ethnicdicot demrss</span></a>
<a class="sourceLine" id="cb87-3" data-line-number="3"><span class="co">##               cshlth csssw legbal repressauthor pop014wdi</span></a>
<a class="sourceLine" id="cb87-4" data-line-number="4"><span class="co">##  [ reached getOption(&quot;max.print&quot;) -- omitted 12 rows ]</span></a>
<a class="sourceLine" id="cb87-5" data-line-number="5"><span class="co">## </span></a>
<a class="sourceLine" id="cb87-6" data-line-number="6"><span class="co">## n</span></a>
<a class="sourceLine" id="cb87-7" data-line-number="7"><span class="co">##               gini_slc cseduc s_dualism fdiingdp rgdpch ethnicdicot demrss</span></a>
<a class="sourceLine" id="cb87-8" data-line-number="8"><span class="co">##               cshlth csssw legbal repressauthor pop014wdi</span></a>
<a class="sourceLine" id="cb87-9" data-line-number="9"><span class="co">##  [ reached getOption(&quot;max.print&quot;) -- omitted 12 rows ]</span></a>
<a class="sourceLine" id="cb87-10" data-line-number="10"><span class="co">## </span></a>
<a class="sourceLine" id="cb87-11" data-line-number="11"><span class="co">## P</span></a>
<a class="sourceLine" id="cb87-12" data-line-number="12"><span class="co">##               gini_slc cseduc s_dualism fdiingdp rgdpch ethnicdicot demrss</span></a>
<a class="sourceLine" id="cb87-13" data-line-number="13"><span class="co">##               cshlth csssw  legbal repressauthor pop014wdi</span></a>
<a class="sourceLine" id="cb87-14" data-line-number="14"><span class="co">##  [ reached getOption(&quot;max.print&quot;) -- omitted 12 rows ]</span></a></code></pre></div>
<p>Ahora que conocemos todas las variables que incorporaremos al modelo, y cómo se relacionan entre sí, profundizaremos sobre las variables de interés: la dependiente y la independiente.</p>
</div>
<div id="distribucion-de-las-variables-de-interes" class="section level3">
<h3><span class="header-section-number">8.2.4</span> Distribución de las variables de interés</h3>
<p>Como mencionamos anteriormente, siempre nos interesa estimar cómo el cambio en una variable independiente (su variación) afecta la variación de una variable dependiente. Es decir, cómo cambia <span class="math inline">\(y\)</span> cuando cambia <span class="math inline">\(x\)</span>.</p>
<p>En este caso, supongamos que nos interesa estimar cómo varían los niveles de desigualdad de un país (medido a partir del Índice de Gini) en relación al gasto en la educación (medido como porcentaje del PBI destinado a la educación). De este modo, nuestra variable independiente de interés es el gasto en la educación, mientras que la variable dependiente es la desigualdad.</p>
<p>Veamos cómose distribuyen estas variables en nuestra base de datos:</p>
<p>La variable dependiente: Índice de Gini</p>
<div class="sourceCode" id="cb88"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb88-1" data-line-number="1"><span class="kw">ggplot</span>(basehys, <span class="kw">aes</span>(<span class="dt">x=</span>gini_slc, <span class="dt">na.rm=</span><span class="ot">TRUE</span>))<span class="op">+</span></a>
<a class="sourceLine" id="cb88-2" data-line-number="2"><span class="st">  </span><span class="kw">geom_histogram</span>(<span class="dt">binwidth =</span> <span class="dv">1</span>,<span class="dt">color=</span><span class="st">&quot;white&quot;</span>, <span class="dt">fill=</span><span class="st">&quot;deepskyblue4&quot;</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb88-3" data-line-number="3"><span class="kw">labs</span>(<span class="dt">title =</span> <span class="kw">paste</span>(</a>
<a class="sourceLine" id="cb88-4" data-line-number="4">          <span class="st">&quot;Distribución de la Variable Dependiente: Índice de Gini&quot;</span>),</a>
<a class="sourceLine" id="cb88-5" data-line-number="5">        <span class="dt">caption =</span> <span class="kw">paste</span> (<span class="st">&quot;Fuente: Huber et al (2012))&quot;</span></a>
<a class="sourceLine" id="cb88-6" data-line-number="6">      ),</a>
<a class="sourceLine" id="cb88-7" data-line-number="7">        <span class="dt">x =</span> <span class="st">&quot;Índice de Gini&quot;</span>,</a>
<a class="sourceLine" id="cb88-8" data-line-number="8">        <span class="dt">y =</span> <span class="st">&quot;Frecuencia&quot;</span></a>
<a class="sourceLine" id="cb88-9" data-line-number="9">)<span class="op">+</span></a>
<a class="sourceLine" id="cb88-10" data-line-number="10"><span class="st">  </span><span class="kw">theme_classic</span>()</a>
<a class="sourceLine" id="cb88-11" data-line-number="11"><span class="co">## Warning: Removed 649 rows containing non-finite values (stat_bin).</span></a></code></pre></div>
<p><img src="lineal_files/figure-html/unnamed-chunk-11-1.png" width="480" style="display: block; margin: auto;" /></p>
<p>La variable independiente: Gasto en Educación (% de PBI)</p>
<div class="sourceCode" id="cb89"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb89-1" data-line-number="1"><span class="kw">ggplot</span>(basehys, <span class="kw">aes</span>(<span class="dt">x=</span>cseduc, <span class="dt">na.rm=</span><span class="ot">TRUE</span>))<span class="op">+</span></a>
<a class="sourceLine" id="cb89-2" data-line-number="2"><span class="st">  </span><span class="kw">geom_histogram</span>(<span class="dt">binwidth =</span> <span class="dv">1</span>,<span class="dt">color=</span><span class="st">&quot;white&quot;</span>, <span class="dt">fill=</span><span class="st">&quot;deepskyblue4&quot;</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb89-3" data-line-number="3"><span class="kw">labs</span>(<span class="dt">title =</span> <span class="kw">paste</span>(</a>
<a class="sourceLine" id="cb89-4" data-line-number="4">          <span class="st">&quot;Distribución de la Variable Independiente: Gasto en Educación&quot;),subtitle = paste(&quot;</span>% de PBI destinado a la Educación&quot;),</a>
<a class="sourceLine" id="cb89-5" data-line-number="5">        <span class="dt">caption =</span> <span class="kw">paste</span> (<span class="st">&quot;Fuente: Huber et al (2012))&quot;</span></a>
<a class="sourceLine" id="cb89-6" data-line-number="6">      ),</a>
<a class="sourceLine" id="cb89-7" data-line-number="7">        <span class="dt">x =</span> <span class="st">&quot;Gasto en Educación&quot;,</span></a>
<a class="sourceLine" id="cb89-8" data-line-number="8"><span class="st">        y = &quot;</span>Frecuencia<span class="st">&quot;</span></a>
<a class="sourceLine" id="cb89-9" data-line-number="9"><span class="st">)+</span></a>
<a class="sourceLine" id="cb89-10" data-line-number="10"><span class="st">  theme_classic()</span></a>
<a class="sourceLine" id="cb89-11" data-line-number="11"><span class="st">## Warning: Removed 325 rows containing non-finite values (stat_bin).</span></a></code></pre></div>
<p><img src="lineal_files/figure-html/unnamed-chunk-12-1.png" width="480" style="display: block; margin: auto;" /></p>
</div>
<div id="relacion-entre-la-variable-dependiente-e-independiente" class="section level3">
<h3><span class="header-section-number">8.2.5</span> Relación entre la variable dependiente e independiente</h3>
<p>Luego de observar cómo distribuyen las variables de interés, podemos ver gráficamente cómo se relacionan. Es decir, graficamos la correlación entre estas dos variables: en el eje de <span class="math inline">\(x\)</span> (horizontal) ubicamos a la variable independiente, mientras que en el eje de <span class="math inline">\(y\)</span> (vertical) la variable dependiente. Como resultado, cada “punto” del gráfico representa una observación de nuestra muestra con un determinado valor de gasto en educación (<span class="math inline">\(x\)</span>) y un determinado valor en el índice de Gini (<span class="math inline">\(y\)</span>).</p>
<div class="sourceCode" id="cb90"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb90-1" data-line-number="1"><span class="kw">ggplot</span>(basehys, <span class="kw">aes</span>(cseduc, gini_slc)) <span class="op">+</span><span class="st"> </span><span class="kw">geom_point</span>()<span class="op">+</span><span class="st"> </span></a>
<a class="sourceLine" id="cb90-2" data-line-number="2"><span class="st">  </span><span class="kw">labs</span>(<span class="dt">title=</span><span class="st">&quot;Relación entre Gasto en Educación e Índice de Gini&quot;</span>, <span class="dt">x=</span><span class="st">&quot;Gasto en Educación (%de PBI)&quot;</span>, <span class="dt">y=</span><span class="st">&quot;Gini&quot;</span>, <span class="dt">caption =</span> <span class="kw">paste</span> (<span class="st">&quot;Fuente: Huber and Stephens, 2012&quot;</span>))</a>
<a class="sourceLine" id="cb90-3" data-line-number="3"><span class="co">## Warning: Removed 718 rows containing missing values (geom_point).</span></a></code></pre></div>
<p><img src="lineal_files/figure-html/unnamed-chunk-13-1.png" width="480" style="display: block; margin: auto;" /></p>
<p>Esta es una primera visualización de la relación entre nuestras variables que nos permite observar si hay algún tipo de vínculo entre ellas. Aquí claramente se observa una relación positiva (a mayor gasto en educación, mayor gini). De todos modos, hasta el momento no podemos decir nada concluyente sobre la relación entre gasto en educación y nivel de desigualdad, para esto es necesario estimar el modelo. Hasta ahora solo estuvimos conociendo nuestros datos.</p>
</div>
</div>
<div id="modelo-bivariado-regresion-lineal-simple" class="section level2">
<h2><span class="header-section-number">8.3</span> Modelo bivariado: regresión lineal simple</h2>
<p>El modelo lineal simple asume que una variable aleatoria de respuesta <span class="math inline">\(y\)</span> es una función lineal de una variable independiente <span class="math inline">\(x\)</span> más un término de error <span class="math inline">\(u\)</span>. También decimos que la variable dependiente <span class="math inline">\(y\)</span> es resultado de un Proceso de Generación del Dato (DGP por sus siglas en inglés) que puede escribirse
<span class="math display">\[ Y = \beta_0 + \beta_1x + u                   (1)\]</span></p>
<p>Entonces, el modelo lineal implica precisamente definir que <span class="math inline">\(Y\)</span> está generada por una función lineal de <span class="math inline">\(x_1\)</span>, además de un término constante <span class="math inline">\(\beta_0\)</span> y la variable <span class="math inline">\(u\)</span> que es inobservada.
Dos supuestos son necesarios para derivar los estimadores de Mínimos Cuadrados Ordinarios. El primero refiere a que la esperanza de <span class="math inline">\(u\)</span> es igual a 0 <span class="math display">\[E(u)=0\]</span>. Esto implica que a nivel poblacional, todos los factores inobservados promedian cero. El supuesto más importante refiere a que la media de <span class="math inline">\(u\)</span> para cada valor de <span class="math inline">\(x\)</span> es cero: <span class="math display">\[E(u|x)=0\]</span></p>
<p>Este supuesto se conoce en la literatura econométrica comomedia condicional cero, o independencia condicional. En la literatura experimentalista se conoce comoexogeneidad de la <span class="math inline">\(x\)</span> o también que <span class="math inline">\(x\)</span> y <span class="math inline">\(u\)</span> son ortogonales. Todos estos términos implican que se asume que para cada valor de la variable independiente de interés <span class="math inline">\(x\)</span> los factores inobservados promediarán cero. En otras palabras, conocer un valor determinado de la <span class="math inline">\(x\)</span> no nos dice nada acerca de los inobservados.
Cuando <span class="math inline">\(E(u|x) = 0\)</span>, entonces se cumple que
<span class="math display">\[cov(x,u) = 0\]</span>.</p>
<p>En definitiva, bajo el supuesto de independencia condicional, <span class="math inline">\(x\)</span> y <span class="math inline">\(u\)</span> no correlacionan y esto permite derivar los estimadores de Mínimos Cuadrados Ordinarios a través de las <em>condiciones de primer orden</em>. Las dos condiciones de primer orden son que <span class="math display">\[E(u)=0\]</span> y <span class="math display">\[E(u|x)=0\]</span></p>
<p>Entender que estas son las condiciones que permiten derivar el <em>estimador</em> de MCO es clave para entender porqué a partir de la estimación por MCO no podemos testear la independencia del error. Esto es, por construcción, los residuos (<span class="math inline">\(\hat{u}\)</span>) de la regresión siempre promediarán cero en la muestra y en cada valor de <span class="math inline">\(x\)</span>. Demandar exogeneidad implica poder argumentar que <span class="math inline">\(u\)</span> es efectivamente ortogonal a las <span class="math inline">\(x&#39;s\)</span>, algo más creíble para experimentos y cuasi experimentos (ver Gerber y Green 2012, Dunning 2012, Glennester y Takavarsha 2013).</p>
<p>Si damos por válido que <span class="math inline">\(E(u|x)= 0\)</span>,entonces por álgebra podemos escribir la esperanza de una variable Y dado X como</p>
<p><span class="math display">\[E(y|x)= \beta_0+ \beta_1x\]</span></p>
<p>Como se ve, el término inobservado <span class="math inline">\(u\)</span> desaparece de la ecuación cuando se considera la esperanza de la distribución de <span class="math inline">\(Y\)</span> (la esperanza de <span class="math inline">\(u\)</span> es cero). Al término constante <span class="math inline">\(\beta_0\)</span> y al efecto de la <span class="math inline">\(x_1\)</span> se lo conoce como “parte sistemática del modelo”&quot;, o también Función de Regresión Poblacional (FRP). Es clave entender que el supuesto de <span class="math inline">\(E(u)=0\)</span> refiere al promedio de los factores inobservables y que por tanto, en promedio <span class="math inline">\(u\)</span> no afecta a <span class="math inline">\(Y\)</span>.
Sin embargo, debe recordarse que cada realización de la variable aleatoria Y está generada por la ecuación 1, y que por tanto, la variable Y de un individuo aleatoriamente seleccionado de esa población es
<span class="math display">\[Y_i= \beta_0+\beta_1x_{1i}+u_i\]</span></p>
<p>Esto quiere decir que la realización de la variable aleatoria <span class="math inline">\(Y\)</span> para el individuo <span class="math inline">\(i\)</span> es una función de <span class="math inline">\(x_1\)</span> y <span class="math inline">\(u\)</span>. O sea, del valor que toma la <span class="math inline">\(x_1\)</span> en ese individuo y el valor que toma <span class="math inline">\(u\)</span>. Todos los factores inobservados que se anotan como<span class="math inline">\(u\)</span> son los que explican que cada individuo se aleje de la FRP.</p>
<div id="estimando-un-modelo-lineal-en-r" class="section level3">
<h3><span class="header-section-number">8.3.1</span> Estimando un modelo lineal en R</h3>
<p>Una vez que hemos definido un modelo poblacional como el descrito por la ecuación (1), nuestro trabajo es estimar el impacto de la variable independiente sobre la dependiente. La función <code>lm</code> que se encuentra en R base es la principal herramienta para estimar modelos lineales. La forma general que toma la función es</p>
<p>De donde se entiende que se estima un <em>linear model</em> (lm) para una variable dependiente Y regresada (~) en una variable independiente X. El “1” no es necesario, pero por estilo, se agrega para denotar el intercepto (<span class="math inline">\(\beta_0\)</span>).</p>
<p>Con base a la investigación de Huber y Stephens (2006) asumamos que la Desigualdad es una función lineal del Gasto en Educación más un término de error inobservado <span class="math inline">\(u\)</span> y una constante <span class="math inline">\(\beta_0\)</span>.
Formalmente:</p>
<p><span class="math display">\[ Desigualdad = \beta_0 + \beta_1 GastoEducación + u \]</span></p>
<p>Por el momento, vamos a asumir que la base de datos tiene 1074 observaciones independientes. En realidad, la estructura es de datos de panel: el mismopaís tiene distintas observaciones a lo largo del tiempo. Sin embargo, por el momento no estamos en condiciones de abordar correctamente estos datos. El supuesto de observaciones independientes e idénticamente distribuidas es lo que permite escribir la realización del modelo para un individuo <span class="math inline">\(i\)</span> aleatoriamente seleccionado como<span class="math display">\[Desigualdad_i= \beta_0 +  \beta_1GastoEducación_i + u_i\]</span></p>
<p>Para estimar el modelo, utilizaremos los datos de la base de Huber y Stephens (2006). La variable dependiente Desigualdad está medida a través del índice de gini y el nombre de la variable es “gini_slc”. La variable independiente Gasto en Educación es “cseduc”. Comolos datos están alojados en un data.frame, a la función le tenemos que indicar que traiga esos datos de la base correspondiente. Eso es lo que ocurre luego de la coma</p>
<div class="sourceCode" id="cb91"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb91-1" data-line-number="1">modelo_<span class="dv">1</span> &lt;-<span class="st"> </span><span class="kw">lm</span>(gini_slc<span class="op">~</span><span class="dv">1</span> <span class="op">+</span><span class="st"> </span>cseduc , <span class="dt">data=</span>basehys) <span class="co">#luego de la coma le indicamos el data.frame que contiene los datos.</span></a>
<a class="sourceLine" id="cb91-2" data-line-number="2"><span class="kw">class</span>(modelo_<span class="dv">1</span>) <span class="co"># verificamos que la clase del objeto  es &quot;lm&quot;</span></a>
<a class="sourceLine" id="cb91-3" data-line-number="3"><span class="co">## [1] &quot;lm&quot;</span></a></code></pre></div>
<p>En la primera línea de código se creó un objeto (modelo_1) en que se está guardando el resultado de la función <code>lm</code>. Esta función arroja objetos de clase “lm” que son vectores que incluyen los coeficientes estimados, los errores estándar, residuos, la bondad de ajuste, entre otros resultados de la estimación. Para ver los componentes del objeto, una forma rápida es utilizar la función <code>summary</code></p>
<div class="sourceCode" id="cb92"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb92-1" data-line-number="1"><span class="kw">summary</span>( modelo_<span class="dv">1</span>)</a>
<a class="sourceLine" id="cb92-2" data-line-number="2"><span class="co">## </span></a>
<a class="sourceLine" id="cb92-3" data-line-number="3"><span class="co">## Call:</span></a>
<a class="sourceLine" id="cb92-4" data-line-number="4"><span class="co">## lm(formula = gini_slc ~ 1 + cseduc, data = basehys)</span></a>
<a class="sourceLine" id="cb92-5" data-line-number="5"><span class="co">## </span></a>
<a class="sourceLine" id="cb92-6" data-line-number="6"><span class="co">## Residuals:</span></a>
<a class="sourceLine" id="cb92-7" data-line-number="7"><span class="co">##    Min     1Q Median     3Q    Max </span></a>
<a class="sourceLine" id="cb92-8" data-line-number="8"><span class="co">## -20.04  -5.62   1.09   4.99  15.57 </span></a>
<a class="sourceLine" id="cb92-9" data-line-number="9"><span class="co">## </span></a>
<a class="sourceLine" id="cb92-10" data-line-number="10"><span class="co">## Coefficients:</span></a>
<a class="sourceLine" id="cb92-11" data-line-number="11"><span class="co">##             Estimate Std. Error t value Pr(&gt;|t|)    </span></a>
<a class="sourceLine" id="cb92-12" data-line-number="12"><span class="co">## (Intercept)    44.80       1.02   43.80  &lt; 2e-16 ***</span></a>
<a class="sourceLine" id="cb92-13" data-line-number="13"><span class="co">##  [ reached getOption(&quot;max.print&quot;) -- omitted 1 row ]</span></a>
<a class="sourceLine" id="cb92-14" data-line-number="14"><span class="co">## ---</span></a>
<a class="sourceLine" id="cb92-15" data-line-number="15"><span class="co">## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</span></a>
<a class="sourceLine" id="cb92-16" data-line-number="16"><span class="co">## </span></a>
<a class="sourceLine" id="cb92-17" data-line-number="17"><span class="co">## Residual standard error: 6.7 on 354 degrees of freedom</span></a>
<a class="sourceLine" id="cb92-18" data-line-number="18"><span class="co">##   (718 observations deleted due to missingness)</span></a>
<a class="sourceLine" id="cb92-19" data-line-number="19"><span class="co">## Multiple R-squared:  0.0642, Adjusted R-squared:  0.0615 </span></a>
<a class="sourceLine" id="cb92-20" data-line-number="20"><span class="co">## F-statistic: 24.3 on 1 and 354 DF,  p-value: 1.29e-06</span></a></code></pre></div>
<p>Presentaciones más elegantes pueden obtenerse con <code>mtable</code> del paquete <code>memisc</code>, o con las funciones <code>stargazer</code> y <code>texreg</code> (los paquetes tienen el mismonombre que la función respectiva)
Veamos la presentación de resultados con la función <code>mtable</code></p>
<div class="sourceCode" id="cb93"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb93-1" data-line-number="1"><span class="kw">library</span>(memisc)</a></code></pre></div>
<div class="sourceCode" id="cb94"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb94-1" data-line-number="1"><span class="kw">mtable</span>(modelo_<span class="dv">1</span>)</a>
<a class="sourceLine" id="cb94-2" data-line-number="2"><span class="co">## </span></a>
<a class="sourceLine" id="cb94-3" data-line-number="3"><span class="co">## Calls:</span></a>
<a class="sourceLine" id="cb94-4" data-line-number="4"><span class="co">## modelo_1: lm(formula = gini_slc ~ 1 + cseduc, data = basehys)</span></a>
<a class="sourceLine" id="cb94-5" data-line-number="5"><span class="co">## </span></a>
<a class="sourceLine" id="cb94-6" data-line-number="6"><span class="co">## ===============================</span></a>
<a class="sourceLine" id="cb94-7" data-line-number="7"><span class="co">##   (Intercept)        44.81***  </span></a>
<a class="sourceLine" id="cb94-8" data-line-number="8"><span class="co">##                      (1.02)    </span></a>
<a class="sourceLine" id="cb94-9" data-line-number="9"><span class="co">##   cseduc              1.23***  </span></a>
<a class="sourceLine" id="cb94-10" data-line-number="10"><span class="co">##                      (0.25)    </span></a>
<a class="sourceLine" id="cb94-11" data-line-number="11"><span class="co">## -------------------------------</span></a>
<a class="sourceLine" id="cb94-12" data-line-number="12"><span class="co">##   R-squared           0.06     </span></a>
<a class="sourceLine" id="cb94-13" data-line-number="13"><span class="co">##   adj. R-squared      0.06     </span></a>
<a class="sourceLine" id="cb94-14" data-line-number="14"><span class="co">##   sigma               6.70     </span></a>
<a class="sourceLine" id="cb94-15" data-line-number="15"><span class="co">##   F                  24.27     </span></a>
<a class="sourceLine" id="cb94-16" data-line-number="16"><span class="co">##   p                   0.00     </span></a>
<a class="sourceLine" id="cb94-17" data-line-number="17"><span class="co">##   Log-likelihood  -1181.47     </span></a>
<a class="sourceLine" id="cb94-18" data-line-number="18"><span class="co">##   Deviance        15907.25     </span></a>
<a class="sourceLine" id="cb94-19" data-line-number="19"><span class="co">##   AIC              2368.94     </span></a>
<a class="sourceLine" id="cb94-20" data-line-number="20"><span class="co">##   BIC              2380.57     </span></a>
<a class="sourceLine" id="cb94-21" data-line-number="21"><span class="co">##   N                 356        </span></a>
<a class="sourceLine" id="cb94-22" data-line-number="22"><span class="co">## ===============================</span></a></code></pre></div>
<p>Como se ve, resulta más cómodo ver los resultados con <code>mtable</code> que con <code>summary</code>. Allí se ve claramente que la variable “cseduc”, Gasto en Educación, tiene un efecto positivo, de magnitud 1.233, estadísticamente significativo.En concreto, cuando el Gasto en Educación como porcentaje del PIB aumenta en una unidad, la desigualdad aumenta en un 1,23%. Esto es así ya que nuestra variable dependiente está medida del 1 al 100 al igual que la independiente. El efecto del Gasto en Educación es significativo al 99.9% de confianza. Sabemos eso porque al lado del coeficiente aparecen tres estrellas, que refieren a un nivel de significancia de 0,01 %.</p>
<p>La significancia estadística es resultado de la prueba t. Esta nos indica la distancia estandarizada donde se encuentra el beta estimado en la distribución del estimador bajo la hipótesis nula de que <span class="math inline">\(\beta_1=0\)</span>. El estimador tiene una distribución t-Student con grados de libertad igual a <span class="math inline">\(n-k-1\)</span> donde <span class="math inline">\(k\)</span> es el número de variables independientes y se le suma 1 por la estimación de la constante <span class="math inline">\(\beta_0\)</span>.</p>
<p>Una aproximación manual de la distancia del beta estimado en la distribución del estimador bajo la hipótesis nula <span class="math inline">\(\beta_1=0\)</span>, la obtenemos cuando dividimos la estimación por su error estándar:</p>
<div class="sourceCode" id="cb95"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb95-1" data-line-number="1"><span class="fl">1.233</span> <span class="op">/</span><span class="st"> </span><span class="fl">0.25</span></a>
<a class="sourceLine" id="cb95-2" data-line-number="2"><span class="co">## [1] 4.9</span></a></code></pre></div>
<p>Este valor es el mismo que arroja la tercera columna de la sección “Coefficients” del <code>summary</code> del modelo_1. El valor t se interpreta como la distancia de la estimación de <span class="math inline">\(\hat\beta_1\)</span> de la media de una distribución del estimador bajo <span class="math inline">\(H_0=\beta_1=0\)</span>. En este caso, el valor 1.233 está a 4.93 desvíos estándar de la distribución del estimador cuando H0 es verdadera (la media de la distribución es 0).
Como las distribuciones t colapsan sobre la normal a medida que aumentan los grados de libertad, y sabemos que aproximadamente hasta 2 desvíos estándar se encuentra el 95% de la probabilidad de una normal, entonces cuando el estadístico t supera el valor de 2 podemos saber que la probabilidad de observar nuestra estimación si H0 fuera cierta es menor a 0.05. Cuando esto sucede, rechazamos la hipótesis nula a un nivel de confianza del 95%.</p>
<p>En este caso, el <span class="math inline">\(\hat\beta_1\)</span> estimado está a más de 4.93 desvíos estándar de la media de la distribución bajo <span class="math inline">\(H_0=\beta_1=0\)</span> por lo que es muy poco probable haber observado un efecto de 1.23 si <span class="math inline">\(H_0\)</span> es verdadera. La probabilidad precisa puede observarse en la cuarta columna del <code>summary</code>del modelo, que puede solicitarse a R con el siguente comando.</p>
<div class="sourceCode" id="cb96"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb96-1" data-line-number="1"><span class="kw">coef</span>(<span class="kw">summary</span>( modelo_<span class="dv">1</span>))[, <span class="st">&quot;Pr(&gt;|t|)&quot;</span>]</a>
<a class="sourceLine" id="cb96-2" data-line-number="2"><span class="co">## (Intercept)      cseduc </span></a>
<a class="sourceLine" id="cb96-3" data-line-number="3"><span class="co">##    5.5e-145     1.3e-06</span></a></code></pre></div>
<p>La probabilidad de observar una estimación de 1.23 si H0 es verdadera es de 0,00000128. Por tanto, podemos rechazar H0 aún a un nivel de confianza de 99.9%</p>
<p>Si el investigador quisiera hacer todas estas operaciones manualmente para diversas variables de un modelo múltiple podría guardar los coeficientes estimados en un vector:</p>
<div class="sourceCode" id="cb97"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb97-1" data-line-number="1">coeficientes_estimados &lt;-<span class="st"> </span><span class="kw">coef</span>( modelo_<span class="dv">1</span>)</a></code></pre></div>
<p>Luego guardar los errores estándar,</p>
<div class="sourceCode" id="cb98"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb98-1" data-line-number="1">ee&lt;-<span class="st"> </span><span class="kw">coef</span>(<span class="kw">summary</span> (modelo_<span class="dv">1</span>)) [, <span class="st">&quot;Std. Error&quot;</span>]</a></code></pre></div>
<p>Para luego operar con esos vectores.</p>
<p>Antes de continuar con el análisis , mostraremos dos paquetes útiles para presentar resultados de regresiones lineales. Tanto <code>stargazer</code>como<code>texreg</code>están diseñados para imprimir tablas de una manera elegante junto al cuerpo del texto que se desea publicar.</p>
<div class="sourceCode" id="cb99"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb99-1" data-line-number="1"><span class="kw">library</span>(stargazer)</a></code></pre></div>
% Table created by stargazer v.5.2.2 by Marek Hlavac, Harvard University. E-mail: hlavac at fas.harvard.edu
% Date and time: lun, ene 14, 2019 - 00:21:22

<div class="sourceCode" id="cb100"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb100-1" data-line-number="1"><span class="kw">library</span>(texreg)</a></code></pre></div>

</div>
<div id="representacion-grafica." class="section level3">
<h3><span class="header-section-number">8.3.2</span> Representación gráfica.</h3>
<p>Como vimos anteriormente, una de las maneras más fáciles de mostrar la relación entre dos variables es a través de gráficos. El paquete <code>ggplot2</code>es una herramienta de suma utilidad para realizar diverso tipo de representaciones. En el primer código se grafican todas las observaciones en función de sus valores de variable independiente y dependiente.</p>
<div class="sourceCode" id="cb101"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb101-1" data-line-number="1"><span class="kw">library</span> (ggplot2)</a></code></pre></div>
<div class="sourceCode" id="cb102"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb102-1" data-line-number="1"></a>
<a class="sourceLine" id="cb102-2" data-line-number="2"><span class="kw">ggplot</span>(<span class="dt">data =</span> basehys, <span class="co">#se especifica el origen de la base de datos</span></a>
<a class="sourceLine" id="cb102-3" data-line-number="3">       <span class="kw">aes</span>(<span class="dt">x =</span> cseduc, <span class="dt">y =</span> gini_slc))<span class="op">+</span><span class="st"> </span><span class="co">#se seleccionan las variables independiente y dependiente</span></a>
<a class="sourceLine" id="cb102-4" data-line-number="4"><span class="st">       </span><span class="kw">geom_point</span>() <span class="op">+</span><span class="st"> </span><span class="co">#se plotean los valores observados</span></a>
<a class="sourceLine" id="cb102-5" data-line-number="5"><span class="st">       </span><span class="kw">geom_smooth</span>(<span class="dt">method =</span> <span class="st">&quot;lm&quot;</span>, <span class="co"># se superpone la línea de regresión</span></a>
<a class="sourceLine" id="cb102-6" data-line-number="6">                   <span class="dt">se =</span> <span class="ot">FALSE</span>, <span class="co">#no se plotea el área de error al 95% de confianza</span></a>
<a class="sourceLine" id="cb102-7" data-line-number="7">                   <span class="dt">color =</span> <span class="st">&quot;blue&quot;</span>)<span class="op">+</span><span class="st"> </span><span class="co">#color de línea</span></a>
<a class="sourceLine" id="cb102-8" data-line-number="8"><span class="st">       </span><span class="kw">labs</span> (<span class="dt">x =</span> <span class="st">&quot;Gasto Educación&quot;) + # título del eje X</span></a>
<a class="sourceLine" id="cb102-9" data-line-number="9"><span class="st">       labs( y= &quot;</span>Desigualdad<span class="st">&quot;) + #título del eje Y</span></a>
<a class="sourceLine" id="cb102-10" data-line-number="10"><span class="st">       labs ( title =&quot;</span>Relación lineal entre Gasto Educación y Desigualdad<span class="st">&quot;) #título del gráfico</span></a>
<a class="sourceLine" id="cb102-11" data-line-number="11"><span class="st">## Warning: Removed 718 rows containing non-finite values (stat_smooth).</span></a>
<a class="sourceLine" id="cb102-12" data-line-number="12"><span class="st">## Warning: Removed 718 rows containing missing values (geom_point).</span></a></code></pre></div>
<p><img src="lineal_files/figure-html/unnamed-chunk-28-1.png" width="480" style="display: block; margin: auto;" /></p>
<p>Usualmente es útil mostrar también una representación gráfica del error de la predicción de la recta. <code>ggplot2</code>nos permite editar un área sombreada donde podrían haber estado los valores predichos con un determinado nivel de significancia. Si bien el 95% de confianza es el valor que viene por defecto, también podemos editar este valor.</p>
<p>El primer bloque muestra la línea de regresión y su error para un nivel de significancia estadística del 95%.</p>
<div class="sourceCode" id="cb103"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb103-1" data-line-number="1"></a>
<a class="sourceLine" id="cb103-2" data-line-number="2"></a>
<a class="sourceLine" id="cb103-3" data-line-number="3"><span class="kw">ggplot</span>(<span class="dt">data =</span> basehys, <span class="co">#se especifica el origen de la base de datos</span></a>
<a class="sourceLine" id="cb103-4" data-line-number="4">       <span class="kw">aes</span>(<span class="dt">x =</span> cseduc, <span class="dt">y =</span> gini_slc))<span class="op">+</span><span class="st"> </span></a>
<a class="sourceLine" id="cb103-5" data-line-number="5"><span class="st">       </span><span class="kw">geom_point</span>() <span class="op">+</span><span class="st"> </span></a>
<a class="sourceLine" id="cb103-6" data-line-number="6"><span class="st">       </span><span class="kw">geom_smooth</span>(<span class="dt">method =</span> <span class="st">&quot;lm&quot;</span>, </a>
<a class="sourceLine" id="cb103-7" data-line-number="7">                   <span class="dt">se =</span> T, <span class="co">#se agrega error de predicción</span></a>
<a class="sourceLine" id="cb103-8" data-line-number="8">                   <span class="dt">color =</span> <span class="st">&quot;blue&quot;</span>)<span class="op">+</span><span class="st"> </span></a>
<a class="sourceLine" id="cb103-9" data-line-number="9"><span class="st">       </span><span class="kw">labs</span> (<span class="dt">x =</span> <span class="st">&quot;Gasto Educación&quot;) +</span></a>
<a class="sourceLine" id="cb103-10" data-line-number="10"><span class="st">       labs( y= &quot;</span>Desigualdad<span class="st">&quot;) +</span></a>
<a class="sourceLine" id="cb103-11" data-line-number="11"><span class="st">       labs ( title =&quot;</span>Relación lineal entre Gasto Educación y Desigualdad<span class="st">&quot;) </span></a>
<a class="sourceLine" id="cb103-12" data-line-number="12"><span class="st">## Warning: Removed 718 rows containing non-finite values (stat_smooth).</span></a>
<a class="sourceLine" id="cb103-13" data-line-number="13"><span class="st">## Warning: Removed 718 rows containing missing values (geom_point).</span></a></code></pre></div>
<p><img src="lineal_files/figure-html/unnamed-chunk-29-1.png" width="480" style="display: block; margin: auto;" /></p>
<p>En este bloque de código se ha cambiado el nivel de significancia estadística al 99,9%</p>
<div class="sourceCode" id="cb104"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb104-1" data-line-number="1"></a>
<a class="sourceLine" id="cb104-2" data-line-number="2"><span class="kw">ggplot</span>(<span class="dt">data =</span> basehys, <span class="co">#se especifica el origen de la base de datos</span></a>
<a class="sourceLine" id="cb104-3" data-line-number="3">       <span class="kw">aes</span>(<span class="dt">x =</span> cseduc, <span class="dt">y =</span> gini_slc))<span class="op">+</span><span class="st"> </span></a>
<a class="sourceLine" id="cb104-4" data-line-number="4"><span class="st">       </span><span class="kw">geom_point</span>() <span class="op">+</span><span class="st"> </span></a>
<a class="sourceLine" id="cb104-5" data-line-number="5"><span class="st">       </span><span class="kw">geom_smooth</span>(<span class="dt">method =</span> <span class="st">&quot;lm&quot;</span>, </a>
<a class="sourceLine" id="cb104-6" data-line-number="6">                   <span class="dt">se =</span> T, <span class="co">#se agrega error de predicción</span></a>
<a class="sourceLine" id="cb104-7" data-line-number="7">                   <span class="dt">color =</span> <span class="st">&quot;blue&quot;</span>,</a>
<a class="sourceLine" id="cb104-8" data-line-number="8">                   <span class="dt">level =</span> <span class="fl">0.999</span>)<span class="op">+</span><span class="st"> </span><span class="co"># se modifica la incertidumbre de la predicción</span></a>
<a class="sourceLine" id="cb104-9" data-line-number="9"><span class="st">       </span><span class="kw">labs</span> (<span class="dt">x =</span> <span class="st">&quot;Gasto Educación&quot;) +</span></a>
<a class="sourceLine" id="cb104-10" data-line-number="10"><span class="st">       labs( y= &quot;</span>Desigualdad<span class="st">&quot;) +</span></a>
<a class="sourceLine" id="cb104-11" data-line-number="11"><span class="st">       labs ( title =&quot;</span>Relación lineal entre Gasto Educación y Desigualdad<span class="st">&quot;) </span></a>
<a class="sourceLine" id="cb104-12" data-line-number="12"><span class="st">## Warning: Removed 718 rows containing non-finite values (stat_smooth).</span></a>
<a class="sourceLine" id="cb104-13" data-line-number="13"><span class="st">## Warning: Removed 718 rows containing missing values (geom_point).</span></a></code></pre></div>
<p><img src="lineal_files/figure-html/unnamed-chunk-30-1.png" width="480" style="display: block; margin: auto;" /></p>
</div>
</div>
<div id="modelo-multivariado-regresion-multiple" class="section level2">
<h2><span class="header-section-number">8.4</span> Modelo multivariado: regresión múltiple</h2>
<p>Si bien suele interesar el efecto de una variable independiente sobre una dependiente, lo más común es estimar modelos en los que la <span class="math inline">\(Y\)</span> es resultado tanto de una variable independiente de interés como de un conjunto de variables de control. Formalmente,</p>
<p><span class="math display">\[Y= \beta_0+\beta_1x_{1}+\beta_1x_{2}+...+\beta_jx_{j}+u\]</span></p>
<p>A diferencia de la regresión simple, ahora la variable aleatoria <span class="math inline">\(Y\)</span> es una función de diversas variables más un término de error <span class="math inline">\(u\)</span>. Al igual que la regresión simple, la esperanza del error condicional en los valores de las <span class="math inline">\(x_j\)</span> debe ser igual a cero. Formalmente, <span class="math inline">\(E(u|x_1, x_2, ..., x_j)=0\)</span>.
Para estimar insesgadamente un modelo lineal múltiple no sólo se necesita el supuesto de media condicional cero, pero se presentarán todos los supuestos en una sección posterior.</p>
<p>Por el momento estimaremos un modelo poblacional en que la desigualdad social (gini_slc) es una función lineal del gasto en educación como porcentaje del PIB (cseduc), de la inversión extranjera directa (fdiingdp), del gasto en salud como porcentaje del PIB (cshlth), del gasto en Seguridad Social como porcentaje del PIB (csssw), de la población joven (pop014wdi), del dualismo estructural de la economía (s_dualism), de la división étnica (ethnicdicot), del PIB per cápita real (rgdpch), del tipo de régimen (demrss), del balance entre los poderes del Estado (legbal) y del autoritarismo (repressauthor).</p>
<p>Como se ve, se han incluido una multiplicidad de variables que se piensa que predicen la desigualdad (Huber et al, 2006). El análisis de regresión múltiple nos permitirá estimar hasta qué punto nuestro modelo es correcto.
En primer término se debe correr la estimación de MCO. La función <code>lm</code>también estima modelos múltiples y la única diferencia es que deben sumarse las variables independientes.</p>
<p>Antes de estimar el modelo, filtraremos la base de datos, eliminando todos los casos con valores perdidos (NA`s) en nuestras variables de control. Hay mejores formas de lidiar con los valores perdidos, para esto puedes revisar el capítulo #XX sobre Imputación de Valores Perdidos. Aquí, por practicidad, simplemente nos quedaremos con aquellos casos (país/año) que están completos para las variables de nuestro modelo:</p>
<div class="sourceCode" id="cb105"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb105-1" data-line-number="1">basehys_sinna&lt;-<span class="st"> </span>basehys <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">drop_na</span>(gini_slc, cseduc , fdiingdp , cshlth , csssw , pop014wdi, s_dualism , ethnicdicot , rgdpch ,  demrss, legbal ,  repressauthor)</a></code></pre></div>
<p>Ahora si estamos en condiciones de estimar el modelo 2:</p>
<div class="sourceCode" id="cb106"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb106-1" data-line-number="1">modelo_<span class="dv">2</span>&lt;-<span class="st"> </span><span class="kw">lm</span>(gini_slc<span class="op">~</span><span class="dv">1</span><span class="op">+</span><span class="st"> </span>cseduc <span class="op">+</span><span class="st"> </span>fdiingdp <span class="op">+</span><span class="st"> </span>cshlth <span class="op">+</span><span class="st"> </span>csssw <span class="op">+</span><span class="st"> </span>pop014wdi<span class="op">+</span><span class="st"> </span>s_dualism <span class="op">+</span><span class="st"> </span>ethnicdicot <span class="op">+</span><span class="st"> </span>rgdpch <span class="op">+</span><span class="st">  </span>demrss<span class="op">+</span><span class="st"> </span>legbal <span class="op">+</span><span class="st">  </span>repressauthor,<span class="dt">data =</span> basehys_sinna )</a></code></pre></div>
<p>Al igual que el modelo simple, podemos visualizar e imprimir los resultados de la estimación con <code>summary</code> , <code>mtable</code>, <code>stargazer</code>o <code>texreg</code>.</p>
<div class="sourceCode" id="cb107"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb107-1" data-line-number="1"><span class="kw">mtable</span>(modelo_<span class="dv">2</span>)</a>
<a class="sourceLine" id="cb107-2" data-line-number="2"><span class="co">## </span></a>
<a class="sourceLine" id="cb107-3" data-line-number="3"><span class="co">## Calls:</span></a>
<a class="sourceLine" id="cb107-4" data-line-number="4"><span class="co">## modelo_2: lm(formula = gini_slc ~ 1 + cseduc + fdiingdp + cshlth + csssw + </span></a>
<a class="sourceLine" id="cb107-5" data-line-number="5"><span class="co">##     pop014wdi + s_dualism + ethnicdicot + rgdpch + demrss + legbal + </span></a>
<a class="sourceLine" id="cb107-6" data-line-number="6"><span class="co">##     repressauthor, data = basehys_sinna)</span></a>
<a class="sourceLine" id="cb107-7" data-line-number="7"><span class="co">## </span></a>
<a class="sourceLine" id="cb107-8" data-line-number="8"><span class="co">## ==============================</span></a>
<a class="sourceLine" id="cb107-9" data-line-number="9"><span class="co">##   (Intercept)       89.27***  </span></a>
<a class="sourceLine" id="cb107-10" data-line-number="10"><span class="co">##                     (7.75)    </span></a>
<a class="sourceLine" id="cb107-11" data-line-number="11"><span class="co">##   cseduc             1.56***  </span></a>
<a class="sourceLine" id="cb107-12" data-line-number="12"><span class="co">##                     (0.44)    </span></a>
<a class="sourceLine" id="cb107-13" data-line-number="13"><span class="co">##   fdiingdp           0.24     </span></a>
<a class="sourceLine" id="cb107-14" data-line-number="14"><span class="co">##                     (0.18)    </span></a>
<a class="sourceLine" id="cb107-15" data-line-number="15"><span class="co">##   cshlth            -0.83**   </span></a>
<a class="sourceLine" id="cb107-16" data-line-number="16"><span class="co">##                     (0.26)    </span></a>
<a class="sourceLine" id="cb107-17" data-line-number="17"><span class="co">##   csssw             -0.83***  </span></a>
<a class="sourceLine" id="cb107-18" data-line-number="18"><span class="co">##                     (0.20)    </span></a>
<a class="sourceLine" id="cb107-19" data-line-number="19"><span class="co">##   pop014wdi         -0.93***  </span></a>
<a class="sourceLine" id="cb107-20" data-line-number="20"><span class="co">##                     (0.17)    </span></a>
<a class="sourceLine" id="cb107-21" data-line-number="21"><span class="co">##   s_dualism         -0.17***  </span></a>
<a class="sourceLine" id="cb107-22" data-line-number="22"><span class="co">##                     (0.03)    </span></a>
<a class="sourceLine" id="cb107-23" data-line-number="23"><span class="co">##   ethnicdicot        3.72***  </span></a>
<a class="sourceLine" id="cb107-24" data-line-number="24"><span class="co">##                     (1.03)    </span></a>
<a class="sourceLine" id="cb107-25" data-line-number="25"><span class="co">##   rgdpch            -0.00**   </span></a>
<a class="sourceLine" id="cb107-26" data-line-number="26"><span class="co">##                     (0.00)    </span></a>
<a class="sourceLine" id="cb107-27" data-line-number="27"><span class="co">##   demrss            -2.07*    </span></a>
<a class="sourceLine" id="cb107-28" data-line-number="28"><span class="co">##                     (0.89)    </span></a>
<a class="sourceLine" id="cb107-29" data-line-number="29"><span class="co">##   legbal           -10.52***  </span></a>
<a class="sourceLine" id="cb107-30" data-line-number="30"><span class="co">##                     (2.17)    </span></a>
<a class="sourceLine" id="cb107-31" data-line-number="31"><span class="co">##   repressauthor     -1.34     </span></a>
<a class="sourceLine" id="cb107-32" data-line-number="32"><span class="co">##                     (1.96)    </span></a>
<a class="sourceLine" id="cb107-33" data-line-number="33"><span class="co">## ------------------------------</span></a>
<a class="sourceLine" id="cb107-34" data-line-number="34"><span class="co">##   R-squared          0.59     </span></a>
<a class="sourceLine" id="cb107-35" data-line-number="35"><span class="co">##   adj. R-squared     0.56     </span></a>
<a class="sourceLine" id="cb107-36" data-line-number="36"><span class="co">##   sigma              4.51     </span></a>
<a class="sourceLine" id="cb107-37" data-line-number="37"><span class="co">##   F                 20.40     </span></a>
<a class="sourceLine" id="cb107-38" data-line-number="38"><span class="co">##   p                  0.00     </span></a>
<a class="sourceLine" id="cb107-39" data-line-number="39"><span class="co">##   Log-likelihood  -482.22     </span></a>
<a class="sourceLine" id="cb107-40" data-line-number="40"><span class="co">##   Deviance        3150.06     </span></a>
<a class="sourceLine" id="cb107-41" data-line-number="41"><span class="co">##   AIC              990.43     </span></a>
<a class="sourceLine" id="cb107-42" data-line-number="42"><span class="co">##   BIC             1030.97     </span></a>
<a class="sourceLine" id="cb107-43" data-line-number="43"><span class="co">##   N                167        </span></a>
<a class="sourceLine" id="cb107-44" data-line-number="44"><span class="co">## ==============================</span></a></code></pre></div>
<p>Estas funciones también nos permiten comparar dos o más modelos. Al momento de presentar una investigación suele ser recomendable mostrar cómo cambian (o no) los resultados ante distintas especificaciones. En el caso que se trabaja aquí la comparación de modelos es</p>
<div class="sourceCode" id="cb108"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb108-1" data-line-number="1"><span class="kw">mtable</span>( modelo_<span class="dv">1</span>, modelo_<span class="dv">2</span>)</a>
<a class="sourceLine" id="cb108-2" data-line-number="2"><span class="co">## </span></a>
<a class="sourceLine" id="cb108-3" data-line-number="3"><span class="co">## Calls:</span></a>
<a class="sourceLine" id="cb108-4" data-line-number="4"><span class="co">## modelo_1: lm(formula = gini_slc ~ 1 + cseduc, data = basehys)</span></a>
<a class="sourceLine" id="cb108-5" data-line-number="5"><span class="co">## modelo_2: lm(formula = gini_slc ~ 1 + cseduc + fdiingdp + cshlth + csssw + </span></a>
<a class="sourceLine" id="cb108-6" data-line-number="6"><span class="co">##     pop014wdi + s_dualism + ethnicdicot + rgdpch + demrss + legbal + </span></a>
<a class="sourceLine" id="cb108-7" data-line-number="7"><span class="co">##     repressauthor, data = basehys_sinna)</span></a>
<a class="sourceLine" id="cb108-8" data-line-number="8"><span class="co">## </span></a>
<a class="sourceLine" id="cb108-9" data-line-number="9"><span class="co">## ===========================================</span></a>
<a class="sourceLine" id="cb108-10" data-line-number="10"><span class="co">##                    modelo_1     modelo_2   </span></a>
<a class="sourceLine" id="cb108-11" data-line-number="11"><span class="co">## -------------------------------------------</span></a>
<a class="sourceLine" id="cb108-12" data-line-number="12"><span class="co">##   (Intercept)        44.81***    89.27***  </span></a>
<a class="sourceLine" id="cb108-13" data-line-number="13"><span class="co">##                      (1.02)      (7.75)    </span></a>
<a class="sourceLine" id="cb108-14" data-line-number="14"><span class="co">##   cseduc              1.23***     1.56***  </span></a>
<a class="sourceLine" id="cb108-15" data-line-number="15"><span class="co">##                      (0.25)      (0.44)    </span></a>
<a class="sourceLine" id="cb108-16" data-line-number="16"><span class="co">##   fdiingdp                        0.24     </span></a>
<a class="sourceLine" id="cb108-17" data-line-number="17"><span class="co">##                                  (0.18)    </span></a>
<a class="sourceLine" id="cb108-18" data-line-number="18"><span class="co">##   cshlth                         -0.83**   </span></a>
<a class="sourceLine" id="cb108-19" data-line-number="19"><span class="co">##                                  (0.26)    </span></a>
<a class="sourceLine" id="cb108-20" data-line-number="20"><span class="co">##   csssw                          -0.83***  </span></a>
<a class="sourceLine" id="cb108-21" data-line-number="21"><span class="co">##                                  (0.20)    </span></a>
<a class="sourceLine" id="cb108-22" data-line-number="22"><span class="co">##   pop014wdi                      -0.93***  </span></a>
<a class="sourceLine" id="cb108-23" data-line-number="23"><span class="co">##                                  (0.17)    </span></a>
<a class="sourceLine" id="cb108-24" data-line-number="24"><span class="co">##   s_dualism                      -0.17***  </span></a>
<a class="sourceLine" id="cb108-25" data-line-number="25"><span class="co">##                                  (0.03)    </span></a>
<a class="sourceLine" id="cb108-26" data-line-number="26"><span class="co">##   ethnicdicot                     3.72***  </span></a>
<a class="sourceLine" id="cb108-27" data-line-number="27"><span class="co">##                                  (1.03)    </span></a>
<a class="sourceLine" id="cb108-28" data-line-number="28"><span class="co">##   rgdpch                         -0.00**   </span></a>
<a class="sourceLine" id="cb108-29" data-line-number="29"><span class="co">##                                  (0.00)    </span></a>
<a class="sourceLine" id="cb108-30" data-line-number="30"><span class="co">##   demrss                         -2.07*    </span></a>
<a class="sourceLine" id="cb108-31" data-line-number="31"><span class="co">##                                  (0.89)    </span></a>
<a class="sourceLine" id="cb108-32" data-line-number="32"><span class="co">##   legbal                        -10.52***  </span></a>
<a class="sourceLine" id="cb108-33" data-line-number="33"><span class="co">##                                  (2.17)    </span></a>
<a class="sourceLine" id="cb108-34" data-line-number="34"><span class="co">##   repressauthor                  -1.34     </span></a>
<a class="sourceLine" id="cb108-35" data-line-number="35"><span class="co">##                                  (1.96)    </span></a>
<a class="sourceLine" id="cb108-36" data-line-number="36"><span class="co">## -------------------------------------------</span></a>
<a class="sourceLine" id="cb108-37" data-line-number="37"><span class="co">##   R-squared           0.06        0.59     </span></a>
<a class="sourceLine" id="cb108-38" data-line-number="38"><span class="co">##   adj. R-squared      0.06        0.56     </span></a>
<a class="sourceLine" id="cb108-39" data-line-number="39"><span class="co">##   sigma               6.70        4.51     </span></a>
<a class="sourceLine" id="cb108-40" data-line-number="40"><span class="co">##   F                  24.27       20.40     </span></a>
<a class="sourceLine" id="cb108-41" data-line-number="41"><span class="co">##   p                   0.00        0.00     </span></a>
<a class="sourceLine" id="cb108-42" data-line-number="42"><span class="co">##   Log-likelihood  -1181.47     -482.22     </span></a>
<a class="sourceLine" id="cb108-43" data-line-number="43"><span class="co">##   Deviance        15907.25     3150.06     </span></a>
<a class="sourceLine" id="cb108-44" data-line-number="44"><span class="co">##   AIC              2368.94      990.43     </span></a>
<a class="sourceLine" id="cb108-45" data-line-number="45"><span class="co">##   BIC              2380.57     1030.97     </span></a>
<a class="sourceLine" id="cb108-46" data-line-number="46"><span class="co">##   N                 356         167        </span></a>
<a class="sourceLine" id="cb108-47" data-line-number="47"><span class="co">## ===========================================</span></a></code></pre></div>
<p>Como se observa, la estimación puntual del efecto del Gasto en Educación cambió ligeramente. Mientras en el modelo simple el efecto es de 1,23 en el modelo múltiple este efecto pasa a 1,56. En este caso, la interpretación es que cuando el gasto en educación aumenta en una unidad, la desigualdad aumenta en promedio 1,56 puntos porcentuales <em>manteniendo todos los demás factores constantes</em>. Esto es, una vez que se descuenta el efecto de las variables de control.</p>
<p>Al igual que en el modelo 1, la variable sigue siendo significativa al 99,9% de confianza por lo que decimos que el efecto del Gasto en Educación es <em>robusto</em> a diferentes especificaciones. Cuando los investigadores incluyen nuevos controles al modelo y la principal variable de interés se mantiene significativa y con magnitudes relativamente estables se gana evidencia a favor del efecto de la misma. En otras palabras, cada vez es menos probable que el efecto observado en primera instancia fuese espurio.</p>
<p>Otra de las contribuciones del modelo 2 es la incorporación de variables nominales. Las variables dicotómicas y las categóricas plantean un ligero desafío de interpretación. Obsérvese la variable Diversidad Étnica que es dicotómica donde el valor 1 implica que más del 20% de la población pertenece a una minoría étnica y 0 si no hay una minoría tan relevante. El coeficiente de “ethicdicot” es 3,7 significativo al 99,9%. ¿Cómo interpretarlo? Sencillamente, el valor predicho de la desigualdad es 3.7 puntos mayor cuando existe una minoría étnica, a cualquier valor de las otras <span class="math inline">\(x&#39;s\)</span>. Para interpretar estos coeficientes siempre debe conocerse la categoría base. Como ethicdicot es igual a 0 cuando no hay minorías étnicas, el coeficiente se interpreta como el pasaje hacia tener minoría étnica.</p>
<p>En el caso de la variable s_dualism, dado que la categoría base es 0 para “sin dualismo”, el coeficiente se interpreta tal que tener una economía dual <em>disminuye</em> (coeficiente negativo) la desigualdad en aproximadamente 0.17 puntos.</p>
<p>Se puede observar gráficamente la incidencia de las variables dicotómicas utilizando <code>plot_model</code> del paquete <code>sjPlot</code></p>
<div class="sourceCode" id="cb109"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb109-1" data-line-number="1"><span class="kw">library</span>(sjPlot)</a>
<a class="sourceLine" id="cb109-2" data-line-number="2"><span class="co">## Warning in checkMatrixPackageVersion(): Package version inconsistency detected.</span></a>
<a class="sourceLine" id="cb109-3" data-line-number="3"><span class="co">## TMB was built with Matrix version 1.2.14</span></a>
<a class="sourceLine" id="cb109-4" data-line-number="4"><span class="co">## Current Matrix version is 1.2.15</span></a>
<a class="sourceLine" id="cb109-5" data-line-number="5"><span class="co">## Please re-install &#39;TMB&#39; from source using install.packages(&#39;TMB&#39;, type = &#39;source&#39;) or ask CRAN for a binary version of &#39;TMB&#39; matching CRAN&#39;s &#39;Matrix&#39; package</span></a></code></pre></div>
<p>En la gráfica que sigue se muestra el efecto del gasto en educación sobre la desigualdad para las distintas categorías de Diversidad Étnica, manteniendo todas las demás variables constantes. Se aprecia claramente que lo único que cambia entre las categorías es el intercepto. Los países que tienen una minoría étnica importante tienen aproximadamente 3,7 puntos más de desigualdad que los que no tienen minorías étnicas, a cualquier valor de gasto en educación, manteniendo todas las demás variables constantes.</p>
<div class="sourceCode" id="cb110"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb110-1" data-line-number="1"><span class="kw">plot_model</span>(<span class="dt">model =</span> modelo_<span class="dv">2</span>, </a>
<a class="sourceLine" id="cb110-2" data-line-number="2">        <span class="dt">type =</span> <span class="st">&quot;pred&quot;</span>,</a>
<a class="sourceLine" id="cb110-3" data-line-number="3">        <span class="dt">terms =</span>   <span class="kw">c</span>(<span class="st">&quot;cseduc&quot;</span>,  <span class="st">&quot;ethnicdicot&quot;</span>), </a>
<a class="sourceLine" id="cb110-4" data-line-number="4">        <span class="dt">facet.grid =</span> F,</a>
<a class="sourceLine" id="cb110-5" data-line-number="5">            <span class="dt">show.ci =</span> T, </a>
<a class="sourceLine" id="cb110-6" data-line-number="6">        <span class="dt">title =</span> <span class="st">&quot;Valores predichos de Desigualdad según Gasto en Educación y Minoría Étnica (dicotómica&quot;)</span></a></code></pre></div>
<p><img src="lineal_files/figure-html/unnamed-chunk-36-1.png" width="480" style="display: block; margin: auto;" /></p>
<div id="ajuste-del-modelo" class="section level3">
<h3><span class="header-section-number">8.4.1</span> Ajuste del modelo</h3>
<p>La bondad de ajuste se define como la capacidad explicativa del modelo. Intuitivamente refiere a qué porción de la variación de la variable dependiente <span class="math inline">\(y\)</span> es explicada por el modelo especificado. La medida de la bondad de ajuste es el <span class="math inline">\(R^2\)</span> y se define como 1- SRC/STC, donde SRC es la Suma de los Residuos al Cuadrado y STC la Suma de los Totales Cuadrados. De manera simple SRC es una medida de todo lo que el modelo <em>no</em> explica, mientras que STC es la variabilidad de la <span class="math inline">\(y\)</span>.
Un modelo que explique <em>toda</em> la variación de <span class="math inline">\(y\)</span> tendrá un <span class="math inline">\(R^2\)</span> de 1. Un modelo que no explique nada de la variabilidad de la variable dependiente tendrá un valor de 0.</p>
<p>Por regla general, a medida que se aumenta el número de variables independientes el <span class="math inline">\(R^2\)</span> nunca disminuye por lo que se suele utilizar el <span class="math inline">\(R^2\)</span> ajustado como una medida que penaliza la inclusión de variables sin fundamento.
Como se puede observar en la comparación de los modelos estimados previamente, el modelo lineal simple tiene un <span class="math inline">\(R^2\)</span> de 0.06. Eso puede leerse como que el modelo 1 explica el 6% de la variabilidad de la desigualdad. El modelo múltiple 2 aumenta su capacidad explicativa al 56%.</p>
<div class="sourceCode" id="cb111"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb111-1" data-line-number="1"><span class="kw">mtable</span>(modelo_<span class="dv">1</span>, modelo_<span class="dv">2</span>)</a>
<a class="sourceLine" id="cb111-2" data-line-number="2"><span class="co">## </span></a>
<a class="sourceLine" id="cb111-3" data-line-number="3"><span class="co">## Calls:</span></a>
<a class="sourceLine" id="cb111-4" data-line-number="4"><span class="co">## modelo_1: lm(formula = gini_slc ~ 1 + cseduc, data = basehys)</span></a>
<a class="sourceLine" id="cb111-5" data-line-number="5"><span class="co">## modelo_2: lm(formula = gini_slc ~ 1 + cseduc + fdiingdp + cshlth + csssw + </span></a>
<a class="sourceLine" id="cb111-6" data-line-number="6"><span class="co">##     pop014wdi + s_dualism + ethnicdicot + rgdpch + demrss + legbal + </span></a>
<a class="sourceLine" id="cb111-7" data-line-number="7"><span class="co">##     repressauthor, data = basehys_sinna)</span></a>
<a class="sourceLine" id="cb111-8" data-line-number="8"><span class="co">## </span></a>
<a class="sourceLine" id="cb111-9" data-line-number="9"><span class="co">## ===========================================</span></a>
<a class="sourceLine" id="cb111-10" data-line-number="10"><span class="co">##                    modelo_1     modelo_2   </span></a>
<a class="sourceLine" id="cb111-11" data-line-number="11"><span class="co">## -------------------------------------------</span></a>
<a class="sourceLine" id="cb111-12" data-line-number="12"><span class="co">##   (Intercept)        44.81***    89.27***  </span></a>
<a class="sourceLine" id="cb111-13" data-line-number="13"><span class="co">##                      (1.02)      (7.75)    </span></a>
<a class="sourceLine" id="cb111-14" data-line-number="14"><span class="co">##   cseduc              1.23***     1.56***  </span></a>
<a class="sourceLine" id="cb111-15" data-line-number="15"><span class="co">##                      (0.25)      (0.44)    </span></a>
<a class="sourceLine" id="cb111-16" data-line-number="16"><span class="co">##   fdiingdp                        0.24     </span></a>
<a class="sourceLine" id="cb111-17" data-line-number="17"><span class="co">##                                  (0.18)    </span></a>
<a class="sourceLine" id="cb111-18" data-line-number="18"><span class="co">##   cshlth                         -0.83**   </span></a>
<a class="sourceLine" id="cb111-19" data-line-number="19"><span class="co">##                                  (0.26)    </span></a>
<a class="sourceLine" id="cb111-20" data-line-number="20"><span class="co">##   csssw                          -0.83***  </span></a>
<a class="sourceLine" id="cb111-21" data-line-number="21"><span class="co">##                                  (0.20)    </span></a>
<a class="sourceLine" id="cb111-22" data-line-number="22"><span class="co">##   pop014wdi                      -0.93***  </span></a>
<a class="sourceLine" id="cb111-23" data-line-number="23"><span class="co">##                                  (0.17)    </span></a>
<a class="sourceLine" id="cb111-24" data-line-number="24"><span class="co">##   s_dualism                      -0.17***  </span></a>
<a class="sourceLine" id="cb111-25" data-line-number="25"><span class="co">##                                  (0.03)    </span></a>
<a class="sourceLine" id="cb111-26" data-line-number="26"><span class="co">##   ethnicdicot                     3.72***  </span></a>
<a class="sourceLine" id="cb111-27" data-line-number="27"><span class="co">##                                  (1.03)    </span></a>
<a class="sourceLine" id="cb111-28" data-line-number="28"><span class="co">##   rgdpch                         -0.00**   </span></a>
<a class="sourceLine" id="cb111-29" data-line-number="29"><span class="co">##                                  (0.00)    </span></a>
<a class="sourceLine" id="cb111-30" data-line-number="30"><span class="co">##   demrss                         -2.07*    </span></a>
<a class="sourceLine" id="cb111-31" data-line-number="31"><span class="co">##                                  (0.89)    </span></a>
<a class="sourceLine" id="cb111-32" data-line-number="32"><span class="co">##   legbal                        -10.52***  </span></a>
<a class="sourceLine" id="cb111-33" data-line-number="33"><span class="co">##                                  (2.17)    </span></a>
<a class="sourceLine" id="cb111-34" data-line-number="34"><span class="co">##   repressauthor                  -1.34     </span></a>
<a class="sourceLine" id="cb111-35" data-line-number="35"><span class="co">##                                  (1.96)    </span></a>
<a class="sourceLine" id="cb111-36" data-line-number="36"><span class="co">## -------------------------------------------</span></a>
<a class="sourceLine" id="cb111-37" data-line-number="37"><span class="co">##   R-squared           0.06        0.59     </span></a>
<a class="sourceLine" id="cb111-38" data-line-number="38"><span class="co">##   adj. R-squared      0.06        0.56     </span></a>
<a class="sourceLine" id="cb111-39" data-line-number="39"><span class="co">##   sigma               6.70        4.51     </span></a>
<a class="sourceLine" id="cb111-40" data-line-number="40"><span class="co">##   F                  24.27       20.40     </span></a>
<a class="sourceLine" id="cb111-41" data-line-number="41"><span class="co">##   p                   0.00        0.00     </span></a>
<a class="sourceLine" id="cb111-42" data-line-number="42"><span class="co">##   Log-likelihood  -1181.47     -482.22     </span></a>
<a class="sourceLine" id="cb111-43" data-line-number="43"><span class="co">##   Deviance        15907.25     3150.06     </span></a>
<a class="sourceLine" id="cb111-44" data-line-number="44"><span class="co">##   AIC              2368.94      990.43     </span></a>
<a class="sourceLine" id="cb111-45" data-line-number="45"><span class="co">##   BIC              2380.57     1030.97     </span></a>
<a class="sourceLine" id="cb111-46" data-line-number="46"><span class="co">##   N                 356         167        </span></a>
<a class="sourceLine" id="cb111-47" data-line-number="47"><span class="co">## ===========================================</span></a></code></pre></div>
<p>Algunos investigadores buscan aumentar la bondad de ajuste del modelo. Sin embargo, estimar el efecto de una variable en concreto no requiere aumentar la bondad de ajuste sino simplemente que se cumplan los supuestos del Modelo Lineal Clásico como la media condicional 0, la linealidad de los parámentros y demás supuestos que se describen en la sección correspondiente.</p>
</div>
<div id="inferencia-en-modelos-lineales-multiples" class="section level3">
<h3><span class="header-section-number">8.4.2</span> Inferencia en modelos lineales múltiples</h3>
<p>Al igual que en la regresión lineal simple, los estimadores de cada uno de los parámentros <span class="math inline">\(\beta_j\)</span> tienen una distribución t-Student por lo que puede realizarse inferencia acerca de las estimaciones puntuales de cada <span class="math inline">\(\hat{\beta_j}\)</span> a través de una prueba t.</p>
<p>Sin embargo, a veces se desea imponer restricciones lineales múltiples al modelo del tipo <span class="math inline">\(H_0= \beta_1= \beta_2 = 0\)</span>. Aquí se está sosteniendo que el efecto de dos variables <span class="math inline">\(x_1\)</span> y <span class="math inline">\(x_2\)</span> es igual a cero. Un caso típico que requiere este tipo de hipótesis nula refiere a las variables categóricas que ingresan al modelo como variables dicotómicas ficticias. La variable dicotómica “educación media” y la dicotómica “educación superior” son en realidad categorías de una única variable nominal “nivel educativo” que sólo puede entrar en un análisis de regresión en la forma de <em>dummies</em> ficticias.</p>
<p>La prueba que permite hacer inferencia para restricción lineal múltiple es la prueba F. Esto implica que la <span class="math inline">\(H_0\)</span> de una restricción múltiple distribuye F de Fisher.</p>
<p>Aquí se muestran dos maneras de testear una restricción lineal múltiple. La primera muestra cada uno de los pasos del test mientras que la segunda es más breve.</p>
<p>Supongamos que se quiere testear la hipótesis nula que $H_0= _1= _2 = _3 =0 $. Según esta hipótesis las variables <span class="math inline">\(x_1\)</span>, <span class="math inline">\(x_2\)</span> y <span class="math inline">\(x_3\)</span> no afectan a <span class="math inline">\(Y\)</span> cuando se las considera en conjunto. La hipótesis alternativa es que al menos uno de los betas es distinto de 0. Si <span class="math inline">\(H_0\)</span> es verdadera entonces un modelo que excluya estas variables debería explicar lo mismo que un modelo que las incluya, o sea, estas variables son redundantes.
La manera de testear esta hipótesis es a través de un test F en el que se compara la suma de los residuos cuadrados del modelo completo y el modelo restringido. En términos simples, si las variables deben ser excluidas porque no explican la variabilidad de <span class="math inline">\(y\)</span> la Suma de los Residuos Cuadrados de ambos modelos (otra manera es ver el <span class="math inline">\(R^2\)</span>) no debe cambiar significativamente.</p>
<p>Se utiliza el hecho que la comparación de los residuos cuadrados distribuye F</p>
<p><span class="math display">\[F= \frac{(SRC_r-SRC_c)/q}{SRC_c/(n-k-1)}\]</span></p>
<p>Donde <span class="math inline">\(SRC_r\)</span> es la Suma de los Residuos Cuadrados del modelo restringido, <span class="math inline">\(SRC_c\)</span> es la Suma de los Residuos Cuadrados del modelo completo, <span class="math inline">\(q\)</span> es la cantidad de variables excluidas y <span class="math inline">\(n-k-1\)</span> son los grados de libertad del modelo completo.</p>
<p>En R se puede utilizar la función <code>anova</code> para comparar los modelos.
Por ejemplo, supongamos que un colega asegura que el balance del legislativo (legbal), el tipo de régimen (demrss) y la diversidad étnica (ethnicdicot) deben excluirse del modelo. Entonces debemos estimar un modelo restringido tal que</p>
<div class="sourceCode" id="cb112"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb112-1" data-line-number="1">modelo_<span class="dv">2</span>_restringido&lt;-<span class="st"> </span><span class="kw">lm</span>(gini_slc<span class="op">~</span><span class="dv">1</span><span class="op">+</span><span class="st"> </span>cseduc <span class="op">+</span><span class="st"> </span>fdiingdp <span class="op">+</span><span class="st"> </span>cshlth <span class="op">+</span><span class="st"> </span>csssw <span class="op">+</span><span class="st"> </span>pop014wdi<span class="op">+</span><span class="st"> </span>s_dualism  <span class="op">+</span><span class="st"> </span>rgdpch <span class="op">+</span><span class="st">  </span>repressauthor,<span class="dt">data =</span> basehys_sinna)</a></code></pre></div>
<p>Como se ve, las variables mencionadas fueron excluidas de la sintaxis.
Ahora se debe comparar el poder explicativo de cada modelo</p>
<div class="sourceCode" id="cb113"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb113-1" data-line-number="1"><span class="kw">anova</span>( modelo_<span class="dv">2</span>, modelo_<span class="dv">2</span>_restringido)</a>
<a class="sourceLine" id="cb113-2" data-line-number="2"><span class="co">## Analysis of Variance Table</span></a>
<a class="sourceLine" id="cb113-3" data-line-number="3"><span class="co">## </span></a>
<a class="sourceLine" id="cb113-4" data-line-number="4"><span class="co">## Model 1: gini_slc ~ 1 + cseduc + fdiingdp + cshlth + csssw + pop014wdi + </span></a>
<a class="sourceLine" id="cb113-5" data-line-number="5"><span class="co">##     s_dualism + ethnicdicot + rgdpch + demrss + legbal + repressauthor</span></a>
<a class="sourceLine" id="cb113-6" data-line-number="6"><span class="co">## Model 2: gini_slc ~ 1 + cseduc + fdiingdp + cshlth + csssw + pop014wdi + </span></a>
<a class="sourceLine" id="cb113-7" data-line-number="7"><span class="co">##     s_dualism + rgdpch + repressauthor</span></a>
<a class="sourceLine" id="cb113-8" data-line-number="8"><span class="co">##   Res.Df  RSS Df Sum of Sq    F  Pr(&gt;F)    </span></a>
<a class="sourceLine" id="cb113-9" data-line-number="9"><span class="co">## 1    155 3150                              </span></a>
<a class="sourceLine" id="cb113-10" data-line-number="10"><span class="co">##  [ reached getOption(&quot;max.print&quot;) -- omitted 1 row ]</span></a>
<a class="sourceLine" id="cb113-11" data-line-number="11"><span class="co">## ---</span></a>
<a class="sourceLine" id="cb113-12" data-line-number="12"><span class="co">## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</span></a></code></pre></div>
<p>La significancia de la última columna del test muestra con claridad que se rechaza la hipótesis nula por lo que esas variables <em>no</em> deben excluirse del modelo.</p>
<p>Otra manera de realizar un test de restricción múltiple es con la función <code>linearHypothesis</code> del paquete <code>car</code></p>
<div class="sourceCode" id="cb114"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb114-1" data-line-number="1"><span class="kw">library</span>(car)</a>
<a class="sourceLine" id="cb114-2" data-line-number="2"><span class="co">## Loading required package: carData</span></a>
<a class="sourceLine" id="cb114-3" data-line-number="3"><span class="co">## </span></a>
<a class="sourceLine" id="cb114-4" data-line-number="4"><span class="co">## Attaching package: &#39;car&#39;</span></a>
<a class="sourceLine" id="cb114-5" data-line-number="5"><span class="co">## The following object is masked from &#39;package:memisc&#39;:</span></a>
<a class="sourceLine" id="cb114-6" data-line-number="6"><span class="co">## </span></a>
<a class="sourceLine" id="cb114-7" data-line-number="7"><span class="co">##     recode</span></a>
<a class="sourceLine" id="cb114-8" data-line-number="8"><span class="co">## The following object is masked from &#39;package:dplyr&#39;:</span></a>
<a class="sourceLine" id="cb114-9" data-line-number="9"><span class="co">## </span></a>
<a class="sourceLine" id="cb114-10" data-line-number="10"><span class="co">##     recode</span></a>
<a class="sourceLine" id="cb114-11" data-line-number="11"><span class="co">## The following object is masked from &#39;package:purrr&#39;:</span></a>
<a class="sourceLine" id="cb114-12" data-line-number="12"><span class="co">## </span></a>
<a class="sourceLine" id="cb114-13" data-line-number="13"><span class="co">##     some</span></a></code></pre></div>
<div class="sourceCode" id="cb115"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb115-1" data-line-number="1"></a>
<a class="sourceLine" id="cb115-2" data-line-number="2"><span class="kw">linearHypothesis</span>(modelo_<span class="dv">2</span>, <span class="kw">c</span>(<span class="st">&quot;legbal=0&quot;</span>, <span class="st">&quot;demrss=0&quot;</span>, <span class="st">&quot;ethnicdicot=0&quot;</span>), <span class="dt">test =</span> <span class="st">&quot;F&quot;</span>,</a>
<a class="sourceLine" id="cb115-3" data-line-number="3">                  <span class="dt">cov. =</span> <span class="kw">vcovHC</span>(modelo_<span class="dv">2</span>, <span class="dt">method=</span><span class="st">&quot;arellano&quot;</span>, <span class="dt">type =</span> <span class="st">&quot;HC1&quot;</span>))</a>
<a class="sourceLine" id="cb115-4" data-line-number="4"><span class="co">## Linear hypothesis test</span></a>
<a class="sourceLine" id="cb115-5" data-line-number="5"><span class="co">## </span></a>
<a class="sourceLine" id="cb115-6" data-line-number="6"><span class="co">## Hypothesis:</span></a>
<a class="sourceLine" id="cb115-7" data-line-number="7"><span class="co">## legbal = 0</span></a>
<a class="sourceLine" id="cb115-8" data-line-number="8"><span class="co">## demrss = 0</span></a>
<a class="sourceLine" id="cb115-9" data-line-number="9"><span class="co">## ethnicdicot = 0</span></a>
<a class="sourceLine" id="cb115-10" data-line-number="10"><span class="co">## </span></a>
<a class="sourceLine" id="cb115-11" data-line-number="11"><span class="co">## Model 1: restricted model</span></a>
<a class="sourceLine" id="cb115-12" data-line-number="12"><span class="co">## Model 2: gini_slc ~ 1 + cseduc + fdiingdp + cshlth + csssw + pop014wdi + </span></a>
<a class="sourceLine" id="cb115-13" data-line-number="13"><span class="co">##     s_dualism + ethnicdicot + rgdpch + demrss + legbal + repressauthor</span></a>
<a class="sourceLine" id="cb115-14" data-line-number="14"><span class="co">## </span></a>
<a class="sourceLine" id="cb115-15" data-line-number="15"><span class="co">##   Res.Df  RSS Df Sum of Sq    F  Pr(&gt;F)    </span></a>
<a class="sourceLine" id="cb115-16" data-line-number="16"><span class="co">## 1    158 4728                              </span></a>
<a class="sourceLine" id="cb115-17" data-line-number="17"><span class="co">##  [ reached getOption(&quot;max.print&quot;) -- omitted 1 row ]</span></a>
<a class="sourceLine" id="cb115-18" data-line-number="18"><span class="co">## ---</span></a>
<a class="sourceLine" id="cb115-19" data-line-number="19"><span class="co">## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</span></a></code></pre></div>
<p>Al igual que con el comando anova, se rechaza la hipótesis nula en que los coeficientes son iguales a cero y por tanto, se mantienen las variables en el modelo.</p>
</div>
<div id="supuestos-de-ols" class="section level3">
<h3><span class="header-section-number">8.4.3</span> Supuestos de OLS</h3>
<p>El estimador de Mínimos Cuadrados Ordinarios será de utilidad (estimará insesgadamente el parámetro poblacional) si es que se cumplen los supuestos de Gauss-Markov que permiten que sea el Mejor Estimador Lineal Insesgado (MELI o BLUE por sus siglas en inglés). Para profundizar sobre los supuestos es recomendable consultar: Wooldrige,2006;Stock y Watson, 2012; Monogan III, 2015.</p>
<p>Por tanto, es importante evaluar que en nuestra estimación se estén cumpliendo estos supuestos. Como veremos a continuación, esta evaluación es teórica y, en algunos casos, se podrá aproximar empíricamente.</p>
<div id="media-condicional-cero" class="section level4">
<h4><span class="header-section-number">8.4.3.1</span> 1. Media condicional cero</h4>
<p>El supuesto central para utilizar el estimador de MCO. El postulado crucial de este supuesto es la independencia entre las variables indpendientes y el término de error, esto nos permite aislar de los factores no observables (contenidos en el término de error <span class="math inline">\(u\)</span>) el efecto de las <span class="math inline">\(x\)</span>.
Este supuesto no puede ser evaluado empíricamente porque, por definición, no conocemos los factores contenidos en el término de error. Por lo tanto, la defensa de este supuesto siempre será <em>teórica</em>.</p>
</div>
<div id="muestreo-aleatorio" class="section level4">
<h4><span class="header-section-number">8.4.3.2</span> 2. Muestreo aleatorio</h4>
<p>Este es un supuesto sobre la generación de los datos. Se asume un muestreo aleatorio de tamaño <span class="math inline">\(n\)</span> que implica que la muestra fue tomada de forma tal que todas las unidades poblacionales tuvieron la misma probabilidad de ser seleccionadas. Es decir, no hay un sesgo de selección muestral.</p>
</div>
<div id="linealidad-en-los-parametros" class="section level4">
<h4><span class="header-section-number">8.4.3.3</span> 3. Linealidad en los Parámetros</h4>
<p>MCO asume que la variable dependiente (<span class="math inline">\(y\)</span>) esta relacionada linealmente con la variable(s) independiente(s) y el término de error (<span class="math inline">\(u\)</span>). Es decir, el aumento en una unidad de <span class="math inline">\(x\)</span> implica un efecto constante en la variable dependiente <span class="math inline">\(y\)</span>. De aquí la forma funcional de la ecuación de regresión:</p>
<p><span class="math display">\[Y = \beta_0 + \beta_1x + u\]</span></p>
<p>Si la relación en realidad no es lineal, entonces estaremos ante un problema de especificación del modelo. Es decir, los valores predichos por nuestro modelo no se ajustarán a la realidad de nuestros datos y, en consecuencia, las estimaciones serán sesgadas. Por tanto, es clave evaluar si la relación que queremos estimar es lineal o si la forma funcional que caracteriza dicha relación es otra (por ejemplo, podría ser cuadrática, cúbica, logarítmica, etc).</p>
<p>La buena noticia es que si tenemos motivos teóricos y empíricos para creer que la relación no es lineal, es posible realizar transformaciones a nuestras variables para lograr una mejor especificación del modelo. Un clásico ejemplo refiere a la relación parabólica entre la edad y el salario: a medida que aumenta la edad aumenta el salario hasta que llega un punto de inflexión donde el aumento de la edad se relaciona con menores niveles de ingreso. En este caso lo recomnedable es realizar una transformación cuadrática a la variable edad para lograr una mejor especificación del modelo.</p>
<p>Para evaluar la linealidad realizamos un gráfico de dispersión de los valores predichos contra los residuos <span class="math inline">\(u\)</span>. Lo que se intenta es evaluar si el promedio de los residuos tiende a ubicarse de manera aleatoria por encima y debajo del cero. Si los residuos muestran un patrón creciente o decreciente - o de cualquier otro tipo - entonces la forma funcional de alguna de las variables en cuestión no es lineal.
Para esto utilizamos el comando <code>plot</code>:</p>
<div class="sourceCode" id="cb116"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb116-1" data-line-number="1"> <span class="kw">plot</span>(<span class="dt">y=</span>modelo_<span class="dv">1</span><span class="op">$</span>residuals,<span class="dt">x=</span>modelo_<span class="dv">1</span><span class="op">$</span>fitted.values,</a>
<a class="sourceLine" id="cb116-2" data-line-number="2">      <span class="dt">xlab=</span><span class="st">&quot;Valores Predichos&quot;</span>,<span class="dt">ylab=</span><span class="st">&quot;Residuales&quot;</span>)</a>
<a class="sourceLine" id="cb116-3" data-line-number="3"><span class="kw">abline</span>(<span class="dv">0</span>, <span class="dv">0</span>)</a></code></pre></div>
<p><img src="lineal_files/figure-html/unnamed-chunk-42-1.png" width="480" style="display: block; margin: auto;" /></p>
<p>Además, podemos hacer un gráfico de residuales parciales (o de componentes), donde se grafican cada una de las variables independientes del modelo contra los residuos. El objetivo es obtener un gráfico “parcial” para observar la relación entre la(s) variable(s) independiente(s) y la variable dependiente dando cuenta (controlando) de las demás variables del modelo. Una línea punteada nos muestra la predicción de OLS, y otra línea (rosada) nos muestra la relación “real”. Si observamos que alguna de nuestras variables <strong>no tiene una relación lineal</strong> podemos realizar transformaciones (a las variables!) para que la forma funcional se acerque a la empiria. Cabe destacar que, además de la justificación empírica, esta transformación lineal <strong>siempre</strong> debe ir acompañada de un argumento teórico de por qué la relación entre las dos variables toma esa forma.</p>
<div class="sourceCode" id="cb117"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb117-1" data-line-number="1"><span class="kw">library</span>(car)</a>
<a class="sourceLine" id="cb117-2" data-line-number="2"><span class="kw">crPlots</span>(modelo_<span class="dv">1</span>)</a></code></pre></div>
<p><img src="lineal_files/figure-html/unnamed-chunk-43-1.png" width="480" style="display: block; margin: auto;" /></p>
<p>La relación de nuestra variable de interés con la variable dependiente parece ser cuadrática creciente. Por tanto, podría ser razonable realizar una transformación cuadrática a la variable. Evaluemos esto gráficamente:</p>
<div class="sourceCode" id="cb118"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb118-1" data-line-number="1">basehys_sinna<span class="op">$</span>cseduc2 &lt;-<span class="st"> </span>basehys_sinna<span class="op">$</span>cseduc<span class="op">*</span>basehys_sinna<span class="op">$</span>cseduc</a>
<a class="sourceLine" id="cb118-2" data-line-number="2">modelo_<span class="dv">1</span>_tl&lt;-<span class="st"> </span><span class="kw">lm</span>(gini_slc<span class="op">~</span><span class="dv">1</span> <span class="op">+</span><span class="st"> </span>cseduc2 <span class="op">+</span><span class="st"> </span>cseduc, <span class="dt">data=</span>basehys_sinna)</a>
<a class="sourceLine" id="cb118-3" data-line-number="3"></a>
<a class="sourceLine" id="cb118-4" data-line-number="4"><span class="kw">library</span>(car)</a>
<a class="sourceLine" id="cb118-5" data-line-number="5"><span class="kw">crPlots</span>(modelo_<span class="dv">1</span>_tl)</a></code></pre></div>
<p><img src="lineal_files/figure-html/unnamed-chunk-44-1.png" width="480" style="display: block; margin: auto;" /></p>
<p>A partir de un diagnostico visual, se observa una tendencia creciente en los residuos a medida que se avanza en los valores predichos. Además, se detectó una relación no lineal entre el gasto en educación y los niveles de desigualdad. La sospecha es que esta relación pueda ser cuadrática (parábola cuadrática creciente) y, de acuerdo al gráfico de residuales parciales parece ser que la variable transformada se acerca bastante más a la relación lineal que estima MCO (marcada por la línea punteada).</p>
<p>Para confirmar las observaciones visuales, se suele utilizar un test estadístico para diagnosticar una mala especificación funcional del modelo: RESET Test de Ramsey. La idea es justamente evaluar si es que existe un error de especificación de la ecuación de regresión. Este test lo que hace es volver a estimar el modelo pero incorporando los valores predichos del modelo original con alguna transformación no lineal de las variables. Luego, a partir de un Test-F se evalúa si el modelo con la especificación no lineal tiene un mejor ajuste que el modelo original sin la transformación no lineal. La hipótesis nula postula que las nuevas variables (en este caso cseduc^2) no aportan significativamente para explicar la variación de la variable dependiente; es decir, que su coeficiente es igual a cero (<span class="math inline">\(\beta=0\)</span>).</p>
<div class="sourceCode" id="cb119"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb119-1" data-line-number="1"><span class="kw">library</span>(lmtest)</a>
<a class="sourceLine" id="cb119-2" data-line-number="2"><span class="co">## Loading required package: zoo</span></a>
<a class="sourceLine" id="cb119-3" data-line-number="3"><span class="co">## </span></a>
<a class="sourceLine" id="cb119-4" data-line-number="4"><span class="co">## Attaching package: &#39;zoo&#39;</span></a>
<a class="sourceLine" id="cb119-5" data-line-number="5"><span class="co">## The following objects are masked from &#39;package:base&#39;:</span></a>
<a class="sourceLine" id="cb119-6" data-line-number="6"><span class="co">## </span></a>
<a class="sourceLine" id="cb119-7" data-line-number="7"><span class="co">##     as.Date, as.Date.numeric</span></a>
<a class="sourceLine" id="cb119-8" data-line-number="8"><span class="kw">resettest</span>(modelo_<span class="dv">1</span>, <span class="dt">power=</span><span class="dv">2</span>, <span class="dt">type=</span><span class="kw">c</span>(<span class="st">&quot;fitted&quot;</span>), <span class="dt">data=</span>basehys_sinna)</a>
<a class="sourceLine" id="cb119-9" data-line-number="9"><span class="co">## </span></a>
<a class="sourceLine" id="cb119-10" data-line-number="10"><span class="co">##  RESET test</span></a>
<a class="sourceLine" id="cb119-11" data-line-number="11"><span class="co">## </span></a>
<a class="sourceLine" id="cb119-12" data-line-number="12"><span class="co">## data:  modelo_1</span></a>
<a class="sourceLine" id="cb119-13" data-line-number="13"><span class="co">## RESET = 9, df1 = 1, df2 = 400, p-value = 0.004</span></a></code></pre></div>
<p>De acuerdo al resultado del Test F, confirmamos lo observado gráficamente: el incorporar un término cuadrático del gasto en educación mejora el ajuste de nuestra estimación. A esta conclusión llegamos observando el <em>valor-p</em> del test RESET de Ramsey: a un nivel de significancia estadística del 5%, se rechaza la hipótesis nula de que la incorporación del término cuadrático no mejora el ajuste del modelo.</p>
<ul>
<li><em>Nota</em>: Esta evaluación se realizó para un modelo de regresión simple (bivariado). Pero bien puede realizarse exactamente lo mismo para modelos multivariados.</li>
</ul>
</div>
<div id="variacion-en-las-variables-independientes-y-no-colinealidad-perfecta" class="section level4">
<h4><span class="header-section-number">8.4.3.4</span> 4. Variación en las variables independientes y no Colinealidad Perfecta</h4>
<p>En primer lugar, es necesario que exista variación en la(s) variable(s) independiente(s). Si no tengo variación, la estimación de los coeficientes será indeterminada. Además, mayor variación en las variables independientes me permitirá realizar estimaciones más precisas.</p>
<p>Por otra parte, la no-colinealidad perfecta implica que las variables independientes no estén perfectamente correlacionadas <em>linealmente</em>. Es decir, si bien las variables independientes por lo general suelen tener alguna relación entre ellas, no queremos que midan prácticamente lo mismo! Eso lo evaluaremos con tests de multicolinealidad.</p>
<p><strong>Problemas de la multicolinealidad:</strong></p>
<p>A. <em>Pérdida de eficiencia</em>, pues sus errores estándar serán infinitos. Aún si la multicolinealidad es menos que perfecta los coeficientes de regresión poseen grandes errores estándar, lo que hace que no puedan ser estimados con gran precisión.</p>
<p>Repasemos la fórmula del error estándar de los coeficientes:</p>
<p><span class="math display">\[\hat{\sigma}{_\hat{\beta}{_1}} = \frac{\hat{\sigma}} {\sqrt{\sum(X_j – \bar{X})^2(1 - R^2_j)}}\]</span></p>
<ul>
<li><p><span class="math inline">\(\hat{\sigma}\)</span> Es la varianza del término de error: <span class="math inline">\(\frac{\sum\hat{u}}{n-k-1}\)</span></p></li>
<li><p><span class="math inline">\(\sum(X_j – \bar{X})^2\)</span> Es la variabilidad de <span class="math inline">\(x_j\)</span> (<span class="math inline">\(STCx_j\)</span>)</p></li>
<li><p><span class="math inline">\(1 - R^2_j\)</span> Es la porción de <span class="math inline">\(x_j\)</span> que no es explicada por el resto de las <em>x</em> en el modelo (<span class="math inline">\(R^2_j\)</span> indica la varianza de <span class="math inline">\(x_j\)</span> que es explicada por el resto de las equis del modelo). Es por este término que la no colinealidad perfecta es tan importante!</p></li>
</ul>
<p>B. Las <em>estimaciones de los coeficientes pueden oscilar demasiado</em> en función de qué otras variables independientes están en el modelo. En una estimación OLS la idea es que puedes cambiar el valor de una variable independiente y no de las otras (de esto se trata ceteris paribus). Sin embargo, cuando las variables independientes están correlacionadas, los cambios en una variable están asociados con los cambios en otra variable. Cuanto más fuerte es la correlación, más difícil es cambiar una variable sin cambiar otra. Se vuelve difícil para el modelo estimar la relación entre cada variable independiente y la variable dependiente manteniendo el resto constante porque las variables independientes tienden a cambiar simultáneamente.</p>
<p>Repasemos la fórmula del estimación del coeficiente en una regresión múltiple:</p>
<p><span class="math display">\[\hat{\beta_1} = \frac{\sum(\hat{r_{i1}}\hat{y_i})}{\sum(\hat{r^2_{i1}})}\]</span></p>
<p>Donde:</p>
<ul>
<li><span class="math inline">\(\hat{r_{i1}}\)</span> son los residuales de una regresión de <span class="math inline">\(x_1\)</span> sobre el resto de las <span class="math inline">\(x\)</span> en el modelo (osea la parte de <span class="math inline">\(x_1\)</span> que no puede ser explicada - o que no está correlacionada - con el resto de las <span class="math inline">\(x\)</span>)</li>
</ul>
<p>Por tanto, <span class="math inline">\(\hat{\beta_1}\)</span> mide la relación muestral entre <span class="math inline">\(y\)</span> y <span class="math inline">\(x_1\)</span> luego de haber descontado los efectos parciales de <span class="math inline">\(x_2\)</span>, <span class="math inline">\(x_3\)</span>…<span class="math inline">\(x_k\)</span>.</p>
<p>Para evaluar la multicolinealidad, un primer paso es observar la matriz de correlación de las variables de nuestro modelo (tal como hicimos en la etapa de analizar los estadísticos descriptivos):</p>
<div class="sourceCode" id="cb120"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb120-1" data-line-number="1">variables &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="st">&quot;gini_slc&quot;</span>,<span class="st">&quot;cseduc&quot;</span>,<span class="st">&quot;s_dualism&quot;</span>,<span class="st">&quot;fdiingdp&quot;</span>,<span class="st">&quot;rgdpch&quot;</span>,<span class="st">&quot;pop014wdi&quot;</span>,<span class="st">&quot;ethnicdicot&quot;</span>,<span class="st">&quot;demrss&quot;</span>,<span class="st">&quot;cshlth&quot;</span>,<span class="st">&quot;csssw&quot;</span>,<span class="st">&quot;legbal&quot;</span>,<span class="st">&quot;repressauthor&quot;</span>)</a>
<a class="sourceLine" id="cb120-2" data-line-number="2">vind &lt;-<span class="st"> </span>basehys[variables]</a>
<a class="sourceLine" id="cb120-3" data-line-number="3">Hmisc<span class="op">::</span><span class="kw">rcorr</span>(<span class="kw">as.matrix</span>(vind))</a>
<a class="sourceLine" id="cb120-4" data-line-number="4"><span class="co">##               gini_slc cseduc s_dualism fdiingdp rgdpch pop014wdi</span></a>
<a class="sourceLine" id="cb120-5" data-line-number="5"><span class="co">##               ethnicdicot demrss cshlth csssw legbal repressauthor</span></a>
<a class="sourceLine" id="cb120-6" data-line-number="6"><span class="co">##  [ reached getOption(&quot;max.print&quot;) -- omitted 12 rows ]</span></a>
<a class="sourceLine" id="cb120-7" data-line-number="7"><span class="co">## </span></a>
<a class="sourceLine" id="cb120-8" data-line-number="8"><span class="co">## n</span></a>
<a class="sourceLine" id="cb120-9" data-line-number="9"><span class="co">##               gini_slc cseduc s_dualism fdiingdp rgdpch pop014wdi</span></a>
<a class="sourceLine" id="cb120-10" data-line-number="10"><span class="co">##               ethnicdicot demrss cshlth csssw legbal repressauthor</span></a>
<a class="sourceLine" id="cb120-11" data-line-number="11"><span class="co">##  [ reached getOption(&quot;max.print&quot;) -- omitted 12 rows ]</span></a>
<a class="sourceLine" id="cb120-12" data-line-number="12"><span class="co">## </span></a>
<a class="sourceLine" id="cb120-13" data-line-number="13"><span class="co">## P</span></a>
<a class="sourceLine" id="cb120-14" data-line-number="14"><span class="co">##               gini_slc cseduc s_dualism fdiingdp rgdpch pop014wdi</span></a>
<a class="sourceLine" id="cb120-15" data-line-number="15"><span class="co">##               ethnicdicot demrss cshlth csssw  legbal repressauthor</span></a>
<a class="sourceLine" id="cb120-16" data-line-number="16"><span class="co">##  [ reached getOption(&quot;max.print&quot;) -- omitted 12 rows ]</span></a></code></pre></div>
<p>Vemos que algunas de nuestras variables están fuertemente correlacionadas!</p>
<p>De todos modos, para detecter multicolinealidad es necesario realizar un test de vif (variance inflation factors) porque ver correlación de a pares no nos ayuda a dilucidar si más de dos variables tienen una correlación lineal. Lo que nos dice este test vif es qué tanto se “agrandan” los errores de cada coeficiente en presencia de las demás variables (qué tanto se incrementa la varianza del error).</p>
<div class="sourceCode" id="cb121"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb121-1" data-line-number="1"><span class="kw">library</span>(car)</a>
<a class="sourceLine" id="cb121-2" data-line-number="2"><span class="kw">vif</span>(modelo_<span class="dv">2</span>)</a>
<a class="sourceLine" id="cb121-3" data-line-number="3"><span class="co">##      cseduc    fdiingdp      cshlth       csssw   pop014wdi   s_dualism </span></a>
<a class="sourceLine" id="cb121-4" data-line-number="4"><span class="co">##         1.8         1.5         1.7         4.8         5.0         1.2 </span></a>
<a class="sourceLine" id="cb121-5" data-line-number="5"><span class="co">## ethnicdicot      rgdpch </span></a>
<a class="sourceLine" id="cb121-6" data-line-number="6"><span class="co">##         1.9         2.4 </span></a>
<a class="sourceLine" id="cb121-7" data-line-number="7"><span class="co">##  [ reached getOption(&quot;max.print&quot;) -- omitted 3 entries ]</span></a>
<a class="sourceLine" id="cb121-8" data-line-number="8"><span class="kw">sqrt</span>(<span class="kw">vif</span>(modelo_<span class="dv">2</span>)) <span class="op">&gt;</span><span class="st"> </span><span class="dv">2</span></a>
<a class="sourceLine" id="cb121-9" data-line-number="9"><span class="co">##      cseduc    fdiingdp      cshlth       csssw   pop014wdi   s_dualism </span></a>
<a class="sourceLine" id="cb121-10" data-line-number="10"><span class="co">##       FALSE       FALSE       FALSE        TRUE        TRUE       FALSE </span></a>
<a class="sourceLine" id="cb121-11" data-line-number="11"><span class="co">## ethnicdicot      rgdpch </span></a>
<a class="sourceLine" id="cb121-12" data-line-number="12"><span class="co">##       FALSE       FALSE </span></a>
<a class="sourceLine" id="cb121-13" data-line-number="13"><span class="co">##  [ reached getOption(&quot;max.print&quot;) -- omitted 3 entries ]</span></a></code></pre></div>
<p>Luego, realizo una consulta sobre si la raíz cuadrada de vif para cada variable es menor que 2 (raíz cuadrada porque lo que me interesa es el error estándar y no la varianza). Vif: debería ser menor a 2, si es mayor a dos quiere decir que la varianza es demasiado alta y por tanto hay problema de multicolinealidad.</p>
<p>De acuerdo a la consulta, parece ser que no tenemos un problema serio de multicolinealidad.
Pero si lo tuvieramos, debríamos corregirla?</p>
<p>La necesidad de reducir la multicolinealidad depende de su gravedad y de cuál es el objetivo principal del modelo de regresión. Hay que tener en cuenta los siguientes tres puntos:</p>
<ol style="list-style-type: decimal">
<li><p>La gravedad de los problemas aumenta con el grado de multicolinealidad. Por lo tanto, si la multicolinealidad es moderada, es posible que no necesitemos resolverla.</p></li>
<li><p>La multicolinealidad afecta solo a las variables independientes específicas que están correlacionadas. Por lo tanto, si la multicolinealidad no está presente para las variables independientes de interés, es posible que no necesitemos resolverla.</p></li>
<li><p>La multicolinealidad afecta los coeficientes y los valores-p, y el error estándar, pero no influye directamente en los valores predichos del modelo, la precisión de estas predicciones y las estadísticas de bondad de ajuste. Si el objetivo principal es hacer predicciones, y no necesitamos comprender el papel de cada variable independiente, no necesitamos reducir la multicolinealidad.</p></li>
</ol>
<p><strong>Soluciones a la multicolinealidad</strong></p>
<ol style="list-style-type: decimal">
<li><p>Remover una de las variables indpendientes que esté altamente correlacionada. Esto constituye un trade-off, y se tiene que justificar teóricamente por qué se mantiene una variable y no la otra, además de hacer evidente el alto grado de correlación.</p></li>
<li><p>Puedo combinar las variables que estén altamente correlacionadas, hacer un índice por ejemplo.</p></li>
<li><p>Realizar un análisis diseñado para variables altamente correlacionadas, como por ejemplo el análisis de componentes principales (ver capítulo Nro. ##).</p></li>
</ol>
<ul>
<li>Hasta ahora hemos visto cuatro supuestos, que permiten derivar la insesgadez de los estimadores por MCO. Es decir, nos permiten confiar en que la esperanza de la estimación realizada a través de MCO será igual al promedio poblacional: <span class="math inline">\(E(\hat\beta)=\beta\)</span></li>
</ul>
<p>El quinto supuesto tiene que ver con la eficiencia. Esto es, con la varianza del término de error de nuestra estimación.</p>
</div>
<div id="homocedasticidad" class="section level4">
<h4><span class="header-section-number">8.4.3.5</span> 5. Homocedasticidad</h4>
<p>La varianza del término de error es constante. Es decir, dado cualquier valor de las variables explicativas, el error tiene la misma varianza:</p>
<p><span class="math inline">\(Var(u\mid{x})=\sigma^2\)</span>, es decir <span class="math inline">\(Var(u)=\sigma^2\)</span></p>
<p>De este modo, la varianza del error no observable, <span class="math inline">\(u\)</span>, condicional sobre las variables explicativas, es constante.</p>
<p>Como mencionamos anteriormente, este supuesto <strong>no afecta la sesgadez</strong> del estimador (es decir, que la distribución muestral de nuestra estimación <span class="math inline">\(_\hat{\beta_1}\)</span> esté centrada en <span class="math inline">\(\beta_1\)</span>), sino su <em>eficiencia</em> (qué tanta dispersión hay en torno a la estimación <span class="math inline">\(_\hat{\beta_1}\)</span> del parámetro <span class="math inline">\(\beta_1\)</span>).</p>
<p>Este supuesto es central para poder calcular la varianza de los estimadores de MCO, y es el que permite que sea el estimador de mínima varianza entre los estimadores lineales insesgados.</p>
<p>Si evaluamos la fórmula del error estándar de los coeficientes, se hace evidente la necesidad del supuesto:
<span class="math display">\[\hat{\sigma}{_\hat{\beta}{_1}} = \frac{\hat{\sigma}} {\sqrt{\sum(X_j – \bar{X})^2(1 - R^2_j)}}\]</span></p>
<ul>
<li><span class="math inline">\(\hat{\sigma}\)</span> Es la varianza del término de error: <span class="math inline">\(\frac{\sum\hat{u}}{n-k-1}\)</span></li>
</ul>
<p>Para poder aplicar esta fórmula, <strong>necesitamos</strong> que <span class="math inline">\({\sigma^2}\)</span> sea constante!!</p>
<p>Cuando este supuesto no se cumple, es decir el término de error no se mantiene constante para distintos valores de <span class="math inline">\(x\)</span>, estamos ante un escenario de <strong>heterocedasticidad</strong>. Es bastante frecuente tener heterocedasticidad.
La buena noticia es que esto no imposibilita la utilización del estimador OLS: hay una solución!</p>
<p><strong>A. Evaluando el supuesto</strong></p>
<p>Para la evaluación de este supuesto se suelen seguir dos pasos:</p>
<ol style="list-style-type: decimal">
<li>Diagnóstico visual</li>
</ol>
<p>Lo que buscamos es observar si los residuales (distancia entre los puntos y la línea de regresión) son constantes para distintos valores de equis.</p>
<p>En primer lugar, hacemos un simple diagrama de dispersión entre la variable independiente que nos interesa y la variable dependiente:</p>
<div class="sourceCode" id="cb122"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb122-1" data-line-number="1"><span class="kw">ggplot</span>(basehys_sinna, <span class="kw">aes</span>(cseduc, gini_slc)) <span class="op">+</span><span class="st"> </span></a>
<a class="sourceLine" id="cb122-2" data-line-number="2"><span class="st">    </span><span class="kw">geom_point</span>() <span class="op">+</span></a>
<a class="sourceLine" id="cb122-3" data-line-number="3"><span class="st">    </span><span class="kw">theme_bw</span>()<span class="op">+</span><span class="st"> </span><span class="kw">geom_smooth</span>(<span class="dt">method=</span>lm)</a></code></pre></div>
<p><img src="lineal_files/figure-html/unnamed-chunk-48-1.png" width="480" style="display: block; margin: auto;" /></p>
<p>Otra manera de hacer lo mismo y donde es más evidente:</p>
<div class="sourceCode" id="cb123"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb123-1" data-line-number="1">car<span class="op">::</span><span class="kw">scatterplot</span>(basehys_sinna<span class="op">$</span>cseduc,basehys_sinna<span class="op">$</span>gini_slc)</a></code></pre></div>
<p><img src="lineal_files/figure-html/unnamed-chunk-49-1.png" width="480" style="display: block; margin: auto;" /></p>
<p>Parece ser que en los niveles más bajos de gasto en educación la variabilidad de los niveles de desigualdad es bastante más alta que a niveles más elevados de gasto en educación.</p>
<p>Podemos hacer un mejor diagnóstico visual si utilizamos el modelo estimado (y no solo la relación entre las dos variables) y graficamos los residuos.</p>
<p>Primero lo hacemos para el modelo bivariado:</p>
<div class="sourceCode" id="cb124"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb124-1" data-line-number="1"><span class="kw">par</span>(<span class="dt">mfrow=</span><span class="kw">c</span>(<span class="dv">2</span>,<span class="dv">2</span>))</a>
<a class="sourceLine" id="cb124-2" data-line-number="2"><span class="kw">plot</span>(modelo_<span class="dv">1</span>)</a></code></pre></div>
<p><img src="lineal_files/figure-html/unnamed-chunk-50-1.png" width="480" style="display: block; margin: auto;" /></p>
<p>Luego para el modelo multivariado:</p>
<div class="sourceCode" id="cb125"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb125-1" data-line-number="1"><span class="kw">plot</span>(modelo_<span class="dv">2</span>)</a>
<a class="sourceLine" id="cb125-2" data-line-number="2"><span class="kw">par</span>(<span class="dt">mfrow=</span><span class="kw">c</span>(<span class="dv">1</span>,<span class="dv">1</span>))</a></code></pre></div>
<p><img src="lineal_files/figure-html/unnamed-chunk-51-1.png" width="480" style="display: block; margin: auto;" /><img src="lineal_files/figure-html/unnamed-chunk-51-2.png" width="480" style="display: block; margin: auto;" /><img src="lineal_files/figure-html/unnamed-chunk-51-3.png" width="480" style="display: block; margin: auto;" /><img src="lineal_files/figure-html/unnamed-chunk-51-4.png" width="480" style="display: block; margin: auto;" /></p>
<p>Los dos gráficos que nos interesa analizar son los de la izquierda: donde se grafican los valores predichos y los residuos.</p>
<p>Recordemos que bajo el supuesto de homocedasticidad, como la <span class="math inline">\(Var(u\mid{x})=\sigma^2\)</span> , entonces la <span class="math inline">\(Var(Y\mid{x})=\sigma^2\)</span>. En otras palabras, la varianza de los residuos de los valores predichos a partir de las equis <strong>debiera ser constante</strong>. Por tanto, si no hay absolutamente ninguna heterocedasticidad (osea si estamos ante un escenario de homocedasticidad), deberíamos ver una distribución de puntos completamente aleatoria e igual en todo el rango del eje X y una línea roja constante.</p>
<p>Sin embargo, claramente se observa que los residuos no son constantes para distintos valores de la variable de gasto en educación! Estamos frente a un caso de <strong>heterocedasticidad</strong></p>
<ul>
<li>Podemos también evaluar cada una de las variables del modelo y, así, identificar para qué variables específicas hay heterocedasticidad. Nuevamente, lo que esperamos es que la línea azul coincida con la línea punteada (en cero).</li>
</ul>
<div class="sourceCode" id="cb126"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb126-1" data-line-number="1">car<span class="op">::</span><span class="kw">residualPlots</span>(modelo_<span class="dv">2</span>)</a>
<a class="sourceLine" id="cb126-2" data-line-number="2"><span class="co">##               Test stat Pr(&gt;|Test stat|)    </span></a>
<a class="sourceLine" id="cb126-3" data-line-number="3"><span class="co">## cseduc            -1.80            0.073 .  </span></a>
<a class="sourceLine" id="cb126-4" data-line-number="4"><span class="co">## fdiingdp          -0.12            0.901    </span></a>
<a class="sourceLine" id="cb126-5" data-line-number="5"><span class="co">##  [ reached getOption(&quot;max.print&quot;) -- omitted 10 rows ]</span></a>
<a class="sourceLine" id="cb126-6" data-line-number="6"><span class="co">## ---</span></a>
<a class="sourceLine" id="cb126-7" data-line-number="7"><span class="co">## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</span></a></code></pre></div>
<p><img src="lineal_files/figure-html/unnamed-chunk-52-1.png" width="480" style="display: block; margin: auto;" /><img src="lineal_files/figure-html/unnamed-chunk-52-2.png" width="480" style="display: block; margin: auto;" /></p>
<ol start="2" style="list-style-type: decimal">
<li>Diagnóstico estadístico</li>
</ol>
<p>En un segundo paso realizamos un diagnóstico estadístico. Hay distintas maneras de evaluar la homocedasticidad, pero hay el Test de <em>Breusch-Pagan</em> es el que se utiliza con más frecuencia.</p>
<p>La lógica que está por detrás de este test es la siguiente: se realiza una regresión donde la variable dependiente son los residuos al cuadrado, para evaluar si las variables independientes del modelo tienen relación con <span class="math inline">\(u\)</span>. Lo que se quiere encontrar es que ese efecto sea 0, porque si la varianza del error es constante, el error (residuos) no debería variar según los valores de las <span class="math inline">\(x&#39;s\)</span>. En definitiva, ¡no se quiere rechazar la hipótesis nula!</p>
<div class="sourceCode" id="cb127"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb127-1" data-line-number="1"><span class="kw">bptest</span>(modelo_<span class="dv">2</span>,<span class="dt">studentize=</span>T)</a>
<a class="sourceLine" id="cb127-2" data-line-number="2"><span class="co">## </span></a>
<a class="sourceLine" id="cb127-3" data-line-number="3"><span class="co">##  studentized Breusch-Pagan test</span></a>
<a class="sourceLine" id="cb127-4" data-line-number="4"><span class="co">## </span></a>
<a class="sourceLine" id="cb127-5" data-line-number="5"><span class="co">## data:  modelo_2</span></a>
<a class="sourceLine" id="cb127-6" data-line-number="6"><span class="co">## BP = 30, df = 10, p-value = 7e-04</span></a></code></pre></div>
<p>El resultado del test de Breusch-Pagan nos confirma que estamos ante un escenario de Heterocedasticidad. Como el p-value es menor a 0.05, se rechaza la hipótesis nula y, por tanto, estamos en un escenario de heterocedasticidad.</p>
<p><strong>B. Soluciones a la Heterocedasticidad</strong></p>
<p>Una vez que identificamos que tenemos heterocedasticidad, es necesario solucionarla.</p>
<ol style="list-style-type: decimal">
<li>Una primera alternativa es corregir la <em>forma funcional</em></li>
</ol>
<p>Claramente podes estar ante el caso que la no constancia del término de error se deba a que la relación entre las variables no es lineal!</p>
<p>Para esto ya vimos posibles soluciones a la no linealidad.</p>
<ol start="2" style="list-style-type: decimal">
<li>Muy frecuentemente sucede que la naturaleza empírica de la relación hace que el error no sea constante.</li>
</ol>
<p>Sabemos que no podemos calcular los errores estándar de los estimadores como lo hacemos siempre en OLS: como la varianza del error <strong>no es constante</strong> es necesario modificar la forma en la que calculamos los errores!</p>
<p>Entonces, para poder hacer inferencia necesitamos ajustar la estimación del error de forma tal de hacer una estimación válida en presencia de <strong>heterocedasticidad de la forma desconocida</strong>. Esto es, aunque no sepa el tipo de heterocedasticidad que tengo, puedo mejorar mi precisión y, además, hacer inferencia estadística válida.</p>
<p>La fórmula habitual del error estándar del estimador es:</p>
<p><span class="math display">\[\hat{\sigma}{_\hat{\beta}{_1}} = \frac{\sum_{i=1}^{n}(x_{i}-\overline{x})^2\hat{\sigma}} {\sqrt{\sum(X_j – \bar{X})^2(1 - R^2_j)}}\]</span></p>
<p>Lo que pasa es que cuando tenemos <strong>homocedasticidad</strong>, lo que está en el nominador: <span class="math inline">\(\sum_{i=1}^{n}(x_{i}-\overline{x})^2\hat{\sigma}=\hat\sigma\)</span></p>
<p>Como ahora <span class="math inline">\(\hat{\sigma}\)</span> ya no es constante, esa igualdad ya no se mantiene! Esto porque el valor que adquiere <span class="math inline">\(\hat{\sigma}\)</span> si va a depender de los distintos valores de <span class="math inline">\(x\)</span>.</p>
<p>Además, recordemos que al estimar una regresión <strong>múltiple</strong>, en la estimación del error estándar es necesario descontar la variación de la <span class="math inline">\(x_1\)</span> que es explicada por el resto de las <span class="math inline">\(x_k\)</span> del modelo.</p>
<p>De este modo, en una regresión múltiple, un estimador válido de <span class="math inline">\(\hat{\sigma}{_\hat{\beta}{_1}}\)</span> bajo heterocedasticidad, será:</p>
<p><span class="math display">\[\hat{\sigma}{_\hat{\beta}{_1}} = \frac{\sum_{i=1}^{n}r_{ij}^2\hat{u}^2}{\sqrt{\sum(X_j–\bar{X})^2(1 - R^2_j)}}\]</span></p>
<p>Donde:</p>
<ul>
<li><span class="math inline">\(r_{ij}^2\)</span> Representa los residuos cuadrados de la regresión del resto de las variables independientes sobre la variable independiente <span class="math inline">\(j\)</span>.</li>
<li> Representa la Varianza Total de equis luego de haber descontado el efecto del resto de las equis.</li>
</ul>
<p>A esta forma de estimar los errores estándar se la denomina <strong>“errores estándares robustos”</strong> o también le decimos <strong>“robustecer”</strong> el error, que no es otra cosa que dar cuenta y permitir la heterocedasticidad, volviendo los errores más exigentes.</p>
</div>
</div>
<div id="errores-estandares-robustos" class="section level3">
<h3><span class="header-section-number">8.4.4</span> Errores estándares robustos</h3>
<p>Si bien hay varias formas de robustecer los errores (incluso se podría hacer a mano), R nos permite calcularlos muy fácilmente con el comando <code>coeftest</code> del paquete <code>lmtest</code>. Además, el paquete <code>sandwich</code> con su función <code>vcovHC</code> nos permite incorporar la especificación de la matriz de varianza-covarianza robusta.</p>
<ul>
<li>HC0 = es la original de White (Wooldrige,2006)</li>
<li>HC1= Es la que utiliza el software de Stata</li>
<li>HC3 = Es la más conservadora y, por tanto, se suele ser altamente recomendada.</li>
</ul>
<div class="sourceCode" id="cb128"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb128-1" data-line-number="1"><span class="kw">library</span>(lmtest)</a>
<a class="sourceLine" id="cb128-2" data-line-number="2"><span class="kw">library</span>(sandwich)</a>
<a class="sourceLine" id="cb128-3" data-line-number="3">modelo_robusto_<span class="dv">3</span>=<span class="kw">coeftest</span>(modelo_<span class="dv">2</span>, <span class="dt">vcov =</span> <span class="kw">vcovHC</span>(modelo_<span class="dv">2</span>, <span class="st">&quot;HC3&quot;</span>))</a>
<a class="sourceLine" id="cb128-4" data-line-number="4">modelo_robusto_<span class="dv">1</span>=<span class="kw">coeftest</span>(modelo_<span class="dv">2</span>, <span class="dt">vcov =</span> <span class="kw">vcovHC</span>(modelo_<span class="dv">2</span>, <span class="st">&quot;HC1&quot;</span>))</a>
<a class="sourceLine" id="cb128-5" data-line-number="5">modelo_robusto_<span class="dv">0</span>=<span class="kw">coeftest</span>(modelo_<span class="dv">2</span>, <span class="dt">vcov =</span> <span class="kw">vcovHC</span>(modelo_<span class="dv">2</span>, <span class="st">&quot;HC0&quot;</span>))</a>
<a class="sourceLine" id="cb128-6" data-line-number="6">stargazer<span class="op">::</span><span class="kw">stargazer</span>(modelo_robusto_<span class="dv">3</span>, modelo_robusto_<span class="dv">1</span>, modelo_robusto_<span class="dv">0</span>, <span class="dt">type =</span> <span class="st">&quot;text&quot;</span>)</a>
<a class="sourceLine" id="cb128-7" data-line-number="7"><span class="co">## </span></a>
<a class="sourceLine" id="cb128-8" data-line-number="8"><span class="co">## ==============================================</span></a>
<a class="sourceLine" id="cb128-9" data-line-number="9"><span class="co">##                     Dependent variable:       </span></a>
<a class="sourceLine" id="cb128-10" data-line-number="10"><span class="co">##               --------------------------------</span></a>
<a class="sourceLine" id="cb128-11" data-line-number="11"><span class="co">##                                               </span></a>
<a class="sourceLine" id="cb128-12" data-line-number="12"><span class="co">##                  (1)        (2)        (3)    </span></a>
<a class="sourceLine" id="cb128-13" data-line-number="13"><span class="co">## ----------------------------------------------</span></a>
<a class="sourceLine" id="cb128-14" data-line-number="14"><span class="co">## cseduc         1.600***   1.600***   1.600*** </span></a>
<a class="sourceLine" id="cb128-15" data-line-number="15"><span class="co">##                (0.540)    (0.500)    (0.480)  </span></a>
<a class="sourceLine" id="cb128-16" data-line-number="16"><span class="co">##                                               </span></a>
<a class="sourceLine" id="cb128-17" data-line-number="17"><span class="co">## fdiingdp        0.240      0.240*     0.240*  </span></a>
<a class="sourceLine" id="cb128-18" data-line-number="18"><span class="co">##                (0.150)    (0.140)    (0.140)  </span></a>
<a class="sourceLine" id="cb128-19" data-line-number="19"><span class="co">##                                               </span></a>
<a class="sourceLine" id="cb128-20" data-line-number="20"><span class="co">## cshlth        -0.830***  -0.830***  -0.830*** </span></a>
<a class="sourceLine" id="cb128-21" data-line-number="21"><span class="co">##                (0.240)    (0.230)    (0.220)  </span></a>
<a class="sourceLine" id="cb128-22" data-line-number="22"><span class="co">##                                               </span></a>
<a class="sourceLine" id="cb128-23" data-line-number="23"><span class="co">## csssw         -0.830***  -0.830***  -0.830*** </span></a>
<a class="sourceLine" id="cb128-24" data-line-number="24"><span class="co">##                (0.280)    (0.260)    (0.250)  </span></a>
<a class="sourceLine" id="cb128-25" data-line-number="25"><span class="co">##                                               </span></a>
<a class="sourceLine" id="cb128-26" data-line-number="26"><span class="co">## pop014wdi     -0.930***  -0.930***  -0.930*** </span></a>
<a class="sourceLine" id="cb128-27" data-line-number="27"><span class="co">##                (0.220)    (0.210)    (0.200)  </span></a>
<a class="sourceLine" id="cb128-28" data-line-number="28"><span class="co">##                                               </span></a>
<a class="sourceLine" id="cb128-29" data-line-number="29"><span class="co">## s_dualism     -0.170***  -0.170***  -0.170*** </span></a>
<a class="sourceLine" id="cb128-30" data-line-number="30"><span class="co">##                (0.034)    (0.032)    (0.031)  </span></a>
<a class="sourceLine" id="cb128-31" data-line-number="31"><span class="co">##                                               </span></a>
<a class="sourceLine" id="cb128-32" data-line-number="32"><span class="co">## ethnicdicot    3.700***   3.700***   3.700*** </span></a>
<a class="sourceLine" id="cb128-33" data-line-number="33"><span class="co">##                (1.000)    (0.950)    (0.920)  </span></a>
<a class="sourceLine" id="cb128-34" data-line-number="34"><span class="co">##                                               </span></a>
<a class="sourceLine" id="cb128-35" data-line-number="35"><span class="co">## rgdpch        -0.0004**  -0.0004**  -0.0004** </span></a>
<a class="sourceLine" id="cb128-36" data-line-number="36"><span class="co">##                (0.0002)   (0.0002)   (0.0002) </span></a>
<a class="sourceLine" id="cb128-37" data-line-number="37"><span class="co">##                                               </span></a>
<a class="sourceLine" id="cb128-38" data-line-number="38"><span class="co">## demrss        -2.100***  -2.100***  -2.100*** </span></a>
<a class="sourceLine" id="cb128-39" data-line-number="39"><span class="co">##                (0.630)    (0.590)    (0.570)  </span></a>
<a class="sourceLine" id="cb128-40" data-line-number="40"><span class="co">##                                               </span></a>
<a class="sourceLine" id="cb128-41" data-line-number="41"><span class="co">## legbal        -11.000*** -11.000*** -11.000***</span></a>
<a class="sourceLine" id="cb128-42" data-line-number="42"><span class="co">##                (2.500)    (2.300)    (2.200)  </span></a>
<a class="sourceLine" id="cb128-43" data-line-number="43"><span class="co">##                                               </span></a>
<a class="sourceLine" id="cb128-44" data-line-number="44"><span class="co">## repressauthor   -1.300     -1.300     -1.300  </span></a>
<a class="sourceLine" id="cb128-45" data-line-number="45"><span class="co">##                (1.800)    (1.700)    (1.600)  </span></a>
<a class="sourceLine" id="cb128-46" data-line-number="46"><span class="co">##                                               </span></a>
<a class="sourceLine" id="cb128-47" data-line-number="47"><span class="co">## Constant      89.000***  89.000***  89.000*** </span></a>
<a class="sourceLine" id="cb128-48" data-line-number="48"><span class="co">##                (10.000)   (9.400)    (9.100)  </span></a>
<a class="sourceLine" id="cb128-49" data-line-number="49"><span class="co">##                                               </span></a>
<a class="sourceLine" id="cb128-50" data-line-number="50"><span class="co">## ==============================================</span></a>
<a class="sourceLine" id="cb128-51" data-line-number="51"><span class="co">## ==============================================</span></a>
<a class="sourceLine" id="cb128-52" data-line-number="52"><span class="co">## Note:              *p&lt;0.1; **p&lt;0.05; ***p&lt;0.01</span></a></code></pre></div>
<p>Todas las alternativas nos dan errores robustos similares. Las diferencias están dadas por distintas especificaciones sobre la matriz de varianza-covarianza robusta (HC).</p>
</div>
<div id="un-caso-especial-de-heterocedasticidad-la-varianza-del-error-asociada-a-clusters" class="section level3">
<h3><span class="header-section-number">8.4.5</span> Un caso especial de Heterocedasticidad: la varianza del error asociada a clusters</h3>
<p>Sabemos que hay observaciones que pueden estar relacionadas entre sí dentro de determinados grupos (o clusters). Por ejemplo, los países de América Latina podrían estar relacionados por pertenecer a regiones similares (América del Sur versus América Central o Caribe, regiones Andinas versus no Andinas, etc). Así, sus errores podrían estar correlacionados en base a la región que pertenecen. Entonces, tengo que la varianza del error condicionada por región no es constante.</p>
<p>Cuando trabajamos con datos de panel, como es nuestro caso, esto es bastante más claro. Al contar con gasto en educación por país para varios años existe una <em>auto-correlación del error</em> entre observaciones de un mismo país. Es decir, los errores se encuentran correlacionados entre las observaciones de un mismo país para cada año (lo que se gasta en un año particular, probablemente esté relacionado con lo que se gastó en el año anterior).</p>
<p>Entonces, cuando mis observaciones pertenecen a clusters y tengo motivos teóricos para pensar que sus errores estarán correlacionados dentro del cluster, la corrección supondrá clusterizar los errores estándar: <strong>cluster standard errors</strong>.</p>
<p>Lo que estamos haciendo cuando clusterizamos los errores estándar es permitir que exista correlación del error dentro de los clusters (se relaja el supuesto de homocedasticidad). Así, permitimos que la varianza del error no sea constante, sino que sea diferente según los clusters.</p>
<p>La selección de cuáles son los clusters relevantes estará dada teóricamente. En nuestro caso, hace sentido pensar que los clusters son los países.</p>
<p>Recordemos que nuestro interés era estimar el el efecto del gasto en educación sobre el índice de Gini en países de América Latina. Observemos esta relación según región para evaluar si, a primera vista, parece haber clusterización:</p>
<div class="sourceCode" id="cb129"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb129-1" data-line-number="1"><span class="kw">library</span>(ggplot2)</a>
<a class="sourceLine" id="cb129-2" data-line-number="2"><span class="kw">ggplot</span>(basehys_sinna, <span class="kw">aes</span>(cseduc, gini_slc)) <span class="op">+</span><span class="st"> </span></a>
<a class="sourceLine" id="cb129-3" data-line-number="3"><span class="st">    </span><span class="kw">geom_point</span>() <span class="op">+</span><span class="st"> </span></a>
<a class="sourceLine" id="cb129-4" data-line-number="4"><span class="st">    </span><span class="kw">facet_wrap</span>(<span class="op">~</span>country) <span class="op">+</span><span class="st"> </span></a>
<a class="sourceLine" id="cb129-5" data-line-number="5"><span class="st">    </span><span class="kw">theme_bw</span>()</a></code></pre></div>
<p><img src="lineal_files/figure-html/unnamed-chunk-55-1.png" width="480" style="display: block; margin: auto;" /></p>
<p>Parece ser que si existe cierta clusterización por país. Es deir, el gasto en educación por país suele mantenerse dentro de un rango que varía por país.</p>
<p>Cuando lo vemos así no queda tan claro porque son demasiados países, pero aún así pareciera haber cierta clusterización por país (las observaciones se agrupan por país; no parecen ser independientes).</p>
<div class="sourceCode" id="cb130"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb130-1" data-line-number="1"><span class="kw">ggplot</span>(basehys_sinna, <span class="kw">aes</span>(cseduc, gini_slc, <span class="dt">color=</span>country)) <span class="op">+</span><span class="st"> </span></a>
<a class="sourceLine" id="cb130-2" data-line-number="2"><span class="st">    </span><span class="kw">geom_point</span>() <span class="op">+</span><span class="st"> </span></a>
<a class="sourceLine" id="cb130-3" data-line-number="3"><span class="st">    </span><span class="kw">theme_bw</span>()</a></code></pre></div>
<p><img src="lineal_files/figure-html/unnamed-chunk-56-1.png" width="480" style="display: block; margin: auto;" /></p>
<p>Para realizar la estimación por MCO con el error clusterizado, utilizamos el comando <code>lm.cluster</code> del paquete <code>miceadds</code>. Este comando lo que hace es clusterizar los errores estándar según la variable de clusterización indicada. En definitiva, lo que estamos haciendo es permitir que exista correlación del error dentro de los clusters, en este caso países (relajando el supuesto de homocedasticidad).</p>
<p>Los errores estándar robustos por cluster pueden aumentar o disminuir los errores estándar. Es decir, los errores estándar clusterizados pueden ser más grandes o más pequeños que los errores estándar convencionales. La dirección en la que cambiarán los errores estándar depende del signo de la correlación del error intraclase.</p>
<div class="sourceCode" id="cb131"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb131-1" data-line-number="1"><span class="co">#install.packages(&quot;miceadds&quot;)</span></a>
<a class="sourceLine" id="cb131-2" data-line-number="2"></a>
<a class="sourceLine" id="cb131-3" data-line-number="3">modelo_<span class="dv">2</span>_cluster &lt;-<span class="st"> </span>miceadds<span class="op">::</span><span class="kw">lm.cluster</span>( <span class="dt">data=</span>basehys_sinna, <span class="dt">formula=</span>gini_slc<span class="op">~</span><span class="dv">1</span> <span class="op">+</span><span class="st"> </span>cseduc <span class="op">+</span><span class="st"> </span>s_dualism <span class="op">+</span><span class="st"> </span>fdiingdp<span class="op">+</span>rgdpch<span class="op">+</span>ethnicdicot<span class="op">+</span>demrss<span class="op">+</span>cshlth<span class="op">+</span>csssw<span class="op">+</span>legbal<span class="op">+</span>repressauthor, <span class="dt">cluster=</span><span class="st">&quot;country&quot;</span>)</a>
<a class="sourceLine" id="cb131-4" data-line-number="4"><span class="kw">summary</span>(modelo_<span class="dv">2</span>_cluster)</a>
<a class="sourceLine" id="cb131-5" data-line-number="5"><span class="co">## R^2= 0.51 </span></a>
<a class="sourceLine" id="cb131-6" data-line-number="6"><span class="co">## </span></a>
<a class="sourceLine" id="cb131-7" data-line-number="7"><span class="co">##               Estimate Std. Error t value Pr(&gt;|t|)</span></a>
<a class="sourceLine" id="cb131-8" data-line-number="8"><span class="co">## (Intercept)    5.1e+01    3.96616   12.86  7.6e-38</span></a>
<a class="sourceLine" id="cb131-9" data-line-number="9"><span class="co">## cseduc         1.2e+00    0.63271    1.88  6.0e-02</span></a>
<a class="sourceLine" id="cb131-10" data-line-number="10"><span class="co">##  [ reached getOption(&quot;max.print&quot;) -- omitted 9 rows ]</span></a></code></pre></div>
</div>
<div id="un-supuesto-adicional-para-poder-realizar-inferencia" class="section level3">
<h3><span class="header-section-number">8.4.6</span> Un supuesto adicional para poder realizar <strong>inferencia</strong></h3>
<p>Hasta aquí hemos repasado y evaluado empíricamente - en la medida de lo posible - los cinco supuestos del teorema de Gauss-Markov que aseguran que el estimador de MCO sea MELI (Mejor Estimador Lineal Insesgado).</p>
<p>Sin embargo, estos no son suficientes para poder realizar inferencia estadística!
Para esto, debemos asumir un supuesto adicional:</p>
<div id="normalidad-en-la-distribucion-del-error" class="section level4">
<h4><span class="header-section-number">8.4.6.1</span> 6. Normalidad en la distribución del error</h4>
<p>Como hemos visto anteriormente, para testear una hipótesis de significancia individual de un coeficiente estimado por MCO se utilizan los estadísticos <span class="math inline">\(t\)</span> que permiten contrastar el valor <span class="math inline">\(t\)</span> empírico contra un valor <span class="math inline">\(t\)</span> teórico (llamado “valor crítico”) dado un nivel de significancia determinado (<span class="math inline">\(\alpha\)</span>), comúnmente se utiliza un alpha del 5% (por esto se habla de significancia estadística al 95% de confianza).</p>
<p>Sin embargo, para poder realizar esta prueba de hipótesis y, así, hacer inferencia estadística, es necesario asumir que el coeficiente (<span class="math inline">\(\beta\)</span>) sigue una distribución T-Student. Sólo así podemos realizar la prubea de hipótesis utilizando el estadístico <span class="math inline">\(t\)</span>.</p>
<p>El supuesto que permite esto es el de <em>normalidad en la distribución del error</em>. Como el estimador MCO (<span class="math inline">\(\beta\)</span>) es una combinación lineal de los errores (<span class="math inline">\(Y = \beta_0 + \beta_1x + u\)</span>), al asumir distribución normal del error (<span class="math inline">\(u\)</span>) podemos asumir distribución normal del estimador MCO.</p>
<p>Sin embargo, como el error y su varianza son desconocidos, se estiman utilizando los residuos de la regresión (<span class="math inline">\(\hat{u}\)</span>), obteniendo así el error estándar de la estimación. Sin embargo, las estimaciones implican una pérdida de grados de libertad (por cada parámetro estimado pierdo un grado de libertad: n-k-1, n=tamaño muestral, k=cantidad de parámetros estimados - variables del modelo-, 1=la estimación del intercepto, <span class="math inline">\(\beta_0\)</span>) y, por tanto, la distribución del error estándar y, por tanto, del coeficiente, ya no distribuye normal sino T-Student (<span class="math inline">\(\hat\beta \sim t_{n-k-1}\)</span>).</p>
<p>Los siguientes dos comandos nos permiten verificar que los residuos del modelo estimado a través de MCO siguen una distribución T-Student (aproximadamente normal).</p>
<ul>
<li>El comando <code>qqplot</code> viene por default en R y genera un gráfico de probabilidad normal que muestra la distribución de los datos contra una distribución normal teórica esperada. Por tanto, lo que es importante mirar del gráfico es que las observaciones (que son los residuos) no se salgan de las líneas punteadas (que delimitan la distribución normal).</li>
</ul>
<div class="sourceCode" id="cb132"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb132-1" data-line-number="1"><span class="kw">qqPlot</span>(modelo_<span class="dv">2</span><span class="op">$</span>residuals)</a>
<a class="sourceLine" id="cb132-2" data-line-number="2"><span class="co">## [1] 160 118</span></a></code></pre></div>
<p><img src="lineal_files/figure-html/unnamed-chunk-58-1.png" width="480" style="display: block; margin: auto;" /></p>
<ul>
<li>El comando <code>ggpubr</code> del paquete <code>ggpubr</code> permite construir gráficos de densidad. De este modo, puedo graficar los residuos para evaluar visualmente si siguen una distribución aproximadamente normal.</li>
</ul>
<div class="sourceCode" id="cb133"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb133-1" data-line-number="1"><span class="kw">library</span>(ggpubr)</a>
<a class="sourceLine" id="cb133-2" data-line-number="2"><span class="co">## Loading required package: magrittr</span></a>
<a class="sourceLine" id="cb133-3" data-line-number="3"><span class="co">## </span></a>
<a class="sourceLine" id="cb133-4" data-line-number="4"><span class="co">## Attaching package: &#39;magrittr&#39;</span></a>
<a class="sourceLine" id="cb133-5" data-line-number="5"><span class="co">## The following object is masked from &#39;package:texreg&#39;:</span></a>
<a class="sourceLine" id="cb133-6" data-line-number="6"><span class="co">## </span></a>
<a class="sourceLine" id="cb133-7" data-line-number="7"><span class="co">##     extract</span></a>
<a class="sourceLine" id="cb133-8" data-line-number="8"><span class="co">## The following object is masked from &#39;package:purrr&#39;:</span></a>
<a class="sourceLine" id="cb133-9" data-line-number="9"><span class="co">## </span></a>
<a class="sourceLine" id="cb133-10" data-line-number="10"><span class="co">##     set_names</span></a>
<a class="sourceLine" id="cb133-11" data-line-number="11"><span class="co">## The following object is masked from &#39;package:tidyr&#39;:</span></a>
<a class="sourceLine" id="cb133-12" data-line-number="12"><span class="co">## </span></a>
<a class="sourceLine" id="cb133-13" data-line-number="13"><span class="co">##     extract</span></a>
<a class="sourceLine" id="cb133-14" data-line-number="14"><span class="kw">ggdensity</span>(modelo_<span class="dv">2</span><span class="op">$</span>residuals, </a>
<a class="sourceLine" id="cb133-15" data-line-number="15">          <span class="dt">main =</span> <span class="st">&quot;Gráfico de Densidad de los Residuos&quot;</span>)</a></code></pre></div>
<p><img src="lineal_files/figure-html/unnamed-chunk-59-1.png" width="480" style="display: block; margin: auto;" /></p>
<p>Luego de la evaluación de los supuestos y buscar soluciones (cuando es necesario), podemos tener mayor confianza en nuestra estimación y la relación encontrada entre las variables. Aún así, una explicación completa de nuestro hallazgo implica profundizar en por qué y cómo se relacionan estas dos variables.</p>
</div>
</div>
</div>
<div id="seleccion-de-casos" class="section level2">
<h2><span class="header-section-number">8.5</span> Selección de casos</h2>
<p>Cuando estamos trabajando con datos observacionales (y no experimentales), las regresiones MCO no pueden, por sí mismas, responder preguntas de inferencia causal. Es decir, si bien nos permiten dilucidar si es que existe algún tipo de relación entre nuestra variable independiente y dependiente, la investigación quedará incompleta si no logramos evidenciar, con otro tipo de métodos, cómo es que se conectan causalmente estas variables.</p>
<p>La selección de métodos para hacer una investigación está guiada por la pregunta que queremos responder. Por ejemplo, si el interés está en entender cuáles son los determinantes de desigualdad en los países de América Latina y el Caribe, vamos a emplear un análisis estadístico de <em>n-grande</em> que nos permita analizar la mayor cantidad de países posible. De este modo, hemos encontrado en las secciones anteriores que, en promedio, el gasto en educación tiene un efecto positivo sobre los niveles de desigualdad. Sin embargo, el hallazgo de que mayor gasto en educación genere mayores niveles de desigualdad resulta un tanto inquietante y contraintuitivo. Además, un hallazgo como este podría tener implicancias importantes para la elaboración de políticas públicas y consecuencias para la vida real de las personas.</p>
<p>Por tanto, para avanzar en nuestra investigación sería aconsejable intentar responder, por ejemplo, ¿Por qué la educación afecta positivamente los niveles de desigualdad? Es decir, cuál es el <em>mecanismo causal</em> que explica que en los países de América Latina y el Caribe mayor gasto en educación genere mayores niveles de desigualdad. Para responder preguntas de este tipo muchas veces recurrimos a los métodos cualitativos (como por ejemplo, el estudio de casos en profundidad y análisis de <em>process tracing</em>) que nos permitan comprender cuáles son los procesos que explican por qué y cómo se da una relación causal. De este modo, lo que pretendemos hacer es <em>integrar</em> (Seawright, 2016) dos métodos de investigación, donde un método plantea la pregunta de investigación (el análisis estadístico), mientras que otro la pretende responder (estudio de caso). Otra alternativa para fortalecer nuestra investigación podría ser la <em>triangulación</em>: abordar la misma pregunta de investigación pero a partir de distintos métodos que, en su conjunto, nos permitirán una explicación más compleja y completa del fenómeno que pretendemos explicar.</p>
<p>Más allá del camino que se tome (integración o triangulación), el objetivo es combinar métodos distintos para ofrecer una explicación más compleja al fenómeno que nos interesa estudiar. A la combinación de métodos la conocemos como “métodos mixtos” donde justamente el objetivo es abordar un mismo fenómeno a partir de distinas metodologías que permitan capturar distintos ángulos o dimensiones. Si bien existen infinitas formas de combinar métodos, algunos métodos son más compatibles entre sí que otros y, de hecho, algunas combianciones pueden llevarnos a mayor confusión que claridad (Lieberman, 2005).</p>
<p>En esta sección veremos una combinación de métodos que Lieberman (2005) ha denominado <em>nested analysis</em> y no es otra cosa que la combinación de análisis estadístico de una muestra grande con el estudio en profundidad de uno o más casos contenido en dicha muestra. En definitiva, lo que haremos será seleccionar casos (en este caso países) a partir de la estimación de nuestro modelo.</p>
<p>Luego de haber estimado el modelo, el primer paso para seleccionar casos de estudio es calcular los residuos y los valores predichos por el modelo para cada una de nuestras observaciones. Esto porque, para seleccionar nuestros casos de estudio, vamos a estar comparando lo que nuestro modelo predijo contra los valores reales (de la muestra) de cada uno de esos casos: la diferencia entre estos dos valores (los predichos y los reales) son los residuos.</p>
<p>Para extraer del modelo los residuos y los valores predichos utilizamos el comando <code>augment</code> del paquete <code>broom</code>. Lo que hace este comando es crear una nueva base de datos que le agrega variables sobre el modelo a la base original (para cada caso): valores predichos, errores estándar, el residuo y el residuo estandarizado, entre otros estadísticos.</p>
<p>Residuos y valores predichos:</p>
<div class="sourceCode" id="cb134"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb134-1" data-line-number="1">modelo_aug &lt;-<span class="st"> </span>broom<span class="op">::</span><span class="kw">augment</span>(modelo_<span class="dv">2</span>, <span class="dt">data =</span> basehys_sinna)</a>
<a class="sourceLine" id="cb134-2" data-line-number="2">modelo_aug</a>
<a class="sourceLine" id="cb134-3" data-line-number="3"><span class="co">## # A tibble: 167 x 32</span></a>
<a class="sourceLine" id="cb134-4" data-line-number="4"><span class="co">##       X1 country id      idn  year gini_merge demrss gini_slc rgdpch cseduc</span></a>
<a class="sourceLine" id="cb134-5" data-line-number="5"><span class="co">##    &lt;dbl&gt; &lt;chr&gt;   &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt;      &lt;dbl&gt;  &lt;dbl&gt;    &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;</span></a>
<a class="sourceLine" id="cb134-6" data-line-number="6"><span class="co">##  1    13 Argent… ARG       1  1982       40.2      2     40.2  7711.    2.5</span></a>
<a class="sourceLine" id="cb134-7" data-line-number="7"><span class="co">##  2    14 Argent… ARG       1  1983       40.4      2     40.4  7907.    2.8</span></a>
<a class="sourceLine" id="cb134-8" data-line-number="8"><span class="co">##  3    21 Argent… ARG       1  1990       43.1      4     43.1  6823.    3.3</span></a>
<a class="sourceLine" id="cb134-9" data-line-number="9"><span class="co">##  4    22 Argent… ARG       1  1991       44        4     44    7392.    3.3</span></a>
<a class="sourceLine" id="cb134-10" data-line-number="10"><span class="co">##  5    23 Argent… ARG       1  1992       43        4     43    7986.    3.5</span></a>
<a class="sourceLine" id="cb134-11" data-line-number="11"><span class="co">##  6    24 Argent… ARG       1  1993       42        4     42    8411.    4.1</span></a>
<a class="sourceLine" id="cb134-12" data-line-number="12"><span class="co">##  7    25 Argent… ARG       1  1994       43        4     43    8764.    4.1</span></a>
<a class="sourceLine" id="cb134-13" data-line-number="13"><span class="co">##  8    26 Argent… ARG       1  1995       46        4     46    8578.    4.3</span></a>
<a class="sourceLine" id="cb134-14" data-line-number="14"><span class="co">##  9    27 Argent… ARG       1  1996       46        4     46    8905.    4.2</span></a>
<a class="sourceLine" id="cb134-15" data-line-number="15"><span class="co">## 10    28 Argent… ARG       1  1997       46        4     46    9425.    4.3</span></a>
<a class="sourceLine" id="cb134-16" data-line-number="16"><span class="co">## # ... with 157 more rows, and 22 more variables: cshlth &lt;dbl&gt;,</span></a>
<a class="sourceLine" id="cb134-17" data-line-number="17"><span class="co">## #   csssw &lt;dbl&gt;, ner2wdi &lt;dbl&gt;, ethnicdicot &lt;dbl&gt;, emplyagwdi &lt;dbl&gt;,</span></a>
<a class="sourceLine" id="cb134-18" data-line-number="18"><span class="co">## #   fdiingdp &lt;dbl&gt;, unstockgdp &lt;dbl&gt;, aggdpwdi &lt;dbl&gt;, cpiprct &lt;dbl&gt;,</span></a>
<a class="sourceLine" id="cb134-19" data-line-number="19"><span class="co">## #   pop014wdi &lt;dbl&gt;, s_dualism &lt;dbl&gt;, repressauthor &lt;dbl&gt;, legbal &lt;dbl&gt;,</span></a>
<a class="sourceLine" id="cb134-20" data-line-number="20"><span class="co">## #   execpart &lt;dbl&gt;, gini_wiid &lt;dbl&gt;, cseduc2 &lt;dbl&gt;, .fitted &lt;dbl&gt;,</span></a>
<a class="sourceLine" id="cb134-21" data-line-number="21"><span class="co">## #   .resid &lt;dbl&gt;, .std.resid &lt;dbl&gt;, .hat &lt;dbl&gt;, .sigma &lt;dbl&gt;,</span></a>
<a class="sourceLine" id="cb134-22" data-line-number="22"><span class="co">## #   .cooksd &lt;dbl&gt;</span></a></code></pre></div>
<div id="que-casos-seleccionar" class="section level3">
<h3><span class="header-section-number">8.5.1</span> ¿Qué casos seleccionar?</h3>
<p>Los casos seleccionados para un estudio en profundidad se eligen de una población, y las razones de esta selección dependen de la forma en que están situados dentro de esa población. En este sentido, de acuerdo a Gerring (2006), un estudio de caso no puede existir aislado del análisis de un n relativamente grande de casos cruzados.</p>
<p>El mejor caso de estudio dependerá de cuál es el objetivo para el cual se está seleccionando el caso. De este modo, la selección de casos debe ser intencional y no aleatoria (Gerring, 2006).</p>
<p>A continuación se detallan distintos objetivos para los que se seleccionan casos y su implementación en R a partir del modelo estadístico sobre los determinantes de la desigualdad en América Latina y el Caribe.</p>
</div>
<div id="casos-tipicos" class="section level3">
<h3><span class="header-section-number">8.5.2</span> Casos Típicos</h3>
<p>Uno de los objetivos de la selección de casos radica en ilustrar la relación encontrada y profundizar sobre los mecanismos que vinculan la variable independiente con la dependiente. Si este es nuestro objetivo, entonces querremos seleccionar casos que sean ejemplos típicos de la relación que encontramos con el análisis estadístico.</p>
<p>Por tanto, lo que buscamos es encontrar aquellos casos con residual más pequeño. Es decir, los casos que nuestro modelo predijo mejor: <em>on the line cases</em> (casos que están sobre la línea de regresión).</p>
<p>Para esto, graficaremos a partir de la base de datos creada con el comando <code>augment</code> los valores predichos sobre los residuos (los cuales transformaremos a valor absoluto porque, por construcción, siempre hay residuos negativos). Además, para identificar los casos, le pediremos al <code>ggplot</code>que agregue las etiquetas de los dos (<code>top_n(-2, .resid_abs)</code>) países (<code>mapping=aes(label=country)</code>) con menores residuos. La línea horizontal (<code>geom_hline(aes(yintercept = 0))</code>) la incorporamos al gráfico para visualizar donde el residuo es nulo (allí se encontrarán los casos que el modelo predijo perfectamente: los más típicos).</p>
<div class="sourceCode" id="cb135"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb135-1" data-line-number="1">ggplot2<span class="op">::</span><span class="kw">qplot</span>(<span class="dt">data =</span> modelo_aug, <span class="dt">x =</span> .fitted, <span class="dt">y =</span> .resid, <span class="dt">geom =</span> <span class="st">&quot;point&quot;</span>,</a>
<a class="sourceLine" id="cb135-2" data-line-number="2">      <span class="dt">main =</span> <span class="st">&quot;Casos típicos&quot;</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb135-3" data-line-number="3"><span class="st">  </span><span class="kw">geom_hline</span>(<span class="kw">aes</span>(<span class="dt">yintercept =</span> <span class="dv">0</span>)) <span class="op">+</span></a>
<a class="sourceLine" id="cb135-4" data-line-number="4"><span class="st">  </span><span class="kw">geom_text</span>(<span class="dt">data =</span> . <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb135-5" data-line-number="5"><span class="st">              </span><span class="kw">mutate</span>(<span class="dt">.resid_abs =</span> <span class="kw">abs</span>(.resid)) <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb135-6" data-line-number="6"><span class="st">              </span><span class="kw">top_n</span>(<span class="op">-</span><span class="dv">2</span>, .resid_abs),</a>
<a class="sourceLine" id="cb135-7" data-line-number="7">            <span class="dt">mapping =</span> <span class="kw">aes</span>(<span class="dt">label =</span> country))</a></code></pre></div>
<p><img src="lineal_files/figure-html/unnamed-chunk-61-1.png" width="480" style="display: block; margin: auto;" /></p>
<p>De acuerdo a lo graficado, Costa Rica y Bolivia son dos casos típicos del modelo estimado sobre los determinantes de la desigualdad en América Latina y el Caribe.</p>
</div>
<div id="casos-desviados" class="section level3">
<h3><span class="header-section-number">8.5.3</span> Casos desviados</h3>
<p>Los casos desviados son aquellos que, dado nuestro modelo, presentan un comportamiento no esperado; son desviados pues no pueden ser explicados por el modelo general. En definitiva son “anomalías teóricas” (Gerring, 2006: 106). Por lo general seleccionamos este tipo de casos para explorar nuevas hipótesis y que, eventualmente pueden arrojar luz sobre variables omitidas del modelo estadístico.</p>
<p>La selección de casos desviados funciona de manera opuesta a la selección de casos típicos: en lugar de seleccionar aquellos con menor residual, se seleccionan los casos cuyo valor predicho difiere más del valor real (mayor residual).</p>
<div class="sourceCode" id="cb136"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb136-1" data-line-number="1">ggplot2<span class="op">::</span><span class="kw">qplot</span>(<span class="dt">data =</span> modelo_aug, <span class="dt">x =</span> .fitted, <span class="dt">y =</span> .resid, <span class="dt">geom =</span> <span class="st">&quot;point&quot;</span>,</a>
<a class="sourceLine" id="cb136-2" data-line-number="2">      <span class="dt">main =</span> <span class="st">&quot;Casos desviados&quot;</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb136-3" data-line-number="3"><span class="st">  </span><span class="kw">geom_hline</span>(<span class="kw">aes</span>(<span class="dt">yintercept =</span> <span class="dv">0</span>)) <span class="op">+</span></a>
<a class="sourceLine" id="cb136-4" data-line-number="4"><span class="st">  </span><span class="kw">geom_text</span>(<span class="dt">data =</span> . <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb136-5" data-line-number="5"><span class="st">              </span><span class="kw">mutate</span>(<span class="dt">.resid_abs =</span> <span class="kw">abs</span>(.resid)) <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb136-6" data-line-number="6"><span class="st">              </span><span class="kw">top_n</span>(<span class="dv">2</span>, .resid_abs),</a>
<a class="sourceLine" id="cb136-7" data-line-number="7">            <span class="dt">mapping =</span> <span class="kw">aes</span>(<span class="dt">label =</span> country))</a></code></pre></div>
<p><img src="lineal_files/figure-html/unnamed-chunk-62-1.png" width="480" style="display: block; margin: auto;" /></p>
</div>
<div id="casos-influyentes" class="section level3">
<h3><span class="header-section-number">8.5.4</span> Casos Influyentes</h3>
<p>Los casos influyentes son aquellos casos que muestran valores extremos pero que tienen mucho peso sobre la relación encontrada por el modelo. Es decir, son casos que influyen en la pendiente de regresión que observamos (recuerda que la pendiente está dada por el coeficiente de regresión <span class="math inline">\(\beta_i\)</span>).</p>
<p>Se trata de casos que, al igual que los casos desviados, también son inusuales aunque de un modo distinto. Cuando selecciono un caso influyente es para confirmar el modelo, mientras que la selección de casos desviados se utiliza para explorar hipótesis alternativas (Gerring, 2006).</p>
<p>Para identificar los casos infulyentes podemos tomar dos caminos:</p>
<ol style="list-style-type: decimal">
<li>Por un lado, se pueden utilizar los <strong>dfbetas</strong> que son estadísticos que indican cuánto el coeficiente de regresión <span class="math inline">\(\beta_i\)</span> cambia en unidades de desviación estándar si la <em>i-ésima</em> observación fuera eliminada. Por tanto, tendremos un <em>dfbeta</em> para cada observación que indica cuánto cambiaría el <span class="math inline">\(\beta_i\)</span> de la variable <em>cseduc</em> (gasto en educación), si ese caso no estuviera presente. Por tanto, cuánto más varíe la pendiente (<span class="math inline">\(\beta_i\)</span>) con la ausencia del caso, más influyente será dicho caso.</li>
</ol>
<p>De este modo, lo que queremos es seleccionar los casos que generan mayores cambios en desviación estándar del <span class="math inline">\(\beta_i\)</span> si fuesen eliminados. Así, los casos influyentes pueden ser utilizados para confirmar la teoría, aunque si su eliminación anula la relación encontrada (si al quitar el caso <span class="math inline">\(\beta_i\)</span> deja de ser significativo), es también útil para explorar nuevas hipótesis o identificar variables que hayan sido omitidas en el modelo.</p>
<div class="sourceCode" id="cb137"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb137-1" data-line-number="1">modelo_aug <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb137-2" data-line-number="2"><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">dfb_cseduc =</span> <span class="kw">as.tibble</span>(<span class="kw">dfbetas</span>(modelo_<span class="dv">2</span>))<span class="op">$</span>cseduc) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb137-3" data-line-number="3"><span class="st">  </span><span class="kw">arrange</span>(<span class="op">-</span>dfb_cseduc) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb137-4" data-line-number="4"><span class="st">  </span><span class="kw">slice</span>(<span class="dv">1</span><span class="op">:</span><span class="dv">3</span>) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb137-5" data-line-number="5"><span class="st">  </span>dplyr<span class="op">::</span><span class="kw">select</span>(country, dfb_cseduc)</a>
<a class="sourceLine" id="cb137-6" data-line-number="6"><span class="co">## # A tibble: 3 x 2</span></a>
<a class="sourceLine" id="cb137-7" data-line-number="7"><span class="co">##   country   dfb_cseduc</span></a>
<a class="sourceLine" id="cb137-8" data-line-number="8"><span class="co">##   &lt;chr&gt;          &lt;dbl&gt;</span></a>
<a class="sourceLine" id="cb137-9" data-line-number="9"><span class="co">## 1 Barbados       0.483</span></a>
<a class="sourceLine" id="cb137-10" data-line-number="10"><span class="co">## 2 Jamaica        0.298</span></a>
<a class="sourceLine" id="cb137-11" data-line-number="11"><span class="co">## 3 Venezuela      0.241</span></a></code></pre></div>
<ol start="2" style="list-style-type: decimal">
<li>Utilizando la <strong>distancia de Cook</strong> que se basa en una lógica muy similar a los <em>dfbetas</em>. La distancia de Cook considera los valores que asume cada observación en la variable independiente y dependiente para calcular cuánto varían los coeficientes cuando en ausencia de cada caso. En definitiva, esta distancia lo que nos indica es qué tanto influye cada caso en la regresión en su conjunto: a mayor distancia de Cook, mayor es la contribuión del caso a las inferencias del modelo. Es decir, los casos con gran distancia de Cook son centrales para mantener las conclusiones analíticas (esto sobre todo con muestras relativamente pequeñas, con muestras muy grandes es menos probable que existan casos con tal poder de influencia).</li>
</ol>
<p>Es por esto que seleccionar estos casos para un estudio en profundidad puede ser relevante: si en el estudio cualitativo de un caso influyente no podemos confirmar nuestra teoría, es poco probable que lo podamos confirmar en otros casos.</p>
<div class="sourceCode" id="cb138"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb138-1" data-line-number="1">ggplot2<span class="op">::</span><span class="kw">qplot</span>(<span class="dt">data =</span> modelo_aug, <span class="dt">x =</span> .fitted, <span class="dt">y =</span> .cooksd, <span class="dt">geom =</span> <span class="st">&quot;point&quot;</span>,</a>
<a class="sourceLine" id="cb138-2" data-line-number="2">      <span class="dt">main =</span> <span class="st">&quot;Casos influyentes&quot;</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb138-3" data-line-number="3"><span class="st">  </span><span class="kw">geom_text</span>(<span class="dt">data =</span> . <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb138-4" data-line-number="4"><span class="st">              </span><span class="kw">top_n</span>(<span class="dv">3</span>, .cooksd),</a>
<a class="sourceLine" id="cb138-5" data-line-number="5">            <span class="dt">mapping =</span> <span class="kw">aes</span>(<span class="dt">label =</span> country))</a></code></pre></div>
<p><img src="lineal_files/figure-html/unnamed-chunk-64-1.png" width="480" style="display: block; margin: auto;" /></p>
</div>
<div id="casos-extremos" class="section level3">
<h3><span class="header-section-number">8.5.5</span> Casos extremos</h3>
<p>La selección de casos extremos supone identificar observaciones que se ubiquen lejos de la media de la distribución de la variable independiente o dependiente (que tenga valores extremos). El interés está en la “rareza” del valor que asume ese caso en la variable.</p>
<p>Es importante destacar que un caso extremos puede coincidir tanto con un caso típico como con uno desviado (Gerring, 2006). El estudio en profundidad de casos extremos es más bien exploratorio: es una forma de evaluar y buscar causas posibles de <span class="math inline">\(y\)</span> o efectos posibles de <span class="math inline">\(x\)</span>. Esta técnica se recomienda para cuando no hay demasiada teoría elaborada y, por tanto, la investigación está concentrada en la construcción teórica.</p>
<p>Un trabajo clásico de selección de casos extremos en la variable dependiente es el de Theda Skocpol (1979) sobre Revoluciones Sociales, donde la teoría se desarrolla en base a tres casos que presentan el valor más extremo de revolución (de hecho son los únicos casos que presentan dicho valor de acuerdo a Skocpol).</p>
<div id="casos-extremos-en-la-variable-independiente-x" class="section level4">
<h4><span class="header-section-number">8.5.5.1</span> Casos extremos en la variable independiente: <span class="math inline">\(x\)</span></h4>
<p>Para seleccionar casos extremos en la variable independiente, a partir del modelo estadístico estimado, simplemente calculamos las diferencias - en valor absoluto - entre el valor de cada caso y la media muestral del gasto en educación. Luego, se seleccionan los tres casos que muestran mayor diferencia entre la media muestral y su valor de la variable independiente.
Primero, calculamos la media para tener la referencia.</p>
<div class="sourceCode" id="cb139"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb139-1" data-line-number="1"><span class="kw">mean</span>(modelo_aug<span class="op">$</span>cseduc, <span class="dt">na.rm =</span> T)</a>
<a class="sourceLine" id="cb139-2" data-line-number="2"><span class="co">## [1] 4</span></a>
<a class="sourceLine" id="cb139-3" data-line-number="3"></a>
<a class="sourceLine" id="cb139-4" data-line-number="4">modelo_aug <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb139-5" data-line-number="5"><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">dif_cseduc =</span> <span class="kw">abs</span>(cseduc <span class="op">-</span><span class="st"> </span><span class="kw">mean</span>(cseduc, <span class="dt">na.rm =</span> T))) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb139-6" data-line-number="6"><span class="st">  </span><span class="kw">top_n</span>(<span class="dv">2</span>, dif_cseduc) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb139-7" data-line-number="7"><span class="st">  </span><span class="kw">arrange</span>(<span class="op">-</span>dif_cseduc) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb139-8" data-line-number="8"><span class="st">  </span>dplyr<span class="op">::</span><span class="kw">select</span>(country, cseduc, dif_cseduc)</a>
<a class="sourceLine" id="cb139-9" data-line-number="9"><span class="co">## # A tibble: 2 x 3</span></a>
<a class="sourceLine" id="cb139-10" data-line-number="10"><span class="co">##   country  cseduc dif_cseduc</span></a>
<a class="sourceLine" id="cb139-11" data-line-number="11"><span class="co">##   &lt;chr&gt;     &lt;dbl&gt;      &lt;dbl&gt;</span></a>
<a class="sourceLine" id="cb139-12" data-line-number="12"><span class="co">## 1 Barbados    0.8       3.16</span></a>
<a class="sourceLine" id="cb139-13" data-line-number="13"><span class="co">## 2 Honduras    6.8       2.84</span></a></code></pre></div>
<p>Lo graficamos para una mejor visualización:</p>
<div class="sourceCode" id="cb140"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb140-1" data-line-number="1">modelo_aug<span class="op">$</span>dif_cseduc =<span class="st"> </span><span class="kw">abs</span>(modelo_aug<span class="op">$</span>cseduc <span class="op">-</span><span class="st"> </span><span class="kw">mean</span>(modelo_aug<span class="op">$</span>cseduc, <span class="dt">na.rm =</span> T))</a>
<a class="sourceLine" id="cb140-2" data-line-number="2"></a>
<a class="sourceLine" id="cb140-3" data-line-number="3">ggplot2<span class="op">::</span><span class="kw">qplot</span>(<span class="dt">data =</span> modelo_aug, <span class="dt">x =</span> .fitted, <span class="dt">y =</span> dif_cseduc, <span class="dt">geom =</span> <span class="st">&quot;point&quot;</span>,</a>
<a class="sourceLine" id="cb140-4" data-line-number="4">      <span class="dt">main =</span> <span class="st">&quot;Casos extremos en Gasto en Educación&quot;) +</span></a>
<a class="sourceLine" id="cb140-5" data-line-number="5"><span class="st">  geom_text(data = . %&gt;% </span></a>
<a class="sourceLine" id="cb140-6" data-line-number="6"><span class="st">              top_n(2, dif_cseduc),</span></a>
<a class="sourceLine" id="cb140-7" data-line-number="7"><span class="st">            mapping = aes(label = country))</span></a></code></pre></div>
<p><img src="lineal_files/figure-html/unnamed-chunk-66-1.png" width="480" style="display: block; margin: auto;" /></p>
</div>
<div id="casos-extremos-en-la-variable-dependiente-y" class="section level4">
<h4><span class="header-section-number">8.5.5.2</span> Casos extremos en la variable dependiente: <span class="math inline">\(y\)</span></h4>
<p>La selección de casos extremos en la variable dependiente se realiza del mismo modo que con los casos extremos en <span class="math inline">\(x\)</span>. Solo que ahora calculamos las diferencias - en valor absoluto - entre el valor de cada caso en la variable dependiente y la media muestral (Índice de Gini en el ejemplo). Luego, se seleccionan los tres casos que muestran mayor diferencia entre la media muestral y su valor de la variable dependiente.
Primero, calculamos la media para tener la referencia.</p>
<div class="sourceCode" id="cb141"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb141-1" data-line-number="1"><span class="kw">mean</span>(modelo_aug<span class="op">$</span>gini_slc, <span class="dt">na.rm =</span> T)</a>
<a class="sourceLine" id="cb141-2" data-line-number="2"><span class="co">## [1] 50</span></a>
<a class="sourceLine" id="cb141-3" data-line-number="3"></a>
<a class="sourceLine" id="cb141-4" data-line-number="4">modelo_aug <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb141-5" data-line-number="5"><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">dif_gini =</span> <span class="kw">abs</span>(gini_slc <span class="op">-</span><span class="st"> </span><span class="kw">mean</span>(gini_slc, <span class="dt">na.rm =</span> T))) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb141-6" data-line-number="6"><span class="st">  </span><span class="kw">top_n</span>(<span class="dv">2</span>, dif_gini) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb141-7" data-line-number="7"><span class="st">  </span><span class="kw">arrange</span>(<span class="op">-</span>dif_gini) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb141-8" data-line-number="8"><span class="st">  </span>dplyr<span class="op">::</span><span class="kw">select</span>(country, gini_slc, dif_gini)</a>
<a class="sourceLine" id="cb141-9" data-line-number="9"><span class="co">## # A tibble: 2 x 3</span></a>
<a class="sourceLine" id="cb141-10" data-line-number="10"><span class="co">##   country  gini_slc dif_gini</span></a>
<a class="sourceLine" id="cb141-11" data-line-number="11"><span class="co">##   &lt;chr&gt;       &lt;dbl&gt;    &lt;dbl&gt;</span></a>
<a class="sourceLine" id="cb141-12" data-line-number="12"><span class="co">## 1 Barbados     28.9     21.4</span></a>
<a class="sourceLine" id="cb141-13" data-line-number="13"><span class="co">## 2 Jamaica      66       15.7</span></a></code></pre></div>
<p>Podemos también graficarlo para una mejor visualización:</p>
<div class="sourceCode" id="cb142"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb142-1" data-line-number="1">modelo_aug<span class="op">$</span>dif_gini =<span class="st"> </span><span class="kw">abs</span>(modelo_aug<span class="op">$</span>gini_slc <span class="op">-</span><span class="st"> </span><span class="kw">mean</span>(modelo_aug<span class="op">$</span>gini_slc, <span class="dt">na.rm =</span> T))</a>
<a class="sourceLine" id="cb142-2" data-line-number="2"></a>
<a class="sourceLine" id="cb142-3" data-line-number="3">ggplot2<span class="op">::</span><span class="kw">qplot</span>(<span class="dt">data =</span> modelo_aug, <span class="dt">x =</span> .fitted, <span class="dt">y =</span> dif_gini, <span class="dt">geom =</span> <span class="st">&quot;point&quot;</span>,</a>
<a class="sourceLine" id="cb142-4" data-line-number="4">      <span class="dt">main =</span> <span class="st">&quot;Casos extremos en Índice de Gini&quot;</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb142-5" data-line-number="5"><span class="st">  </span><span class="kw">geom_text</span>(<span class="dt">data =</span> . <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb142-6" data-line-number="6"><span class="st">              </span><span class="kw">top_n</span>(<span class="dv">2</span>, dif_gini),</a>
<a class="sourceLine" id="cb142-7" data-line-number="7">            <span class="dt">mapping =</span> <span class="kw">aes</span>(<span class="dt">label =</span> country))</a></code></pre></div>
<p><img src="lineal_files/figure-html/unnamed-chunk-68-1.png" width="480" style="display: block; margin: auto;" /></p>
</div>
</div>
<div id="casos-mas-similares" class="section level3">
<h3><span class="header-section-number">8.5.6</span> Casos más similares</h3>
<p>La selección de casos similares supone identificar <em>dos</em> casos que son similares en todas las variables salvo en las variables de interés. Cuando estamos en una etapa exploratoria de nuestra investigación y no tenemos una teoría (no tenemos identificada una variable independiente en particular), se buscan un par de casos que sean iguales en sus variables independientes pero que difieran en la variable de resultado (dependiente). De este modo, el objetivo será identificar uno o más factores que difieran entre los casos y que puedan explicar la divergencia en el resultado.</p>
<p>Sin embargo, cuando ya tenemos una teoría sobre cómo se vincula una determinada variable independiente con la variable dependiente, la seleción de casos similares se enfoca en identificar dos casos que sean similares en todas las variables independientes, salvo en la variable independiente de interés (y también en la dependiente). Aquí, el interés estará en confirmar el argumento y profundizar en los mecanismos causales que conectan la variable independiente con la dependiente.</p>
<p>Para seleccionar casos similares, se recomienda utilizar alguna técnica de <em>matching</em> (Gerring, 2006: 134). En simples palabras, esta técnica supone justamente juntar pares (en su versión más básica) de observaciones que sean lo más similares posible en todas las variables de control pero que difieran en la variable independiente de interés. Para simplificar el análisis, la variable independiente suele ser dicotómica (0 y 1) emulando una situación experimental donde hay una tratamiento (1) y un placebo o control (0). De este modo, el objetivo es “matchear” (la menor distancia posible entre los valores de las variables de control) pares donde una observación pertenece al grupo del tratamiento y la otra al grupo de control.</p>
<p>Como encontrar pares que coincidan en todas las variables de control es, por lo general, bastante exigente, se suele utilizar un procedimiento denominado como matching en base al puntaje de propensión (<em>propensity score</em>). Este procedimiento supone encontrar pares de observaciones que tengan probabilidades estimadas similares de estar en el grupo de tratamiento (tener valor 1 en la variable independiente de interés), condicionadas en las variables de control.</p>
<p>Para implementar esta selección de casos en nuestra investigación vamos a crear una variable dummy de tratamiento (para la variable de gasto en educación), donde 0 es gasto menor a la media muestral de gasto y 1 gasto mayor a la media.</p>
<div class="sourceCode" id="cb143"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb143-1" data-line-number="1">media &lt;-<span class="st"> </span><span class="kw">mean</span>(basehys_sinna<span class="op">$</span>cseduc, <span class="dt">na.rm =</span> <span class="ot">TRUE</span>)</a>
<a class="sourceLine" id="cb143-2" data-line-number="2">basehys_sinna<span class="op">$</span>tratamiento &lt;-<span class="st"> </span><span class="kw">ifelse</span>(basehys_sinna<span class="op">$</span>cseduc <span class="op">&gt;</span><span class="st"> </span>media, <span class="dv">1</span>, <span class="dv">0</span>)</a></code></pre></div>
<p>Ahora que tenemos la variable de tratamiento, podemos calcular los puntajes de propensión. Es decir, la probabilidad de estar en el grupo de tratamiento (gasto en educación mayor a la media muestral), condicionado en las variables de control del modelo. Este cálculo se hace a partir de un modelo logit (VER CAPÍTULO ##), ya que nuestra variable dependiente es una variable dicotómica.</p>
<div class="sourceCode" id="cb144"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb144-1" data-line-number="1">propensityscore &lt;-<span class="st"> </span><span class="kw">glm</span>(tratamiento <span class="op">~</span><span class="st"> </span>s_dualism <span class="op">+</span><span class="st"> </span>fdiingdp<span class="op">+</span>rgdpch<span class="op">+</span>pop014wdi<span class="op">+</span>ethnicdicot<span class="op">+</span>demrss<span class="op">+</span><span class="st"> </span>demrss<span class="op">*</span>csssw<span class="op">+</span>cshlth<span class="op">+</span>csssw<span class="op">+</span>legbal<span class="op">+</span>repressauthor, </a>
<a class="sourceLine" id="cb144-2" data-line-number="2">                          <span class="dt">data   =</span> basehys_sinna, </a>
<a class="sourceLine" id="cb144-3" data-line-number="3">                          <span class="dt">family =</span> <span class="kw">binomial</span>(<span class="dt">link =</span> logit), </a>
<a class="sourceLine" id="cb144-4" data-line-number="4">                          <span class="dt">na.action =</span> na.exclude)</a></code></pre></div>
<p>Al igual que como hicimos con el modelo general de los determinantes de la desigualdad, crearemos una base de datos con el comando <code>augment</code> para guardar algunos estadísticos que nos serán útiles para seleccionar los casos.</p>
<div class="sourceCode" id="cb145"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb145-1" data-line-number="1">propensity_scores&lt;-<span class="st"> </span>broom<span class="op">::</span><span class="kw">augment</span>(propensityscore, <span class="dt">data =</span> basehys_sinna, <span class="dt">type.predict =</span> <span class="st">&quot;response&quot;</span>) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb145-2" data-line-number="2"><span class="st">  </span>dplyr<span class="op">::</span><span class="kw">select</span>(<span class="dt">propensity_scores =</span> .fitted, country, tratamiento, year, gini_slc)</a></code></pre></div>
<p>Ahora, identificaremos los casos con menores puntajes de propensión tanto para el grupo de tratamiento (alto gasto en educación) como para el grupo de control (bajo gasto en educación), para decidir la selección de casos. Cabe destacar que esto también puede hacerse para altos puntajes de propensión, o para cualquier puntaje de propensión, lo importante es que tengan puntajes similares o “cercanos” (igual probabilidad de recibir el tratamiento).</p>
<p>Casos con bajo puntaje de propensión, en el grupo de países con gasto en educación mayor a la media muestral:</p>
<div class="sourceCode" id="cb146"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb146-1" data-line-number="1">propensity_scores <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb146-2" data-line-number="2"><span class="st">  </span><span class="kw">filter</span>(tratamiento <span class="op">==</span><span class="st"> </span><span class="dv">1</span>) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb146-3" data-line-number="3"><span class="st">  </span><span class="kw">arrange</span>(propensity_scores) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb146-4" data-line-number="4"><span class="st">  </span>dplyr<span class="op">::</span><span class="kw">select</span>(country, year, propensity_scores) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb146-5" data-line-number="5"><span class="st">  </span><span class="kw">slice</span>(<span class="dv">1</span><span class="op">:</span><span class="dv">2</span>)</a>
<a class="sourceLine" id="cb146-6" data-line-number="6"><span class="co">## # A tibble: 2 x 3</span></a>
<a class="sourceLine" id="cb146-7" data-line-number="7"><span class="co">##   country  year propensity_scores</span></a>
<a class="sourceLine" id="cb146-8" data-line-number="8"><span class="co">##   &lt;chr&gt;   &lt;dbl&gt;             &lt;dbl&gt;</span></a>
<a class="sourceLine" id="cb146-9" data-line-number="9"><span class="co">## 1 Brazil   1984            0.0815</span></a>
<a class="sourceLine" id="cb146-10" data-line-number="10"><span class="co">## 2 Mexico   2000            0.159</span></a></code></pre></div>
<p>Por otra parte, veamos cuáles son los casos con bajo puntaje de propensión pero entre aquellos países con gasto en educación menor a la media muestral:</p>
<div class="sourceCode" id="cb147"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb147-1" data-line-number="1">propensity_scores <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb147-2" data-line-number="2"><span class="st">  </span><span class="kw">filter</span>(tratamiento <span class="op">==</span><span class="st"> </span><span class="dv">0</span>) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb147-3" data-line-number="3"><span class="st">  </span><span class="kw">arrange</span>(propensity_scores) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb147-4" data-line-number="4"><span class="st">  </span>dplyr<span class="op">::</span><span class="kw">select</span>(country, year, propensity_scores) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb147-5" data-line-number="5"><span class="st">  </span><span class="kw">slice</span>(<span class="dv">1</span><span class="op">:</span><span class="dv">2</span>)</a>
<a class="sourceLine" id="cb147-6" data-line-number="6"><span class="co">## # A tibble: 2 x 3</span></a>
<a class="sourceLine" id="cb147-7" data-line-number="7"><span class="co">##   country    year propensity_scores</span></a>
<a class="sourceLine" id="cb147-8" data-line-number="8"><span class="co">##   &lt;chr&gt;     &lt;dbl&gt;             &lt;dbl&gt;</span></a>
<a class="sourceLine" id="cb147-9" data-line-number="9"><span class="co">## 1 Paraguay   1994           0.00309</span></a>
<a class="sourceLine" id="cb147-10" data-line-number="10"><span class="co">## 2 Argentina  1982           0.00673</span></a></code></pre></div>
<p>De acuerdo a los resultados obtenidos, tanto Brasil como México podrían ser seleccionados para ser comparados con Paraguay o Argentina para realizar estudios de casos más similares en profundidad.</p>
</div>
<div id="casos-mas-diferentes" class="section level3">
<h3><span class="header-section-number">8.5.7</span> Casos más diferentes</h3>
<p>El procedimiento de selección de casos más diferentes supone una lógica opuesta a la de casos más similares. Aquí se buscan casos que sean en realidad distintos en las variables de control, pero que sean similares en el valor asumido por la variable independiente de interés y la variable dependiente. En definitiva, lo que buscamos son distintos puntajes de propensión pero coincidencia en la variable independiente y dependiente.</p>
<p>Cabe destacar que este tipo de selección de casos es útil cuando se asume “causalidad única” (Gerring, 2006: 143). Es decir, cuando la variable dependiente es causada por una única variable (o cuando nos interesa explicar el efecto de un sólo factor). Si el interés es indagar sobre la combinación de distintos factores causales, este procedimiento de selección de casos no resulta el más indicado.</p>
<p>Para seleccionar casos “más diferentes” también utilizaremos los puntajes de propensión, pero ahora nos interesa seleccionar en base a iguales resultados en la variable dependiente, así como en la variable independiente y con puntajes de propensión muy distintos.</p>
<p>Veamos, entonces, cuáles son los casos donde hay coincidencia en la variable independiente de interés y en la de resultado pero con diferente puntaje de propensión.</p>
<p>Primero creamos una variable dummy para el gini mayor y menor a la media. Luego, identificamos los casos tratados con menor puntaje de propensión (baja probabilidad de tener gasto mayor a la media) para valores de gini mayores a la media muestral y valores de gasto en educación también mayor a la media muestral:</p>
<div class="sourceCode" id="cb148"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb148-1" data-line-number="1">propensity_scores<span class="op">$</span>gini &lt;-<span class="st"> </span><span class="kw">ifelse</span>(propensity_scores<span class="op">$</span>gini_slc <span class="op">&gt;</span><span class="st"> </span>(<span class="kw">mean</span>(propensity_scores<span class="op">$</span>gini_slc, <span class="dt">na.rm =</span> <span class="ot">TRUE</span>)), <span class="dv">1</span>, <span class="dv">0</span>)</a>
<a class="sourceLine" id="cb148-2" data-line-number="2"></a>
<a class="sourceLine" id="cb148-3" data-line-number="3">propensity_scores <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb148-4" data-line-number="4"><span class="st">  </span><span class="kw">filter</span>(gini <span class="op">==</span><span class="st"> </span><span class="dv">1</span> <span class="op">&amp;</span><span class="st"> </span>tratamiento<span class="op">==</span><span class="dv">1</span>) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb148-5" data-line-number="5"><span class="st">  </span><span class="kw">arrange</span>(propensity_scores) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb148-6" data-line-number="6"><span class="st">  </span>dplyr<span class="op">::</span><span class="kw">select</span>(country, year, propensity_scores) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb148-7" data-line-number="7"><span class="st">  </span><span class="kw">slice</span>(<span class="dv">1</span><span class="op">:</span><span class="dv">2</span>)</a>
<a class="sourceLine" id="cb148-8" data-line-number="8"><span class="co">## # A tibble: 2 x 3</span></a>
<a class="sourceLine" id="cb148-9" data-line-number="9"><span class="co">##   country  year propensity_scores</span></a>
<a class="sourceLine" id="cb148-10" data-line-number="10"><span class="co">##   &lt;chr&gt;   &lt;dbl&gt;             &lt;dbl&gt;</span></a>
<a class="sourceLine" id="cb148-11" data-line-number="11"><span class="co">## 1 Brazil   1984            0.0815</span></a>
<a class="sourceLine" id="cb148-12" data-line-number="12"><span class="co">## 2 Mexico   2000            0.159</span></a></code></pre></div>
<p>A continuación, hacemos lo mismo pero para los puntajes de propensión más altos (es decir, donde la probabilidad de recibir el tratamiento - tener gasto en educación mayor a la media - es muy elevada). Es decir, identificamos los casos con mayor puntaje de propensión para valores de gini mayores a la media muestral y gasto en educación mayor a la media muestral:</p>
<div class="sourceCode" id="cb149"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb149-1" data-line-number="1">propensity_scores <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb149-2" data-line-number="2"><span class="st">  </span><span class="kw">filter</span>(gini <span class="op">==</span><span class="st"> </span><span class="dv">1</span> <span class="op">&amp;</span><span class="st"> </span>tratamiento<span class="op">==</span><span class="dv">1</span>) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb149-3" data-line-number="3"><span class="st">  </span><span class="kw">arrange</span>(<span class="op">-</span>propensity_scores) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb149-4" data-line-number="4"><span class="st">  </span>dplyr<span class="op">::</span><span class="kw">select</span>(country, year, propensity_scores) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb149-5" data-line-number="5"><span class="st">  </span><span class="kw">slice</span>(<span class="dv">1</span><span class="op">:</span><span class="dv">2</span>)</a>
<a class="sourceLine" id="cb149-6" data-line-number="6"><span class="co">## # A tibble: 2 x 3</span></a>
<a class="sourceLine" id="cb149-7" data-line-number="7"><span class="co">##   country   year propensity_scores</span></a>
<a class="sourceLine" id="cb149-8" data-line-number="8"><span class="co">##   &lt;chr&gt;    &lt;dbl&gt;             &lt;dbl&gt;</span></a>
<a class="sourceLine" id="cb149-9" data-line-number="9"><span class="co">## 1 Panama    1996             0.997</span></a>
<a class="sourceLine" id="cb149-10" data-line-number="10"><span class="co">## 2 Honduras  2001             0.997</span></a></code></pre></div>
<p>Nuestros resultados indican que, tanto Brasil como México podrían ser seleccionados para ser comparados con Panama u Honduras para realizar estudios de casos “más diferentes” en profundidad.</p>
</div>
</div>
<div id="la-relevancia-de-combinar-metodos" class="section level2">
<h2><span class="header-section-number">8.6</span> La relevancia de combinar métodos</h2>
<p>Para finalizar, consideramos importante insistir sobre la relevancia de combinar métodos al momento de responder una pregunta de investigación. Si bien cuáles serán los métodos apropiados dependerán de cuál es la pregunta, una respuesta a un fenómeno requiere tanto de la identificación de una relación entre dos (o más) variables, y una explicación que detalle cómo estas dos variables se vinculan y por qué se genera el efecto identificado. Para abordar estas dos dimensiones resulta necesario combinar distintas estrategias empíricas, para explotar las respectivas virtudes y complementar sus debilidades.</p>
<p>En el caso concreto que nos ocupa, la estimación por MCO permite identificar relaciones promedio entre dos variables en un gran número de casos y para varios años, algo que la investigación cualitativa no puede realizar. Sin embargo, MCO no puede responder sobre el por qué o el cómo de estas relaciones y, para eso, es necesaria una investigación cualitativa que profundice en los procesos y actores que “producen” estas relaciones. Claro que el proceso también puede ser el inverso: identificar primero una relación entre dos variables a partir de estudios en profundidad de casos y, luego, testear la relación encontrada en otros casos en un estudio cuantitativo de <em>n-grande</em> para evaluar la generalización del hallazgo. En todo caso, la combinación de métodos - ya sea por triangulación o por integración (Seawright, 2016) -, es aconsejable para ofrecer explicaciones más complejas y acabadas de los fenómenos que nos interesa estudiar.</p>
</div>
<div id="referencias" class="section level2">
<h2><span class="header-section-number">8.7</span> Referencias</h2>
<p>Angrist, Joshua, Jörn-Steffen Pischke.2008. “Mostly Harmless Econometrics: An Empiricist’s Companion”.</p>
<p>Dunning, Thad. 2012. Natural Experiments in the Social Sciences. A design-based approach. Cambridge University Press.</p>
<p>Gelman, Andrew, Jennifer Hill. 2006. “Data Analysis Using Regression and Multilevel/Hierarchical Models”. Cambridge University Press.</p>
<p>Gerber, Alan y Donald Green. 2012. “Field Experiments. Design, Analysis, and Interpretation”. Norton and Co.</p>
<p>Gerring, John. 2006. Case study research: Principles and practices. Cambridge university press, pp. 86-150.</p>
<p>Glennerster, Rachel y Kudzai Takavarasha. 2013. “Running Randomized Evaluations. A practical Guide”. Princeton University Press.</p>
<p>Imai, Kosuke. 2017. “Quantitative Social Science. An Introduction”. Princeton University Press.</p>
<p>Lieberman, Evan S. 2005. “Nested analysis as a mixed-method strategy for comparative research.” American Political Science Review 99.3: 435-452.</p>
<p>Monogan III, James E. 2015. Political Analysis Using R. Springer</p>
<p>Seawright, Jason. 2016. Multi-Method Social Science: Combining Qualitative and Quantitative Tools. Cambridge University Press.</p>
<p>Wooldridge, Jeffrey.2010. “Introducción a la econometría. Un enfoque moderno”. Ed. Cengage</p>

</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="stats.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="logit.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": false,
"fontsettings": {
"theme": "white",
"family": "serif",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"download": ["adp-bookdown.pdf"],
"toc": {
"collapse": "section"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdn.bootcss.com/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:" && /^https?:/.test(src))
      src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
