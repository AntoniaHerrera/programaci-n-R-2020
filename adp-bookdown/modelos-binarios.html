<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">

<head>

<meta charset="utf-8">
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="pandoc" />
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta property="og:title" content="analizaR datos políticos" />
<meta property="og:type" content="book" />


<meta property="og:description" content="This is a minimal example of using the bookdown package to write a book. The output format for this example is bookdown::gitbook." />
<meta name="github-repo" content="rstudio/bookdown-demo" />

<meta name="author" content="Francisco Urdinez y Andrés Cruz" />

<meta name="date" content="2017-12-22" />

<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  TeX: { equationNumbers: { autoNumber: "AMS" } }
});
</script>
  <script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_CHTML-full" type="text/javascript"></script>

<meta name="description" content="This is a minimal example of using the bookdown package to write a book. The output format for this example is bookdown::gitbook.">

<title>analizaR datos políticos</title>

<link href="libs/tufte-css-2015.12.29/tufte.css" rel="stylesheet" />


<style type="text/css">code{white-space: pre;}</style>
<style type="text/css">
div.sourceCode { overflow-x: auto; }
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
code > span.kw { color: #007020; font-weight: bold; } /* Keyword */
code > span.dt { color: #902000; } /* DataType */
code > span.dv { color: #40a070; } /* DecVal */
code > span.bn { color: #40a070; } /* BaseN */
code > span.fl { color: #40a070; } /* Float */
code > span.ch { color: #4070a0; } /* Char */
code > span.st { color: #4070a0; } /* String */
code > span.co { color: #60a0b0; font-style: italic; } /* Comment */
code > span.ot { color: #007020; } /* Other */
code > span.al { color: #ff0000; font-weight: bold; } /* Alert */
code > span.fu { color: #06287e; } /* Function */
code > span.er { color: #ff0000; font-weight: bold; } /* Error */
code > span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
code > span.cn { color: #880000; } /* Constant */
code > span.sc { color: #4070a0; } /* SpecialChar */
code > span.vs { color: #4070a0; } /* VerbatimString */
code > span.ss { color: #bb6688; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { color: #19177c; } /* Variable */
code > span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code > span.op { color: #666666; } /* Operator */
code > span.bu { } /* BuiltIn */
code > span.ex { } /* Extension */
code > span.pp { color: #bc7a00; } /* Preprocessor */
code > span.at { color: #7d9029; } /* Attribute */
code > span.do { color: #ba2121; font-style: italic; } /* Documentation */
code > span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code > span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code > span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
</style>


<link rel="stylesheet" href="toc.css" type="text/css" />

</head>

<body>



<div class="row">
<div class="col-sm-12">
<div id="TOC">
<ul>
<li><a href="index.html#inicio">Inicio</a></li>
<li class="has-sub"><a href="prefacio.html#prefacio"><span class="toc-section-number">1</span> Prefacio</a><ul>
<li><a href="prefacio.html#agradecimientos"><span class="toc-section-number">1.1</span> Agradecimientos</a></li>
</ul></li>
<li class="has-sub"><a href="introduccion.html#introduccion"><span class="toc-section-number">2</span> Introducción</a><ul>
<li><a href="introduccion.html#organizacion-del-libro"><span class="toc-section-number">2.1</span> Organización del libro</a></li>
<li><a href="introduccion.html#prerrequisitos"><span class="toc-section-number">2.2</span> Prerrequisitos</a></li>
</ul></li>
<li class="has-sub"><a href="r-basico.html#r-basico"><span class="toc-section-number">3</span> R básico</a><ul>
<li class="has-sub"><a href="r-basico.html#instalacion"><span class="toc-section-number">3.1</span> Instalación</a><ul>
<li><a href="r-basico.html#r"><span class="toc-section-number">3.1.1</span> R</a></li>
<li><a href="r-basico.html#rstudio"><span class="toc-section-number">3.1.2</span> RStudio</a></li>
</ul></li>
<li class="has-sub"><a href="r-basico.html#partes-de-rstudio"><span class="toc-section-number">3.2</span> Partes de RStudio</a><ul>
<li><a href="r-basico.html#consola"><span class="toc-section-number">3.2.1</span> Consola</a></li>
<li><a href="r-basico.html#script"><span class="toc-section-number">3.2.2</span> Script</a></li>
<li><a href="r-basico.html#objetos"><span class="toc-section-number">3.2.3</span> Objetos</a></li>
<li><a href="r-basico.html#archivos-graficos-paquetes-ayuda"><span class="toc-section-number">3.2.4</span> Archivos / gráficos / paquetes / ayuda</a></li>
</ul></li>
<li><a href="r-basico.html#ejercicios"><span class="toc-section-number">3.3</span> Ejercicios</a></li>
</ul></li>
<li class="has-sub"><a href="manejo.html#manejo"><span class="toc-section-number">4</span> Manejo</a><ul>
<li><a href="manejo.html#nuestra-base-de-datos"><span class="toc-section-number">4.1</span> Nuestra base de datos</a></li>
<li><a href="manejo.html#describir-base"><span class="toc-section-number">4.2</span> Describir base</a></li>
<li><a href="manejo.html#ordenar-la-base"><span class="toc-section-number">4.3</span> Ordenar la base</a></li>
<li><a href="manejo.html#seleccionar-columnas"><span class="toc-section-number">4.4</span> Seleccionar columnas</a></li>
<li><a href="manejo.html#renombrar-columnas"><span class="toc-section-number">4.5</span> Renombrar columnas</a></li>
<li><a href="manejo.html#filtrar-observaciones"><span class="toc-section-number">4.6</span> Filtrar observaciones</a></li>
<li><a href="manejo.html#crear-nuevas-variables"><span class="toc-section-number">4.7</span> Crear nuevas variables</a></li>
<li><a href="manejo.html#concatenar-comandos-las-pipes"><span class="toc-section-number">4.8</span> Concatenar comandos: las pipes</a></li>
<li><a href="manejo.html#ejercicios-1"><span class="toc-section-number">4.9</span> Ejercicios</a></li>
</ul></li>
<li class="has-sub"><a href="modelos-binarios.html#modelos-binarios"><span class="toc-section-number">5</span> Modelos binarios</a><ul>
<li><a href="modelos-binarios.html#pseudo-r2"><span class="toc-section-number">5.0.1</span> <span class="math inline">\(Pseudo-R^2\)</span></a></li>
<li><a href="modelos-binarios.html#aic"><span class="toc-section-number">5.0.2</span> AIC</a></li>
<li><a href="modelos-binarios.html#bic"><span class="toc-section-number">5.0.3</span> BIC</a></li>
<li><a href="modelos-binarios.html#brier-score"><span class="toc-section-number">5.0.4</span> Brier Score</a></li>
<li><a href="modelos-binarios.html#porcentaje-de-predicciones-correctas"><span class="toc-section-number">5.0.5</span> Porcentaje de predicciones correctas</a></li>
<li><a href="modelos-binarios.html#roc-plot"><span class="toc-section-number">5.0.6</span> ROC plot</a></li>
<li><a href="modelos-binarios.html#separation-plots"><span class="toc-section-number">5.0.7</span> Separation plots</a></li>
</ul></li>
<li class="has-sub"><a href="modelos-de-supervivencia.html#modelos-de-supervivencia"><span class="toc-section-number">6</span> Modelos de supervivencia</a><ul>
<li><a href="modelos-de-supervivencia.html#el-modelo-cox-de-riesgos-proporcionales"><span class="toc-section-number">6.1</span> El modelo Cox de riesgos proporcionales:</a></li>
</ul></li>
</ul>
</div>
</div>
</div>
<div class="row">
<div class="col-sm-12">
<div id="modelos-binarios" class="section level1">
<h1><span class="header-section-number">Capítulo 5</span> Modelos binarios</h1>
<table style="width:89%;">
<colgroup>
<col width="88%" />
</colgroup>
<tbody>
<tr class="odd">
<td align="left"><strong>Lectura de referencia:</strong></td>
</tr>
<tr class="even">
<td align="left">* Box-Steffensmeier, J. M., Brady, H. E., &amp; Collier, D. (Eds.). (2008). <em>The Oxford Handbook of Political Methodology</em> (Vol. 10). Oxford Handbooks of Political Science. Oxford: Oxford University Press. Cap. 22 – Discrete Choice Methods. * Agresti, A. (2007). <em>An Introduction to Categorical Data Analysis</em>, 2nd Ed. Hoboken: Wiley. Cap. 3, 4 y 5 – Generalized Linear Models; Logistic Regression; Building and Applying Logistic Regression Models. * Greenhill, B., Ward, M. D., &amp; Sacks, A. (2011). The separation plot: A new visual method for evaluating the fit of binary models. <em>American Journal of Political Science</em>, 55(4), 991-1002.</td>
</tr>
</tbody>
</table>
<p>En el capítulo anterior vimos cómo hacer regresiones linarias en R de una manera simple y cubriendo los paquetes más útiles a nuestro alcance. En este capítulo veremos cómo hacer los mismos para variables dependientes dicotómicas. Al igual que en los capítulos previos, no cubriremos aspectos sustanciales a la teoría por tras de cada modelo, ni desglosaremos en detalle las fórmulas. Para ello dejamos tres referencias que van a ayudarte a acompañar lo que describimos si nunca has leído al respecto. Los modelos para variables dependientes dicotómicas (aquellas que asumen una de dos posibilidades, comúnmente 0 y 1) son utilizados para estimar la probabilidad de ocurrencia de un evento. Es importante remarcar que en inglés existen dos conceptos diferentes que en español y portugués se traducen como una única palabra: probability y likelihood se traducen como probabilidad, si bien la distinción entre ambos es vital para comprender como funcionan los modelos dicotómicos estimados por Máxima Verosimilitud (<em>Maximum Likelihood</em> en inglés). Si bien no vamos a ahondar en su distinción, es importante comprende que una probabilidad se estima a partir de una población de la cual conocemos sus parámetros, mientras que la verosimilitud recorre el camino inverso, es decir, estima los valores de los parámetros para los cuales el resultado observado mejor se ajusta a ellos (ver <a href="modelos-binarios.html#fig:realmuestra">5.1</a>).</p>
<p>
<span class="marginnote shownote"><!--
<div class="figure">--> <img src="00-images/fig_7_1.png" alt="Realidad y muestra" width="120%"  /> <!--<span id="fig:realmuestra"></span>
<p class="caption marginnote">-->Figura 5.1: Realidad y muestra<!--</p>--> <!--</div>--></span>
</p>
<p>Cuando tenemos una variable dependiente dicotómica que queremos modelar, asumimos que la misma tiene una distribución de Bernoulli con una probabilidad que desconocemos. Así, estimaremos por medio de Máxima Verosimilitud nuestra probabilidad desconocida dada una combinación linear determinada de variables independientes (ver (fig:bernou)). Un muy buen ejercicio para comprender como se estima un parámetro cuya distribución es binomial por medio de Máxima Verosimilitud es ofrecida por [RPubs] (<a href="https://rpubs.com/felixmay/MLE" class="uri">https://rpubs.com/felixmay/MLE</a>).</p>
<p>
<span class="marginnote shownote"><!--
<div class="figure">--> <img src="00-images/fig_7_2.png" alt="Bernoulli" width="120%"  /> <!--<span id="fig:bernou"></span>
<p class="caption marginnote">-->Figura 5.2: Bernoulli<!--</p>--> <!--</div>--></span>
</p>
<p>La Ciencia Política ha hecho extensivo el uso de modelos Logit, por sobre los modelos Probit, en buena medida debido a que los primeros permiten el cálculo de razones de oportunidades (<em>odds ratios</em>). Casi todos los manuales econométricos discuten las diferencias y similitudes entre ambos, las cuales son muchas a los fines prácticos de estimar un modelo. Por ello, siendo que son métodos que derivan en resultados muy similares, sólo utilizaremos Logit en este capítulo. Ambos métodos utilizan funciones de enlace (<em>link functions</em>) diferentes y Logit lleva ese nombre debido a que su función está dada por el logaritmo natural de las razones de oportunidad.</p>
<p><span class="math inline">\(ln(odds) = ln(\frac {p}{1 - p})\)</span></p>
<p>Despejando los términos podemos calcular, de tal forma que obtenemos</p>
<p>$logit^{-1}() =  =  $</p>
<p>Donde es la combinación linear de las variables independientes y sus coeficientes. La inversa del Logit nos dará la probabilidad de Y ser igual a 1 dada una cierta combinación de variables independientes. Asi,</p>
<p>
<span class="marginnote shownote"><!--
<div class="figure">--> <img src="00-images/fig_7_3.png" alt="Inversa del logit" width="120%"  /> <!--<span id="fig:unnamed-chunk-50"></span>
<p class="caption marginnote">-->Figura 5.3: Inversa del logit<!--</p>--> <!--</div>--></span>
</p>
<p>Nótese que la función es indefinida en 0 y en 1, es decir, la probabilidad se aproxima infinitamente al límite sin nunca tocarlo.</p>
<p>Los modelos probabilísticos han ganado enorme preeminencia en la Ciencia Política en los últimos años y es probable que estés buscando una guía para saber qué hacer y qué no hacer cuando tiene una variable dependiente dicotómica. Para ello vamos a ilustrar un paso a paso en R utilizando como ejemplo la base de datos del libro [“Democracies and Dictatorships in Latin America: Emergence, Survival, and Fall” de Scott Mainwaring y Aníbal Perez-Liñan (2013)] (<a href="https://kellogg.nd.edu/democracies-and-dictatorships-latin-america-emergence-survival-and-fall" class="uri">https://kellogg.nd.edu/democracies-and-dictatorships-latin-america-emergence-survival-and-fall</a>). A lo largo del libro los autores analizan qué variables permiten explicar que a lo largo del siglo XX y comienzos del XXI hayan ocurrido quiebres democráticos en América Latina. En el capítulo 4 se preguntan qué factores explican la supervivencia de los regímenes políticos. Si bien testan varios modelos, algunos logísticos y otros de supervivencia (que están desarrollados en el Capítulo 10), a los fines prácticos haremos un ejemplo muy sencillo. Suponiendo que la variable dependiente asume el valor “1” si el país sufre un quiebre de su régimen político democrático y “0” si no, ¿qué efecto tiene sobre la probabilidad de un quiebre de este tipo ocurrir que un país latinoamericano de mayores poderes constitucionales al poder ejecutivo? Como argumentan los autores, se puede medir estos poderes por medio del índice creado por [Shugart y Carey] (<a href="http://www.cambridge.org/gb/academic/subjects/politics-international-relations/comparative-politics/presidents-and-assemblies-constitutional-design-and-electoral-dynamics?format=PB&amp;isbn=9780521429900" class="uri">http://www.cambridge.org/gb/academic/subjects/politics-international-relations/comparative-politics/presidents-and-assemblies-constitutional-design-and-electoral-dynamics?format=PB&amp;isbn=9780521429900</a>) de poder presidencial (1992) que los autores incluyen en su base de datos. Así,</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">datos_mp &lt;-<span class="st"> </span><span class="kw">read_stata</span>(<span class="st">&quot;00-datos/Cap 7_base_mainwaring_perez.dta&quot;</span>)</code></pre></div>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">summary</span>(datos_mp)</code></pre></div>
<pre><code>##    country              cc_cow         sc_wb                year     
##  Length:2216        Min.   : 40.0   Length:2216        Min.   :1900  
##  Class :character   1st Qu.: 90.0   Class :character   1st Qu.:1927  
##  Mode  :character   Median :100.0   Mode  :character   Median :1955  
##                     Mean   :106.5                      Mean   :1955  
##                     3rd Qu.:145.0                      3rd Qu.:1983  
##                     Max.   :165.0                      Max.   :2010  
##                                                                      
##     admin                 r                e                f        
##  Length:2216        Min.   :0.0000   Min.   :0.0000   Min.   :0.000  
##  Class :character   1st Qu.:0.0000   1st Qu.:0.0000   1st Qu.:2.000  
##  Mode  :character   Median :0.0000   Median :0.0000   Median :2.000  
##                     Mean   :0.6728   Mean   :0.7811   Mean   :1.888  
##                     3rd Qu.:1.0000   3rd Qu.:2.0000   3rd Qu.:2.000  
##                     Max.   :2.0000   Max.   :2.0000   Max.   :2.000  
##                                                       NA&#39;s   :1183   
##        cl             p             trans2         breakdown     
##  Min.   :0.00   Min.   :0.000   Min.   :0.0000   Min.   :0.0000  
##  1st Qu.:1.00   1st Qu.:2.000   1st Qu.:0.0000   1st Qu.:0.0000  
##  Median :2.00   Median :2.000   Median :0.0000   Median :0.0000  
##  Mean   :1.53   Mean   :1.822   Mean   :0.0633   Mean   :0.0485  
##  3rd Qu.:2.00   3rd Qu.:2.000   3rd Qu.:0.0000   3rd Qu.:0.0000  
##  Max.   :2.00   Max.   :2.000   Max.   :2.0000   Max.   :1.0000  
##  NA&#39;s   :1183   NA&#39;s   :1183    NA&#39;s   :968      NA&#39;s   :1268    
##       a_1              s_1              age             age2     
##  Min.   :0.0000   Min.   :0.0000   Min.   : 1.00   Min.   :   1  
##  1st Qu.:0.0000   1st Qu.:0.0000   1st Qu.: 5.00   1st Qu.:  25  
##  Median :1.0000   Median :0.0000   Median :12.00   Median : 144  
##  Mean   :0.5683   Mean   :0.1976   Mean   :15.37   Mean   : 391  
##  3rd Qu.:1.0000   3rd Qu.:0.0000   3rd Qu.:22.00   3rd Qu.: 484  
##  Max.   :1.0000   Max.   :1.0000   Max.   :61.00   Max.   :3721  
##  NA&#39;s   :20       NA&#39;s   :20       NA&#39;s   :896     NA&#39;s   :896   
##       age3            time3         lntime3            fh        
##  Min.   :     1   Min.   : 0.0   Min.   :0.000   Min.   : 0.000  
##  1st Qu.:   125   1st Qu.: 6.0   1st Qu.:1.946   1st Qu.: 5.000  
##  Median :  1728   Median :13.0   Median :2.639   Median : 8.000  
##  Mean   : 12923   Mean   :13.6   Mean   :2.387   Mean   : 7.158  
##  3rd Qu.: 10648   3rd Qu.:20.0   3rd Qu.:2.996   3rd Qu.: 9.000  
##  Max.   :226981   Max.   :32.0   Max.   :3.466   Max.   :12.000  
##  NA&#39;s   :896      NA&#39;s   :1694   NA&#39;s   :1713    NA&#39;s   :1436    
##      aclp2          npr_all           npr_gov           npr_opp       
##  Min.   :1.000   Min.   :-1.0000   Min.   :-1.0000   Min.   :-1.0000  
##  1st Qu.:2.000   1st Qu.:-0.2500   1st Qu.:-0.5000   1st Qu.: 0.0000  
##  Median :2.000   Median : 0.1667   Median : 0.0000   Median : 0.2500  
##  Mean   :2.721   Mean   : 0.1675   Mean   : 0.0978   Mean   : 0.2649  
##  3rd Qu.:4.000   3rd Qu.: 0.5000   3rd Qu.: 0.6667   3rd Qu.: 0.7500  
##  Max.   :4.000   Max.   : 1.0000   Max.   : 1.0000   Max.   : 1.0000  
##  NA&#39;s   :996     NA&#39;s   :876       NA&#39;s   :876       NA&#39;s   :876      
##     rad_all          rad_gov          rad_opp          npr_all1      
##  Min.   :0.0000   Min.   :0.0000   Min.   :0.0000   Min.   :-1.0000  
##  1st Qu.:0.1250   1st Qu.:0.0000   1st Qu.:0.0000   1st Qu.:-0.2500  
##  Median :0.3333   Median :0.3333   Median :0.2500   Median : 0.1667  
##  Mean   :0.3945   Mean   :0.3970   Mean   :0.3600   Mean   : 0.1618  
##  3rd Qu.:0.6667   3rd Qu.:0.7500   3rd Qu.:0.6667   3rd Qu.: 0.5000  
##  Max.   :1.0000   Max.   :1.0000   Max.   :1.0000   Max.   : 1.0000  
##  NA&#39;s   :876      NA&#39;s   :876      NA&#39;s   :876      NA&#39;s   :896      
##      region          d_nonla              us_t            dif08        
##  Min.   :0.0000   Min.   :-2.59483   Min.   :0.0000   Min.   :-4.0630  
##  1st Qu.:0.1842   1st Qu.:-1.49515   1st Qu.:0.1250   1st Qu.:-0.9838  
##  Median :0.2632   Median : 0.14000   Median :0.2500   Median :-0.1264  
##  Mean   :0.3329   Mean   : 0.02808   Mean   :0.4033   Mean   : 0.6851  
##  3rd Qu.:0.4474   3rd Qu.: 1.38000   3rd Qu.:0.7500   3rd Qu.: 2.4828  
##  Max.   :0.8684   Max.   : 3.22222   Max.   :1.0000   Max.   : 5.8831  
##  NA&#39;s   :20       NA&#39;s   :100        NA&#39;s   :60       NA&#39;s   :996      
##       pgdp             gdp_1_          gpgdp                g_1           
##  Min.   :0.04224   Min.   :3.743   Min.   :-0.286233   Min.   :-0.286233  
##  1st Qu.:0.74426   1st Qu.:6.612   1st Qu.:-0.001656   1st Qu.:-0.001656  
##  Median :1.31840   Median :7.184   Median : 0.019615   Median : 0.019615  
##  Mean   :1.90181   Mean   :7.166   Mean   : 0.022346   Mean   : 0.022346  
##  3rd Qu.:2.48104   3rd Qu.:7.816   3rd Qu.: 0.047283   3rd Qu.: 0.047283  
##  Max.   :9.89381   Max.   :9.200   Max.   : 0.531078   Max.   : 0.531078  
##  NA&#39;s   :22        NA&#39;s   :22      NA&#39;s   :22          NA&#39;s   :22         
##     ghist10                i              ihist10             wfm        
##  Min.   :-0.143831   Min.   :-0.1084   Min.   :-0.0816   Min.   :0.0000  
##  1st Qu.: 0.005731   1st Qu.: 0.0379   1st Qu.: 0.0520   1st Qu.:0.0032  
##  Median : 0.017613   Median : 0.1027   Median : 0.1232   Median :0.0110  
##  Mean   : 0.022876   Mean   : 0.2277   Mean   : 0.2432   Mean   :0.0486  
##  3rd Qu.: 0.035152   3rd Qu.: 0.2147   3rd Qu.: 0.2277   3rd Qu.:0.0709  
##  Max.   : 0.141336   Max.   : 4.7749   Max.   : 3.8725   Max.   :0.4369  
##  NA&#39;s   :1           NA&#39;s   :1119      NA&#39;s   :1087      NA&#39;s   :1508    
##      oilmin          indust_            lit_           gini_      
##  Min.   :0.0000   Min.   : 5.384   Min.   : 8.00   Min.   :29.96  
##  1st Qu.:0.0000   1st Qu.:17.000   1st Qu.:49.60   1st Qu.:46.48  
##  Median :0.0000   Median :22.001   Median :71.46   Median :51.85  
##  Mean   :0.1784   Mean   :21.102   Mean   :66.80   Mean   :51.18  
##  3rd Qu.:0.0000   3rd Qu.:26.222   3rd Qu.:86.64   3rd Qu.:56.50  
##  Max.   :1.0000   Max.   :34.500   Max.   :98.60   Max.   :67.83  
##  NA&#39;s   :876      NA&#39;s   :896      NA&#39;s   :630     NA&#39;s   :1551   
##       iac             multip          shugart         d_00_44      
##  Min.   :0.0000   Min.   :0.0000   Min.   : 5.00   Min.   :0.0000  
##  1st Qu.:0.0000   1st Qu.:0.0000   1st Qu.:15.00   1st Qu.:0.0000  
##  Median :0.0000   Median :0.0000   Median :16.00   Median :0.0556  
##  Mean   :0.1221   Mean   :0.3502   Mean   :16.33   Mean   :0.1553  
##  3rd Qu.:0.0000   3rd Qu.:1.0000   3rd Qu.:18.00   3rd Qu.:0.2959  
##  Max.   :1.0000   Max.   :1.0000   Max.   :25.00   Max.   :0.5889  
##  NA&#39;s   :996      NA&#39;s   :1171     NA&#39;s   :1054    NA&#39;s   :896     
##    npr_45_77         rad_45_77          npr_t             rad_t       
##  Min.   :-0.6162   Min.   :0.1253   Min.   :-1.8644   Min.   :0.0000  
##  1st Qu.:-0.3458   1st Qu.:0.2654   1st Qu.:-0.4498   1st Qu.:0.5418  
##  Median :-0.0129   Median :0.4610   Median : 0.0182   Median :0.8989  
##  Mean   :-0.0332   Mean   :0.4780   Mean   : 0.0589   Mean   :1.0872  
##  3rd Qu.: 0.1793   3rd Qu.:0.6806   3rd Qu.: 0.5336   3rd Qu.:1.5459  
##  Max.   : 0.8995   Max.   :0.9242   Max.   : 3.1174   Max.   :3.1166  
##  NA&#39;s   :1556      NA&#39;s   :1556     NA&#39;s   :1713      NA&#39;s   :1713    
##    idsampler    
##  Min.   :10.00  
##  1st Qu.:21.00  
##  Median :22.00  
##  Mean   :33.71  
##  3rd Qu.:51.00  
##  Max.   :52.00  
##  NA&#39;s   :20</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">modelo_<span class="dv">1</span> &lt;-<span class="st"> </span><span class="kw">glm</span>(breakdown <span class="op">~</span><span class="st"> </span>shugart, 
                <span class="dt">data   =</span> datos_mp,
                <span class="dt">family =</span> <span class="kw">binomial</span>(<span class="st">&quot;logit&quot;</span>))</code></pre></div>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">summary</span>(modelo_<span class="dv">1</span>)</code></pre></div>
<pre><code>## 
## Call:
## glm(formula = breakdown ~ shugart, family = binomial(&quot;logit&quot;), 
##     data = datos_mp)
## 
## Deviance Residuals: 
##     Min       1Q   Median       3Q      Max  
## -0.7268  -0.2953  -0.2689  -0.2227   2.7917  
## 
## Coefficients:
##             Estimate Std. Error z value Pr(&gt;|z|)   
## (Intercept) -0.23929    0.96383  -0.248  0.80392   
## shugart     -0.19142    0.06477  -2.955  0.00312 **
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## (Dispersion parameter for binomial family taken to be 1)
## 
##     Null deviance: 217.84  on 643  degrees of freedom
## Residual deviance: 209.56  on 642  degrees of freedom
##   (1572 observations deleted due to missingness)
## AIC: 213.56
## 
## Number of Fisher Scoring iterations: 6</code></pre>
<p>El coeficiente para la variable <em>shugart</em> está negativamente asociado a la probabilidad de ocurrencia de un quiebre de régimen, y es estadísticamente significativo (p=0.0026). Ahora bien, a diferencia de los modelos por MCO del capítulo anterior, donde podíamos interpretar directamente el efecto de la variable independiente sobre la dependiente a partir de los coeficientes de la regresión, para el caso de regresiones logísticas esto no es tan sencillo. Si partimos de que la función de enlace de logit es el logaritmo de las razones de oportunidades, tenemos que</p>
<p><span class="math inline">\(ln(\frac {p}{1 - p}) = \beta_{0} + \beta_{1}x_{1}\)</span></p>
<p>Despejando <span class="math inline">\(ln\)</span>, tenemos que</p>
<p><span class="math inline">\((\frac {p}{1 - p}) = e^{\beta_{0}+\beta_{1}x_{1}}\)</span></p>
<p>Y despejando los términos tenemos que</p>
<p><span class="math inline">\(\hat{p} = \frac {e^{\beta_{0}+\beta_{1}x_{1}}}{1 + e^{\beta_{0}+\beta_{1}x_{1}}}\)</span></p>
<p>Lo que queremos, entonces, es transformar los coeficientes tal y como los reporta R en una probabilidad asociada a que la variable dependiente asuma el valor “1”. Sabemos que la variable independiente (<em>shugart</em>) es un índice que a mayor valor, mayor concentración de poder del ejecutivo <em>vis a vis</em> el legislativo, por lo tanto el coeficiente nos dice que a menor concentración de poder del ejecutivo, mayor la probabilidad de un quiebre de régimen. En la muestra de los autores, que cubre 20 países latinoamericanos entre 1900 y 2010, el índice oscila de un mínimo de 5 (Haití, varios años) a un máximo de 25 (Brasil en 1945) ¿Cómo puedo saber en qué magnitud se afecta la probabilidad de un quiebre democrático si el nivel de concentración de poder del ejecutivo pasa de un puntaje de 5 (mínimo) a uno de 25 (máximo)?</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">attach</span>(datos_mp)
<span class="kw">qplot</span>(shugart, <span class="dt">geom=</span><span class="st">&quot;histogram&quot;</span>) </code></pre></div>
<pre><code>## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`.</code></pre>
<pre><code>## Warning: Removed 1054 rows containing non-finite values (stat_bin).</code></pre>
<p><img src="adp-bookdown_files/figure-html/unnamed-chunk-56-1.png" width="672"  /></p>
<p>Para ello podemos reemplazar los valores de nuestra última fórmula, en la que hemos aislado en el lado izquierdo de la fórmula a <span class="math inline">\(\hat {p}\)</span>. Primero debemos calcular cuál es la probabilidad de sufrir un quiebre de régimen en un nivel de Shugart de 5 y en un nivel 25, respectivamente, para luego calcular la diferencia. Así tenemos que</p>
<p><span class="math inline">\(\hat{p} = \frac {e^{(0+(-0.019*5))}}{1 + e^{(0+(-0.019*5))}}\)</span></p>
<p>Note que el valor correspondiente al intercepto es igual a 0 pues ese coeficiente no ha resultado estadísticamente significativo. Sabemos que para un índice de Shugart y Carey de 5, luego de hacer el cálculo en la fórmula arriba, la probabilidad es igual a 0.47 o 47%. Si repetimos el proceso para un valor de Shugart de 25 la probabilidad cae a 38%. Con las probabilidades podemos calcular oportunidades, que son simplemente <span class="math inline">\(\frac {p}{1-p}\)</span>. De esta manera, la oportunidad (<em>odd</em> en inglés) para un valor 5 del índice de Shugart y Carey es de 0.90 mientras que para un índice de Shugart y Carey de 25 es de 0.62. La utilidad de las oportunidades es que permite calcular razones de probabilidades (<em>odds ratios</em>). ¿Cuál es la utilidad de una razón de probabilidades? Si calculo la probabilidad de un cambio en el índice de Shugart y Carey de 23 a 24 la magnitud será diferente a un cambio en el índice de 12 a 13, por ejemplo. Es decir, los efectos de la variable independiente sobre la probabilidad de la variable dependiente ocurrir no son lineares. Estos dependerán de la curvatura en forma de “S” de la función. Sin embargo, las razones de probabilidades tienen la propiedad de reflejar cambios independientemente de la curvatura de la función, es decir, son cambios “constantes”. Siendo que los modelos Probit y Logit generan resultados muy similares, pero que apenas los modelos Logit permiten el cálculo de razones de probabilidad, ésta es la principal razón por la que la literatura de Ciencia Política se ha inclinado hacia esta opción. Veamos cómo sería el cálculo de razones de probabilidad siguiendo el ejemplo que acabamos de crear con la base de datos de Mainwaring y Perez-Liñan. Dijimos que la oportunidad está dada por <span class="math inline">\(\frac {p}{1 - p}\)</span>. Una razón de oportunidades se expresaría, entonces, como <span class="math inline">\(\frac {\frac {p_1}{1-p_1}}{\frac {p_2}{1-p_2}}\)</span>. Supongamos que Chile en el año 1992 tenía un índice de Shugart de 15, y que en el año 1993 ese índice subió a 16 (no son valores reales).</p>
<p>$ Pr(quiebre democrático){<em>{Chile,1992}} =  = 0.42$ $ Pr(quiebre democrático){</em>{Chile,1993}} =  = 0.43$</p>
<p>La probabilidad difiere poco y cae en un 2.4% lo que puede ser un valor considerable. La razón de oportunidades se calcula como el cociente de ambas oportunidades, así:</p>
<p><span class="math inline">\(\frac {0.42}{0.43}=0.97\)</span></p>
<p>De esta manera, toda razón de oportunidades mayor a 1 expresa un cambio positivo, mientras que todo valor menor a 1 (entre 0 y 1) representa un cambio negativo en las probabilidades estimadas. Si hiciéramos el mismo ejercicio para otros valores del índice de Shugart y Carey, por ejemplo, un cambio de 3 a 4 o de 23 a 24, el cociente de las oportunidades daría 0.97. R ofrece paquetes para que este análisis sea fácil de hacerse. Podemos visualizar fácilmente los cocientes de oportunidades utilizando el paquete ´sjPlot´, podemos calcular probabilidades predichas, y además podemos hacer tests para saber la capacidad explicativa de nuestros modelos. Utilizando la misma base de datos haremos un ejemplo de una rutina típica, que puedes recrear en casa utilizando tus propios datos. Los pasos a seguir son (a) estimar los modelos, (b) crear tablas formateadas para pegar en nuestros procesadores de texto, (c) crear figuras para visualizar la magnitud de los coeficientes por medio de cociente de oportunidades, (d) visualizar probabilidades predichas para variables de interés, (e) calcular capacidad explicativa de los modelos (porcentaje correctamente predicho, AIC, BIC, curvas ROC, <em>Brier scores</em> o <em>separation plots</em>, que explicaremos a continuación). Cuando uno trabaja con una variable dependiente binaria, y lo que quiere es rodar algunos modelos logísticos para incorporar a su trabajo, primero es recomendable utilizar Pacman. <code>pacman</code> es un paquete de R que hace mucho más fácil trabajar con otros paquetes, pues permite cargar todos al mismo tiempo. Comencemos por cargarlo:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="cf">if</span> (<span class="op">!</span><span class="kw">require</span>(<span class="st">&quot;pacman&quot;</span>))
    <span class="kw">install.packages</span>(<span class="st">&quot;pacman&quot;</span>); <span class="kw">library</span>(pacman)  </code></pre></div>
<p>Para que sea simple utilizar la función <code>pacman</code>, recomendamos añadir <code>library(pacman)</code> a <a href="http://www.statmethods.net/interface/customizing.html">su archivo de .Rprofile</a>, para que se cargue automáticamente cada vez que abra R Studio. De esta manera no habrá que ejecutarlo cada vez que abra R Studio. La principal gracia de <code>pacman</code> es su función <code>p_load</code>, que nos permite cargar varios paquetes en un solo comando y, si nos los tenemos instalados, lo hace por nosotros (en el siguiente paso la utilizaremos). Si no tienes instalados los siguientes paquetes, <code>p_load</code> los instalará por ti. Si nos has acompañado desde los capítulos anteriores, este paso te resultará familiar.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">p_load</span>(haven,    <span class="co"># parte del tidyverse, para cargar bases de datos en formatos foráneos</span>
       verification,
       janitor,  <span class="co"># nos da la función tabyl(), para hacer tablas tidy</span>
       sjPlot,
       stargazer, <span class="co"># nos ayuda a hacer tablas de modelos de regresión</span>
       tidyverse,
       pscl,
       separationplot
       )</code></pre></div>
<p>¿Recuerde el ADP? Una de las funciones que hemos facilitado es la de creación de tablas editables para artículos académicos utilizando la función <code>stargazer</code>. Si utilizas nuestro paquete te ahorrarás muchos pasos que son engorrosos.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(stargazer)
<span class="kw">source</span>(<span class="st">&quot;00-funs/ADP.R&quot;</span>)</code></pre></div>
<p>Por medio de <code>stargazer</code> podemos exportar nuestras tablas formateadas en html para poder incorporarlas en nuestros artículos directamente. Para ejemplificar este paso lo que haremos es agregar al modelo 1 dos modelos más: El modelo 2 tendrá como variables independientes al índice de Shugart y Carey más la variable <em>age</em> que mide en años la edad del régimen político. qplot(age, geom=“histogram”)</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">modelo_<span class="dv">2</span> &lt;-<span class="st"> </span><span class="kw">glm</span>(breakdown <span class="op">~</span><span class="st"> </span>shugart<span class="op">+</span>age, 
                <span class="dt">data   =</span> datos_mp,
                <span class="dt">family =</span> <span class="kw">binomial</span>(<span class="st">&quot;logit&quot;</span>))</code></pre></div>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">summary</span>(modelo_<span class="dv">2</span>)</code></pre></div>
<pre><code>## 
## Call:
## glm(formula = breakdown ~ shugart + age, family = binomial(&quot;logit&quot;), 
##     data = datos_mp)
## 
## Deviance Residuals: 
##     Min       1Q   Median       3Q      Max  
## -0.7336  -0.3020  -0.2656  -0.2178   2.8279  
## 
## Coefficients:
##              Estimate Std. Error z value Pr(&gt;|z|)   
## (Intercept) -0.222202   0.967643  -0.230  0.81838   
## shugart     -0.188970   0.065811  -2.871  0.00409 **
## age         -0.004084   0.019607  -0.208  0.83501   
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## (Dispersion parameter for binomial family taken to be 1)
## 
##     Null deviance: 217.84  on 643  degrees of freedom
## Residual deviance: 209.52  on 641  degrees of freedom
##   (1572 observations deleted due to missingness)
## AIC: 215.52
## 
## Number of Fisher Scoring iterations: 6</code></pre>
<p>El modelo 3 agrega a las dos variables del modelo 2 una tercer variable llamada <em>fh</em> que corresponde al <a href="https://freedomhouse.org/report/methodology-freedom-world-2017">Freedom House score</a> de democracia.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">qplot</span>(fh, <span class="dt">geom=</span><span class="st">&quot;histogram&quot;</span>) </code></pre></div>
<pre><code>## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`.</code></pre>
<pre><code>## Warning: Removed 1436 rows containing non-finite values (stat_bin).</code></pre>
<p><img src="adp-bookdown_files/figure-html/unnamed-chunk-62-1.png" width="672"  /></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">modelo_<span class="dv">3</span> &lt;-<span class="st"> </span><span class="kw">glm</span>(breakdown <span class="op">~</span><span class="st"> </span>shugart<span class="op">+</span>age<span class="op">+</span>fh, 
                <span class="dt">data   =</span> datos_mp,
                <span class="dt">family =</span> <span class="kw">binomial</span>(<span class="st">&quot;logit&quot;</span>))</code></pre></div>
<pre><code>## Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">summary</span>(modelo_<span class="dv">3</span>)</code></pre></div>
<pre><code>## 
## Call:
## glm(formula = breakdown ~ shugart + age + fh, family = binomial(&quot;logit&quot;), 
##     data = datos_mp)
## 
## Deviance Residuals: 
##      Min        1Q    Median        3Q       Max  
## -1.78635  -0.00080  -0.00007  -0.00001   1.89399  
## 
## Coefficients:
##             Estimate Std. Error z value Pr(&gt;|z|)  
## (Intercept)  15.3596     6.5842   2.333   0.0197 *
## shugart      -0.2173     0.1656  -1.312   0.1894  
## age           0.1664     0.1123   1.482   0.1384  
## fh           -3.7480     1.5051  -2.490   0.0128 *
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## (Dispersion parameter for binomial family taken to be 1)
## 
##     Null deviance: 71.271  on 421  degrees of freedom
## Residual deviance: 12.113  on 418  degrees of freedom
##   (1794 observations deleted due to missingness)
## AIC: 20.113
## 
## Number of Fisher Scoring iterations: 12</code></pre>
<p>Una vez creados los tres modelos de interés, los agrupamos en una lista por medio de la función ´list´.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">mp_modelos &lt;-<span class="st"> </span><span class="kw">list</span>(modelo_<span class="dv">1</span>, 
                   modelo_<span class="dv">2</span>,
                   modelo_<span class="dv">3</span>)</code></pre></div>
<p>Para exportar la tabla a html demos definir la opción <strong>type</strong> y un nombre para el archivo html en la opción <strong>out</strong>. Así el comando sería</p>
<p>stargazer_easy_binary(mp_modelos, type = “html”, # OJO out = “output/tabla_mp_modelos.htm”, # OJO report = “vct*“, title =”Modelos 1-3 en base a Mainwaring y Perez Liñan (2013)“, align = TRUE, dep.var.labels = c(”Quiebre de régimen“), covariate.labels =c (”Indice de Shugart &amp; Carey (1992)“,”Edad del régimen“,”Freedom House“), no.space = TRUE) &lt;&lt;&lt;&lt;&lt;&lt;&lt; HEAD )</p>
<p>======= ``` &gt;&gt;&gt;&gt;&gt;&gt;&gt; 6ab9b13e3b97f2177dde92a805c753c3bbe5efbc A simple vista observamos que <em>shugart</em> deja de ser estadísticamente significativa cuando controlamos por <em>fh</em> y, además, ésta pasa a ser la única variable estadísticamente significativa en el tercer modelo. Vemos como el número de observaciones cae significativamente al incluir la variable <em>fh</em> lo que hace difícil comparar los modelos. Entonces al obtener una tabla como la que acabamos de crear tenemos dos desafíos: comparar los modelos para saber cuál tiene mejor ajuste, y saber si la magnitud de los efectos es substantiva desde un punto de vista científico (por ejemplo, si la variable <em>fh</em> resulta estadísticamente significativa pero la probabilidad de un quiebre de régimen cae en 0.03% si un país pasa del peor score de <em>fh</em> al mejor, entonces diríamos que, a pesar de estadísticamente significativa, nuestra variable carece de significancia substantiva). Jane Miller hace mucho énfasis en su [libro] (<a href="http://www.press.uchicago.edu/ucp/books/book/chicago/C/bo15506942.html" class="uri">http://www.press.uchicago.edu/ucp/books/book/chicago/C/bo15506942.html</a>) respecto a la diferencia entre significancia estadística y significancia substantiva: no por ser una variable significativa estadísticamente la magnitud del efecto será el esperado. Para explorar las magnitudes de los coeficientes vamos a concentrarnos en el tercer modelo. Una tabla individual, podrán anticipar, se haría así:</p>
<p>stargazer_easy_binary(modelo_3, type = “text”, report = “vct*“, title =”Modelo 3 en base Mainwaring y Perez Liñan (2013)“, )</p>
<p>Comencemos reemplazando los coeficientes en la tabla por cocientes de oportunidades. Noten cómo el procedimiento es muy similar al de reemplazar errores estándar:</p>
<p>stargazer_easy_binary(modelo_3, type = “text”, report = “vct*“, title =”Modelo 3 en base Mainwaring y Perez Liñan (2013), odds ratios“, coef = list(exp(modelo_3$coefficients)))</p>
<p>Podemos representar visualmente lo anterior con la función <code>sjp.glm()</code> del paquete <code>sjPlot</code>:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">sjp.glm</span>(modelo_<span class="dv">3</span>, 
        <span class="dt">show.ci     =</span> T,
        <span class="dt">title       =</span> <span class="st">&quot;Modelo 3 en base Mainwaring y Perez Liñan (2013), odds ratios&quot;</span>)</code></pre></div>
<pre><code>## Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred

## Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred

## Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred

## Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred

## Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred

## Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred

## Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred

## Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred

## Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred

## Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred

## Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred

## Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred

## Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred

## Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred

## Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred

## Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred

## Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred

## Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred

## Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred

## Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred

## Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred

## Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred

## Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred

## Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred

## Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred

## Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred

## Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred

## Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred

## Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred

## Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred

## Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred

## Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred

## Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred</code></pre>
<pre><code>## Warning in sjp.glm(modelo_3, show.ci = T, title = &quot;Modelo 3 en base
## Mainwaring y Perez Liñan (2013), odds ratios&quot;): Exp. coefficients and/or
## exp. confidence intervals may be out of printable bounds. Consider using
## `axis.lim` argument!</code></pre>
<pre><code>## Warning: Removed 1 rows containing missing values (geom_errorbar).</code></pre>
<p><img src="adp-bookdown_files/figure-html/unnamed-chunk-66-1.png" width="672"  /> Esta figura es mucho más intuitiva de leerse que los coeficientes de las tablas. En muchas ocasiones es preferible utilizar este tipo de figuras a tablas. La [tendencia] (<a href="https://www.princeton.edu/~jkastell/Tables2Graphs/graphs.pdf" class="uri">https://www.princeton.edu/~jkastell/Tables2Graphs/graphs.pdf</a>) en la disciplina es a la de prescindir de tablas cuando estas no sean esenciales. La ciencia política no prestó demasiada atención a la presentación de resultados por medio de figuras hasta hace unas dos décadas, y hoy en día con software como R es muy simple de hacer. Un precursor en la disciplina fue [Edward Tufte] (<a href="http://pages.mtu.edu/~hcking/Tufte_hKing.pdf" class="uri">http://pages.mtu.edu/~hcking/Tufte_hKing.pdf</a>). Con el argumento <code>type = &quot;slope&quot;</code> en <code>sjp.glm()</code> podemos apreciar cómo es la relación entre cada variable independiente y la variable dependiente, cuando las demás variables independientes están en 0.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">sjp.glm</span>(modelo_<span class="dv">3</span>,
        <span class="dt">type        =</span> <span class="st">&quot;slope&quot;</span>,
        <span class="dt">show.ci     =</span> <span class="ot">TRUE</span>,
        <span class="dt">title       =</span> <span class="st">&quot;Modelo 3 en base Mainwaring y Perez Liñan (2013), pr. predichas con otras variables en 0&quot;</span>)</code></pre></div>
<p><img src="adp-bookdown_files/figure-html/unnamed-chunk-67-1.png" width="672"  /> Con el argumento <code>type = &quot;pred&quot;</code> en <code>sjp.glm()</code> podemos apreciar cómo es la relación entre cada variable independiente y la variable dependiente, cuando las demás variables independientes están en sus medias</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">sjp.glm</span>(modelo_<span class="dv">3</span>, 
        <span class="dt">type        =</span> <span class="st">&quot;pred&quot;</span>,
        <span class="dt">show.ci     =</span> <span class="ot">TRUE</span>,
        <span class="dt">vars        =</span> <span class="st">&quot;fh&quot;</span>,
        <span class="dt">title       =</span> <span class="st">&quot;Modelo 3 en base Mainwaring y Perez Liñan (2013), pr. predichas con otras variables en sus medias&quot;</span>)</code></pre></div>
<p><img src="adp-bookdown_files/figure-html/unnamed-chunk-68-1.png" width="672"  /> Con el argumento <code>type = &quot;eff&quot;</code> en <code>sjp.glm()</code> podemos calcular efectos marginales de cada variable independiente en relación a la variable dependiente, dejando las demás variables independientes están en sus medias. El efecto marginal es el incremento previsto de la variable dependiente asociada al aumento de una unidad en una de las variables independientes, manteniendo las otras constantes. En la regresión lineal, es solo el parámetro beta. En la regresión logística, depende del valor de la variable independiente.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">sjp.glm</span>(modelo_<span class="dv">3</span>, 
        <span class="dt">type        =</span> <span class="st">&quot;eff&quot;</span>,
        <span class="dt">show.ci     =</span> <span class="ot">TRUE</span>,
        <span class="dt">title       =</span> <span class="st">&quot;Modelo 3 en base Mainwaring y Perez Liñan (2013), efectos marginales&quot;</span>)</code></pre></div>
<p><img src="adp-bookdown_files/figure-html/unnamed-chunk-69-1.png" width="672"  /> Una vez que uno ha analizado la significancia substantiva de los modelos por medio de figuras analizando las probabilidades predichas y los efectos marginales, podemos explorar el ajuste de los modelos. Así como en MCO podemos usar el <span class="math inline">\(R^2\)</span> y el <em>Mean Root Square Error</em> ,existe una serie de estadísticas diseñadas para saber cuál de los modelos logísticos tiene mejor fit.</p>
<p>stargazer_easy_binary(mp_modelos, type = “text”, report = “vct*“, title =”Modelos 1-3 en base Mainwaring y Perez Liñan (2013)&quot; )</p>
<p>El <em>wrapper</em> que hemos creado ya nos provee de varios indicadores de ajuste, que también podemos calcular por separado:</p>
<div id="pseudo-r2" class="section level3">
<h3><span class="header-section-number">5.0.1</span> <span class="math inline">\(Pseudo-R^2\)</span></h3>
<p>Para entender como e interpreta el Pseudo-<span class="math inline">\(R^2\)</span> (normalmente se usa el de McFadden) es importante compreender como se diferencia de um <span class="math inline">\(R^2\)</span> por MCO (usar este link para R2 em el cap de OLS <a href="http://setosa.io/ev/ordinary-least-squares-regression/" class="uri">http://setosa.io/ev/ordinary-least-squares-regression/</a>). La fórmula, en este caso es <span class="math inline">\(Pseudo-R^2= 1-\frac {ln \hat{L}(Modelo completo)}{ln \hat{L}(Modelo sólo con intercepto)}\)</span> Donde <span class="math inline">\(\hat{L}\)</span> es la verosimilitud estimada por el modelo. Básicamente, lo que la fórmula está haciendo es comparar el modelo con todas nuestras covariables al modelo que apenas tiene el intercepto, para ver cuanto mejora la capacidad explicativa del mismo. Como <span class="math inline">\(L\)</span> está entre 0 y 1, su log es menor o igual a 0. Así, cuanto menor la razón, mayor la diferencia entre el modelo elegido y el modelo con apenas el intercepto.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">pR2</span>(modelo_<span class="dv">1</span>)[[<span class="st">&quot;McFadden&quot;</span>]]</code></pre></div>
<pre><code>## [1] 0.4306823</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">pR2</span>(modelo_<span class="dv">2</span>)[[<span class="st">&quot;McFadden&quot;</span>]]</code></pre></div>
<pre><code>## [1] 0.4308023</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">pR2</span>(modelo_<span class="dv">3</span>)[[<span class="st">&quot;McFadden&quot;</span>]]</code></pre></div>
<pre><code>## [1] 0.9670939</code></pre>
<p>También se podría implementar un <span class="math inline">\(Pseudo-R^2\)</span> ajustado, es decir, una versión que penalice por cantidad de covaraibles. Siendo que <span class="math inline">\(c\)</span> es cantidad de covariables, tenemos que <span class="math inline">\(Pseudo-R^2= 1-\frac {ln \hat{L}(Modelo completo)-c}{ln \hat{L}(Modelo sólo con intercepto)}\)</span></p>
</div>
<div id="aic" class="section level3">
<h3><span class="header-section-number">5.0.2</span> AIC</h3>
<p>El Akaike Information Criterion (AIC) también usa información de <span class="math inline">\(ln(\hat {L})\)</span> como el <span class="math inline">\(Pseudo-R^2\)</span>. El AIC lo que hace es medir la “distancia” que existe entre los verdaderos parámetros y los estimadores del modelo, por medio de la distancia de Kullback-Leibler. Por ello, cuanto menor esta distancia, mejor el modelo. Es muy útil a la hora de comparar diferentes modelos. Se calcula como <span class="math inline">\(AIC = 2p-2ln(\hat {L})\)</span> Donde <span class="math inline">\(p\)</span> es la cantidad de regresores incluyendo al intercepto, y <span class="math inline">\(\hat{L}\)</span> es la verosimilitud estimada por el modelo.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">AIC</span>(modelo_<span class="dv">1</span>)</code></pre></div>
<pre><code>## [1] 213.5639</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">AIC</span>(modelo_<span class="dv">2</span>)</code></pre></div>
<pre><code>## [1] 215.5197</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">AIC</span>(modelo_<span class="dv">3</span>)</code></pre></div>
<pre><code>## [1] 20.11261</code></pre>
</div>
<div id="bic" class="section level3">
<h3><span class="header-section-number">5.0.3</span> BIC</h3>
<p>BIC (Bayesian information criterion) al igual que AIC es un criterio de comparación de modelos según su ajuste. A los fines prácticos, y para no entrar en las diferencias entre AIC y BIC, es importante saber que BIC penaliza de manera más rigurosa que AIC la complejidad del modelo, siendo que su fórmula es <span class="math inline">\(BIC=ln(n)p-2ln(\hat {L})\)</span> donde agrega a la formula <span class="math inline">\(n\)</span> que es el número de observaciones en la muestra.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">BIC</span>(modelo_<span class="dv">1</span>)</code></pre></div>
<pre><code>## [1] 222.4993</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">BIC</span>(modelo_<span class="dv">2</span>)</code></pre></div>
<pre><code>## [1] 228.9228</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">BIC</span>(modelo_<span class="dv">3</span>)</code></pre></div>
<pre><code>## [1] 36.29263</code></pre>
</div>
<div id="brier-score" class="section level3">
<h3><span class="header-section-number">5.0.4</span> Brier Score</h3>
<p>Ésta es otra medida de ajuste. Cuanto más próximo el score de Brier a 0, mejor el ajuste del modelo. En general uno no utiliza todas (AIC, BIC, Brier, etc) sino que elige dos o tres que sean de su agrado. El Brier se utiliza poco en ciencia política, pero es bastante común en epidemiología. Creemos que situaciones en que se quiere “castigar” mucho las predicciones erróneas, ésta es una alternativa ideal ya que su fórmula viene dada por <span class="math inline">\(B=frac\{1}{N} \sum(\hat{p} - x)^2\)</span> Donde <span class="math inline">\(N\)</span> es el número de observaciones, <span class="math inline">\(\hat{p}\)</span> es la probabilidad predicha para cada observación, y <span class="math inline">\(x\)</span> es el valor real de la observación en nuestra base de datos. El score es el promedio para todas las observaciones de la muestra. ¿Cuál de los tres modelos tiene menor score?</p>
<p>brier_score(modelo_1) brier_score(modelo_2) brier_score(modelo_3)</p>
</div>
<div id="porcentaje-de-predicciones-correctas" class="section level3">
<h3><span class="header-section-number">5.0.5</span> Porcentaje de predicciones correctas</h3>
<p>Para entender el porcentaje de predicciones correctas en un modelo es importante tener en claro que un modelo produce cuatro combinaciones posibles:</p>
<p><img src="00-images/fig_7_4.png" width="120%"  /> Toda observación será clasificada como “correcta” si corresponde a la casilla superior izquierda (verdadero positivo) o a la inferior derecha (verdadero negativo). El porcentaje de observaciones que pertenecen a estas dos casillas determina el porcentaje de predicciones correctas en el modelo. Como criterio estándar, si la probabilidad estimada para una observación es mayor o igual a 50% se estima que es una probabilidad positiva, y si es menor a 50% será una probabilidad negativa.</p>
<p>corr_pred_binary(modelo_1, type = “prop”) corr_pred_binary(modelo_2, type = “prop”) corr_pred_binary(modelo_3, type = “prop”)</p>
</div>
<div id="roc-plot" class="section level3">
<h3><span class="header-section-number">5.0.6</span> ROC plot</h3>
<p>Las curvas de ROC tienen la ventaja de no definir un límite arbitrario a partir del cual se decide si la observación ha sido correcta o incorrectamente clasificada. Su desventaja es que es una figura extra que deberemos incluir en nuestro artículo (¿quizás pensemos en un apéndice?). Para interpretar estas figuras, lo que nos interesa es el área debajo de la curva. A mayor el área bajo la curva, mejor el ajuste del modelo. Si quieren leer más al respecto, el área conforma un score que se denomina AUC score (que viene de “Area Under the Curve”). Vamos a construirlo con la función <code>roc.plot()</code> del paquete <code>verification</code></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">roc.plot</span>(<span class="dt">x    =</span> modelo_<span class="dv">1</span><span class="op">$</span>y, <span class="co"># tienen el mismo x!</span>
         <span class="dt">pred =</span> <span class="kw">cbind</span>(<span class="kw">predict.glm</span>(modelo_<span class="dv">1</span>, <span class="dt">type=</span><span class="st">&quot;response&quot;</span>),
                      <span class="kw">predict.glm</span>(modelo_<span class="dv">2</span>, <span class="dt">type=</span><span class="st">&quot;response&quot;</span>),
                      <span class="kw">predict.glm</span>(modelo_<span class="dv">3</span>, <span class="dt">type=</span><span class="st">&quot;response&quot;</span>)),
         <span class="dt">threshold =</span> <span class="kw">seq</span>(<span class="dv">0</span>,<span class="dv">1</span>, <span class="fl">0.1</span>),<span class="dt">legend =</span> T, <span class="dt">show.thres =</span> F,
         <span class="dt">xlab=</span><span class="st">&quot;Ratio de falsas alarmas&quot;</span>, 
         <span class="dt">ylab=</span><span class="st">&quot;Ratio de aciertos&quot;</span>,
         <span class="dt">leg.text =</span> <span class="kw">c</span>(<span class="st">&quot;Modelo 1&quot;</span>,<span class="st">&quot;Modelo 2&quot;</span>, <span class="st">&quot;Modelo 3&quot;</span>), 
         <span class="dt">main=</span><span class="st">&quot;ROC plot - Modelos 1-3 en base a Mainwaring y Perez Liñan (2013)&quot;</span>)</code></pre></div>
<pre><code>## Warning in cbind(predict.glm(modelo_1, type = &quot;response&quot;),
## predict.glm(modelo_2, : number of rows of result is not a multiple of
## vector length (arg 3)</code></pre>
<p><img src="adp-bookdown_files/figure-html/unnamed-chunk-74-1.png" width="672"  /></p>
<p>En el eje vertical tenemos la <em>sensibilidad</em> del modelo mientras que en el eje horizontal tenemos (1-<em>especificidad</em>) del modelo. La sensibilidad es la razón entre los verdaderos positivos (o sea, aquellas observaciones predichas como “1”, que realmente eran “1” en la base de datos), y la suma de los verdaderos postivos más los falsos negativos (aquellos preichos como “0” que en verdad eran “1”). La especificidad es la razón entre los verdaderos negativos (aquellas observaciones predichas como “0” que eran “0” en la base de datos) y la suma de los falsos positivos (aquellas observaciones predichas como “1” que en verdad eran “0”) sumado a los verdaderos negativos.</p>
</div>
<div id="separation-plots" class="section level3">
<h3><span class="header-section-number">5.0.7</span> Separation plots</h3>
<p>Nótese cómo ocupamos el argumento <code>type = &quot;bands&quot;</code>, en tanto nuestro n es muy alto.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">separationplot</span>(<span class="dt">pred    =</span> <span class="kw">predict.glm</span>(modelo_<span class="dv">1</span>, <span class="dt">type =</span> <span class="st">&quot;response&quot;</span>),
               <span class="dt">actual  =</span> <span class="kw">as.vector</span>(modelo_<span class="dv">1</span><span class="op">$</span>y),
               <span class="dt">type    =</span> <span class="st">&quot;bands&quot;</span>,
               <span class="dt">newplot =</span> F, 
               <span class="dt">heading =</span> <span class="st">&quot;Separation plot - Modelo 1 en base a Mainwaring y Perez Liñan (2013)&quot;</span>)</code></pre></div>
<p><img src="adp-bookdown_files/figure-html/unnamed-chunk-75-1.png" width="672"  /></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">separationplot</span>(<span class="dt">pred    =</span> <span class="kw">predict.glm</span>(modelo_<span class="dv">2</span>, <span class="dt">type =</span> <span class="st">&quot;response&quot;</span>),
               <span class="dt">actual  =</span> <span class="kw">as.vector</span>(modelo_<span class="dv">2</span><span class="op">$</span>y),
               <span class="dt">type    =</span> <span class="st">&quot;bands&quot;</span>,
               <span class="dt">newplot =</span> F, 
               <span class="dt">heading =</span> <span class="st">&quot;Separation plot - Modelo 2 en base a a Mainwaring y Perez Liñan (2013)&quot;</span>)</code></pre></div>
<p><img src="adp-bookdown_files/figure-html/unnamed-chunk-76-1.png" width="672"  /></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">separationplot</span>(<span class="dt">pred    =</span> <span class="kw">predict.glm</span>(modelo_<span class="dv">3</span>, <span class="dt">type =</span> <span class="st">&quot;response&quot;</span>),
               <span class="dt">actual  =</span> <span class="kw">as.vector</span>(modelo_<span class="dv">3</span><span class="op">$</span>y),
               <span class="dt">type    =</span> <span class="st">&quot;bands&quot;</span>,
               <span class="dt">newplot =</span> F, 
               <span class="dt">heading =</span> <span class="st">&quot;Separation plot - Modelo 3 en base a a Mainwaring y Perez Liñan (2013)&quot;</span>)</code></pre></div>
<p><img src="adp-bookdown_files/figure-html/unnamed-chunk-77-1.png" width="672"  /></p>

</div>
</div>
<p style="text-align: center;">
<a href="manejo.html"><button class="btn btn-default">Previous</button></a>
<a href="modelos-de-supervivencia.html"><button class="btn btn-default">Next</button></a>
</p>
</div>
</div>



</body>
</html>
